{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63072392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the neccessory libarary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b027153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('uci breast cancer datatset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2148a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df2 = df.copy()\n",
    "df3 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7564c36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "724e165c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('id', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c21af73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding the categorical feature that is our target column.\n",
    "le = LabelEncoder()\n",
    "df.diagnosis = le.fit_transform(df['diagnosis'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c29ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select features into X & y\n",
    "X = df.drop('diagnosis', axis=1)\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a0636b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8633c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n"
     ]
    }
   ],
   "source": [
    "#split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d7e5e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply XGB Algorithm\n",
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "877c784a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74b8d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Accuracy and Confusion Matrix\n",
    "xgb_acc = xgb_clf.score(X_test, y_test)\n",
    "xgb_cm = confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5942567b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary Score:  0.9415204678362573\n",
      "Confusion matrix:  [[105   7]\n",
      " [  3  56]]\n"
     ]
    }
   ],
   "source": [
    "print('Accurary Score: ', xgb_acc)\n",
    "print('Confusion matrix: ', xgb_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c60ef843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(xgb_cm, annot=True,cmap='Blues', fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca677e9",
   "metadata": {},
   "source": [
    "# Hyperperameter Tuning using perameter 1\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cd24bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [4, 5, 6, 8, 10], 'min_child_weight': range(1, 6, 2), 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4], 'subsample': [0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9], 'reg_alpha': [1e-05, 0.01, 0.1, 1, 100]}\n"
     ]
    }
   ],
   "source": [
    "#let's randomly choose the parameters value and use GridSearchCV algorithm finding the best one. \n",
    "\n",
    "params = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2),\n",
    "    'max_depth':[4,5,6,8,10],\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eb9e11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=200,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.7, 0.8,\n",
       "                                                             0.9],\n",
       "                                        &#x27;gamma&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        &#x27;max_depth&#x27;: [4, 5, 6, 8, 10],\n",
       "                                        &#x27;min_child_weight&#x27;: range(1, 6, 2),\n",
       "                                        &#x27;reg_alpha&#x27;: [1e-05, 0.01, 0.1, 1, 100],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.7, 0.8, 0.9]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=200,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.7, 0.8,\n",
       "                                                             0.9],\n",
       "                                        &#x27;gamma&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        &#x27;max_depth&#x27;: [4, 5, 6, 8, 10],\n",
       "                                        &#x27;min_child_weight&#x27;: range(1, 6, 2),\n",
       "                                        &#x27;reg_alpha&#x27;: [1e-05, 0.01, 0.1, 1, 100],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.7, 0.8, 0.9]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=200,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.7, 0.8,\n",
       "                                                             0.9],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'max_depth': [4, 5, 6, 8, 10],\n",
       "                                        'min_child_weight': range(1, 6, 2),\n",
       "                                        'reg_alpha': [1e-05, 0.01, 0.1, 1, 100],\n",
       "                                        'subsample': [0.6, 0.7, 0.8, 0.9]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_xgb_clf = XGBClassifier()\n",
    "p_xgb_rcv = RandomizedSearchCV(p_xgb_clf, params, n_iter=200, cv=3)\n",
    "p_xgb_rcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f42c0fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03515204, 0.0325036 , 0.03213072, 0.04828898, 0.10807554,\n",
       "        0.09016458, 0.0365123 , 0.09182366, 0.03305387, 0.04854806,\n",
       "        0.02941434, 0.05608376, 0.14760431, 0.07620796, 0.13836432,\n",
       "        0.12516896, 0.06782738, 0.05890203, 0.12507963, 0.08134611,\n",
       "        0.12201349, 0.14745943, 0.11031437, 0.04213166, 0.07885965,\n",
       "        0.04928343, 0.15117868, 0.05845459, 0.03431161, 0.03934201,\n",
       "        0.04246068, 0.08454506, 0.12061977, 0.10914667, 0.05837806,\n",
       "        0.06899238, 0.05204431, 0.07612332, 0.05266825, 0.06682007,\n",
       "        0.05935931, 0.03702784, 0.03172763, 0.0995055 , 0.07915958,\n",
       "        0.05328202, 0.08806403, 0.06957936, 0.10537561, 0.06054425,\n",
       "        0.04359468, 0.03132161, 0.04780785, 0.04332503, 0.0354894 ,\n",
       "        0.04733102, 0.04881096, 0.04691879, 0.04537495, 0.03601964,\n",
       "        0.03261852, 0.04008603, 0.04802608, 0.03884602, 0.03349137,\n",
       "        0.03762992, 0.03317984, 0.0327758 , 0.03453   , 0.03593564,\n",
       "        0.03754465, 0.03189739, 0.03105601, 0.03282221, 0.03549035,\n",
       "        0.03154445, 0.03936672, 0.03149509, 0.03223165, 0.09277765,\n",
       "        0.14439416, 0.06795192, 0.04315106, 0.03292632, 0.03348645,\n",
       "        0.0359985 , 0.03166731, 0.0313127 , 0.03239799, 0.03215472,\n",
       "        0.03217665, 0.03193863, 0.03320257, 0.04019125, 0.03172326,\n",
       "        0.03239703, 0.03962771, 0.04615736, 0.03325597, 0.0329361 ,\n",
       "        0.03151441, 0.03282523, 0.02914921, 0.03012904, 0.03567664,\n",
       "        0.03646064, 0.03069901, 0.02968168, 0.03706861, 0.03034329,\n",
       "        0.03001213, 0.0306503 , 0.0318718 , 0.03078834, 0.03277683,\n",
       "        0.03520624, 0.03492037, 0.04164632, 0.03683027, 0.04327599,\n",
       "        0.03519432, 0.04281108, 0.03963733, 0.03745341, 0.04011464,\n",
       "        0.0392127 , 0.03956334, 0.03929408, 0.03590568, 0.03379695,\n",
       "        0.04163337, 0.03965767, 0.03409505, 0.03915334, 0.05682373,\n",
       "        0.04666924, 0.05070925, 0.04309289, 0.0411764 , 0.03521442,\n",
       "        0.0332396 , 0.0325954 , 0.07483164, 0.03388119, 0.04109693,\n",
       "        0.032547  , 0.07787395, 0.03958201, 0.14175256, 0.03843546,\n",
       "        0.03601329, 0.0314513 , 0.03326329, 0.03571065, 0.03096557,\n",
       "        0.03215377, 0.03244901, 0.03617867, 0.03277802, 0.03928336,\n",
       "        0.0311753 , 0.03038931, 0.03960061, 0.03125032, 0.03076736,\n",
       "        0.03104536, 0.04650394, 0.03451626, 0.03062201, 0.03477836,\n",
       "        0.04536931, 0.04550505, 0.05519732, 0.0611589 , 0.06184721,\n",
       "        0.06471244, 0.07559721, 0.07951665, 0.05222829, 0.06227366,\n",
       "        0.03529302, 0.03509967, 0.03207866, 0.03437066, 0.04279407,\n",
       "        0.03841686, 0.03364499, 0.03989299, 0.03297901, 0.03779054,\n",
       "        0.03228569, 0.03098289, 0.03557237, 0.04739396, 0.04688438,\n",
       "        0.04831616, 0.0403173 , 0.05147457, 0.03253404, 0.0315183 ]),\n",
       " 'std_fit_time': array([4.70170927e-03, 1.57931895e-03, 2.10513929e-03, 1.60437880e-02,\n",
       "        2.20073116e-02, 3.63397403e-02, 2.91694275e-03, 5.29227193e-02,\n",
       "        3.33585015e-03, 2.17876913e-02, 1.05724181e-03, 1.99549733e-02,\n",
       "        7.26360239e-02, 7.22078881e-03, 2.36250389e-02, 4.32461781e-02,\n",
       "        2.16855074e-02, 2.06263667e-02, 3.58211452e-02, 1.06890879e-03,\n",
       "        4.27333811e-02, 2.65562310e-02, 4.16416156e-02, 1.91888660e-03,\n",
       "        2.88837568e-02, 6.23099583e-03, 1.86360126e-02, 2.83327935e-02,\n",
       "        2.95553594e-03, 2.73039717e-04, 5.25096267e-04, 2.95969211e-02,\n",
       "        1.82629348e-02, 1.06255964e-02, 3.53851633e-03, 1.02269033e-02,\n",
       "        2.79740089e-03, 3.90031534e-03, 1.36878439e-03, 1.58574179e-02,\n",
       "        7.13449551e-03, 4.76710081e-03, 2.67526847e-04, 4.45422837e-02,\n",
       "        1.87569485e-02, 1.22924911e-02, 7.06482219e-03, 2.58975580e-02,\n",
       "        1.55422874e-02, 1.96368175e-02, 1.32555027e-03, 8.70950223e-04,\n",
       "        1.73603927e-02, 1.44026004e-02, 1.97441550e-03, 1.36644181e-02,\n",
       "        1.08933824e-03, 1.08446482e-02, 4.85234960e-03, 1.15679067e-03,\n",
       "        1.74729692e-03, 1.47960243e-03, 1.03681568e-02, 9.32505257e-03,\n",
       "        8.77105434e-04, 8.11318558e-03, 9.19090899e-04, 1.26600748e-03,\n",
       "        2.69097818e-03, 1.34630647e-03, 4.08943103e-03, 4.12818830e-04,\n",
       "        1.39309940e-03, 7.02129002e-04, 5.82331944e-04, 1.43935158e-03,\n",
       "        8.43951705e-03, 1.06511007e-03, 1.08487978e-03, 2.23870565e-02,\n",
       "        4.45888745e-02, 1.61261791e-02, 3.56254560e-03, 2.94437260e-04,\n",
       "        1.64478823e-03, 5.06692686e-03, 3.27972254e-04, 1.23440514e-04,\n",
       "        2.68858364e-04, 1.36849541e-04, 4.72234781e-04, 3.37524893e-04,\n",
       "        1.55492598e-03, 7.73677973e-03, 8.30284432e-04, 1.34122210e-03,\n",
       "        3.26829653e-03, 2.58502681e-03, 7.51130190e-04, 2.37239934e-03,\n",
       "        1.27350842e-03, 3.10252092e-03, 2.14021134e-04, 2.69229676e-04,\n",
       "        4.50590692e-04, 4.39492861e-04, 1.19932050e-04, 1.40501588e-04,\n",
       "        2.63376908e-03, 2.73787658e-04, 2.03233345e-04, 1.86465618e-04,\n",
       "        1.95253469e-03, 5.73004367e-04, 2.29024111e-03, 9.94388423e-04,\n",
       "        4.91567126e-03, 6.50794838e-03, 3.24338426e-03, 3.91787492e-03,\n",
       "        7.17845476e-04, 2.91882746e-03, 2.26028924e-03, 2.70069237e-03,\n",
       "        3.70757827e-03, 5.38457298e-04, 6.62530108e-04, 5.23000824e-04,\n",
       "        1.70580688e-03, 4.34313296e-04, 3.77273672e-03, 3.61973586e-03,\n",
       "        1.41275578e-03, 3.84304874e-03, 7.56662538e-03, 2.68378297e-03,\n",
       "        6.80037135e-03, 1.12301158e-03, 5.35089407e-03, 3.87025112e-03,\n",
       "        7.32441458e-04, 4.57203832e-04, 3.00862852e-02, 1.28783593e-03,\n",
       "        6.41114963e-04, 7.34084133e-04, 4.25128632e-02, 3.67961369e-03,\n",
       "        6.13493806e-02, 1.05695269e-03, 2.17990022e-03, 2.68238903e-04,\n",
       "        2.58243997e-03, 1.02571268e-03, 1.03597925e-04, 1.69265363e-04,\n",
       "        8.11148525e-04, 2.09872974e-03, 2.55125509e-03, 6.64092383e-04,\n",
       "        7.97681164e-04, 1.62463325e-04, 1.14587546e-03, 9.42692175e-05,\n",
       "        4.55956083e-04, 4.18861992e-04, 1.38408822e-02, 5.83701153e-04,\n",
       "        7.23986847e-05, 1.35217101e-03, 7.26574548e-03, 8.45745111e-03,\n",
       "        5.32931837e-03, 1.88780205e-03, 2.20324376e-03, 2.25757068e-03,\n",
       "        5.51398674e-03, 2.11579182e-03, 1.80909052e-03, 1.64411579e-02,\n",
       "        1.96687953e-03, 1.34382232e-03, 5.30310894e-04, 1.96247922e-03,\n",
       "        1.96545105e-03, 1.39371516e-03, 1.32459201e-03, 2.75729589e-03,\n",
       "        3.77965097e-03, 5.81831840e-04, 5.59245460e-04, 6.11184011e-05,\n",
       "        2.79657977e-03, 1.21926096e-03, 1.12083159e-02, 2.61541929e-03,\n",
       "        2.47626881e-03, 7.41037837e-03, 6.26369134e-04, 5.39772408e-04]),\n",
       " 'mean_score_time': array([0.00303801, 0.00302505, 0.00313695, 0.0035181 , 0.0037965 ,\n",
       "        0.00330035, 0.003395  , 0.00359313, 0.00299438, 0.00327428,\n",
       "        0.00309141, 0.00481892, 0.00366545, 0.00443244, 0.00425053,\n",
       "        0.0069174 , 0.0033203 , 0.00353169, 0.00352867, 0.00346796,\n",
       "        0.00534741, 0.00537562, 0.00382479, 0.00393534, 0.00362372,\n",
       "        0.00382169, 0.00383743, 0.00346661, 0.00351532, 0.0035847 ,\n",
       "        0.00373165, 0.00445962, 0.00412758, 0.00399439, 0.00360131,\n",
       "        0.00414793, 0.00353471, 0.00371067, 0.00359066, 0.00356094,\n",
       "        0.00352351, 0.00337291, 0.00326586, 0.00390093, 0.00393359,\n",
       "        0.00339023, 0.00386238, 0.0036726 , 0.00364772, 0.00368476,\n",
       "        0.00327142, 0.00330591, 0.00323431, 0.00314291, 0.00343299,\n",
       "        0.00354091, 0.00349315, 0.00341487, 0.00337903, 0.00319664,\n",
       "        0.00317923, 0.0032169 , 0.00335304, 0.00314665, 0.00321198,\n",
       "        0.00312066, 0.00315094, 0.00313592, 0.00320903, 0.0037624 ,\n",
       "        0.00333166, 0.00318193, 0.0031302 , 0.00315976, 0.00317399,\n",
       "        0.00315666, 0.00320991, 0.00330806, 0.00341058, 0.004131  ,\n",
       "        0.00463422, 0.00366871, 0.00352859, 0.00350952, 0.00331958,\n",
       "        0.00330385, 0.00332729, 0.0032258 , 0.00326506, 0.00318543,\n",
       "        0.00328533, 0.00328469, 0.00331028, 0.00357429, 0.00320005,\n",
       "        0.00325394, 0.00343259, 0.00331632, 0.00332602, 0.00309022,\n",
       "        0.00314665, 0.00310802, 0.00304627, 0.00310699, 0.00315237,\n",
       "        0.00311939, 0.00304445, 0.00302704, 0.00312495, 0.00309571,\n",
       "        0.00313783, 0.0030431 , 0.00307989, 0.00308959, 0.00322707,\n",
       "        0.00327794, 0.00325259, 0.00324734, 0.00323653, 0.00329304,\n",
       "        0.003148  , 0.00332737, 0.00332133, 0.003304  , 0.00347575,\n",
       "        0.00335956, 0.0034229 , 0.00356062, 0.00351858, 0.00333103,\n",
       "        0.00351628, 0.00352391, 0.00340366, 0.00351715, 0.00382296,\n",
       "        0.00354568, 0.00362388, 0.00366521, 0.00343959, 0.00351501,\n",
       "        0.00327563, 0.00327261, 0.00353932, 0.00332451, 0.00327762,\n",
       "        0.0033834 , 0.00377711, 0.00337013, 0.00414507, 0.0032289 ,\n",
       "        0.00320045, 0.00318058, 0.00316572, 0.00324488, 0.00312901,\n",
       "        0.00313528, 0.00321937, 0.00332777, 0.00317574, 0.00363859,\n",
       "        0.00314267, 0.00313671, 0.00324726, 0.00322405, 0.00315293,\n",
       "        0.00315158, 0.00332022, 0.00318472, 0.00307727, 0.00328398,\n",
       "        0.0032169 , 0.00348775, 0.00364669, 0.00364232, 0.00382837,\n",
       "        0.00367133, 0.00365233, 0.00372084, 0.00358462, 0.0035495 ,\n",
       "        0.00323415, 0.00326792, 0.0032057 , 0.00335161, 0.00331497,\n",
       "        0.00334891, 0.00332244, 0.00326975, 0.00322262, 0.00325274,\n",
       "        0.00320307, 0.00313886, 0.00340041, 0.00336854, 0.00345564,\n",
       "        0.00361657, 0.00346303, 0.00381796, 0.00314665, 0.00322477]),\n",
       " 'std_score_time': array([1.52407024e-04, 8.62616299e-05, 1.28084611e-04, 3.77338259e-04,\n",
       "        2.36711137e-04, 3.17723289e-04, 3.60586555e-04, 5.12810683e-04,\n",
       "        1.08774860e-04, 1.56581461e-04, 2.35497086e-04, 1.50952732e-03,\n",
       "        3.31889338e-04, 1.45339158e-03, 6.00001027e-04, 4.15212300e-03,\n",
       "        2.63723449e-04, 2.77219676e-04, 1.34466716e-04, 1.06151051e-04,\n",
       "        7.89631160e-04, 1.89373794e-03, 2.34782332e-04, 3.63159004e-04,\n",
       "        2.04326531e-04, 2.11324984e-04, 2.33802319e-04, 1.19986070e-04,\n",
       "        1.27805455e-04, 2.09066707e-04, 1.84394470e-04, 4.30983289e-04,\n",
       "        2.50768999e-04, 4.07262219e-04, 1.12115729e-04, 5.31835643e-04,\n",
       "        4.56575556e-05, 5.34264538e-05, 1.07988323e-04, 1.45751101e-04,\n",
       "        3.49602907e-05, 9.18857492e-05, 6.18477585e-05, 3.48372560e-04,\n",
       "        4.71277422e-04, 1.54557816e-04, 4.02950017e-04, 5.87864638e-04,\n",
       "        1.44582910e-04, 6.99079567e-04, 4.50782782e-05, 7.09967135e-05,\n",
       "        3.51235876e-05, 4.73312758e-05, 1.88215122e-04, 3.88475711e-04,\n",
       "        1.63999212e-04, 8.99191069e-05, 2.72188430e-04, 5.84653477e-05,\n",
       "        4.35035334e-05, 2.20948843e-05, 2.58197255e-04, 1.50839404e-05,\n",
       "        8.43941153e-05, 2.81825149e-05, 5.00213316e-05, 1.32588743e-05,\n",
       "        8.89778080e-05, 1.14290207e-04, 1.52243782e-04, 4.31166449e-05,\n",
       "        6.82563148e-05, 1.44749730e-05, 3.53601537e-05, 8.22072885e-05,\n",
       "        2.15233252e-04, 1.75841205e-04, 1.45658858e-04, 1.05664599e-04,\n",
       "        1.03531377e-03, 5.07069231e-05, 2.08264418e-04, 3.32145291e-04,\n",
       "        4.06894833e-05, 9.05606400e-05, 5.04435470e-05, 1.42134271e-05,\n",
       "        1.58822489e-05, 2.09991900e-05, 8.40520083e-05, 1.31987170e-05,\n",
       "        5.89462581e-05, 1.58557059e-04, 1.04524184e-05, 7.55168660e-05,\n",
       "        1.24275988e-04, 3.37771808e-05, 1.08309292e-04, 3.78924728e-05,\n",
       "        5.55305482e-05, 1.60904576e-05, 3.23711211e-05, 1.12500956e-04,\n",
       "        4.96853488e-05, 4.04358348e-05, 1.51407791e-05, 1.27953772e-05,\n",
       "        4.02162511e-05, 1.43399521e-05, 1.21098020e-04, 1.74011085e-05,\n",
       "        4.36286457e-05, 5.30470474e-05, 1.46463069e-04, 4.52188699e-05,\n",
       "        1.62580766e-04, 1.25467889e-04, 1.43490091e-04, 1.68627963e-04,\n",
       "        6.93729331e-05, 1.53394272e-04, 1.27716471e-04, 6.37468448e-05,\n",
       "        1.31456422e-04, 2.20228916e-04, 6.04980065e-05, 1.99238190e-04,\n",
       "        6.38831301e-05, 1.87451528e-05, 1.71511896e-04, 1.44946252e-04,\n",
       "        1.12006163e-04, 1.48694591e-04, 2.34737053e-04, 5.22785253e-05,\n",
       "        2.36037230e-04, 1.51469683e-04, 9.88954084e-05, 1.75250576e-04,\n",
       "        2.45011102e-05, 1.66464816e-05, 3.11757615e-04, 3.63351792e-05,\n",
       "        5.96257278e-05, 2.34008615e-04, 3.27702808e-04, 1.19333256e-04,\n",
       "        4.88024150e-04, 6.42483882e-05, 6.65879185e-05, 1.86356654e-05,\n",
       "        4.26993409e-05, 2.79678984e-05, 3.05864184e-05, 4.57653280e-05,\n",
       "        5.32750392e-05, 8.59915439e-05, 5.07135242e-05, 6.39192232e-04,\n",
       "        4.13220661e-05, 4.13509440e-05, 3.64336042e-05, 7.09863933e-05,\n",
       "        4.60965879e-05, 2.41398730e-05, 1.59150786e-04, 4.49182684e-05,\n",
       "        1.61034058e-05, 1.09631766e-04, 9.84244978e-06, 1.98040785e-04,\n",
       "        2.84563159e-04, 1.71620753e-04, 8.52086195e-05, 1.39479329e-04,\n",
       "        2.06916286e-04, 1.33325854e-04, 2.01814908e-04, 3.67388169e-04,\n",
       "        1.50045938e-05, 2.76650036e-05, 4.11267250e-06, 4.27651131e-05,\n",
       "        1.52844472e-04, 2.06904137e-04, 1.36603698e-04, 7.53448816e-05,\n",
       "        1.12388393e-04, 1.31672835e-04, 3.00630187e-05, 4.26963825e-05,\n",
       "        1.72094216e-04, 1.70307687e-04, 9.95952533e-05, 1.42991663e-04,\n",
       "        1.92468730e-04, 2.96107834e-04, 7.01074957e-06, 1.05558388e-05]),\n",
       " 'param_subsample': masked_array(data=[0.7, 0.7, 0.7, 0.7, 0.6, 0.9, 0.8, 0.7, 0.6, 0.6, 0.9,\n",
       "                    0.7, 0.6, 0.8, 0.9, 0.9, 0.7, 0.6, 0.7, 0.9, 0.9, 0.8,\n",
       "                    0.9, 0.8, 0.7, 0.8, 0.7, 0.9, 0.6, 0.8, 0.8, 0.8, 0.9,\n",
       "                    0.9, 0.8, 0.6, 0.8, 0.9, 0.8, 0.7, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.7, 0.6, 0.7, 0.9, 0.6, 0.8, 0.9, 0.6, 0.6, 0.9, 0.8,\n",
       "                    0.7, 0.6, 0.6, 0.8, 0.7, 0.7, 0.9, 0.6, 0.7, 0.9, 0.7,\n",
       "                    0.8, 0.7, 0.8, 0.8, 0.6, 0.9, 0.7, 0.6, 0.9, 0.6, 0.9,\n",
       "                    0.6, 0.8, 0.9, 0.8, 0.9, 0.8, 0.6, 0.6, 0.8, 0.6, 0.8,\n",
       "                    0.8, 0.8, 0.6, 0.8, 0.6, 0.9, 0.7, 0.7, 0.9, 0.7, 0.8,\n",
       "                    0.6, 0.7, 0.6, 0.6, 0.7, 0.8, 0.8, 0.8, 0.9, 0.8, 0.6,\n",
       "                    0.6, 0.8, 0.6, 0.9, 0.6, 0.6, 0.7, 0.6, 0.6, 0.8, 0.7,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.7, 0.7, 0.6, 0.7, 0.9, 0.8, 0.8,\n",
       "                    0.7, 0.7, 0.9, 0.7, 0.7, 0.9, 0.8, 0.9, 0.7, 0.7, 0.9,\n",
       "                    0.7, 0.9, 0.7, 0.8, 0.7, 0.6, 0.7, 0.8, 0.7, 0.6, 0.8,\n",
       "                    0.9, 0.7, 0.6, 0.6, 0.6, 0.7, 0.8, 0.9, 0.8, 0.6, 0.8,\n",
       "                    0.9, 0.7, 0.8, 0.7, 0.6, 0.8, 0.7, 0.6, 0.8, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.8, 0.6, 0.7, 0.6, 0.9, 0.8, 0.6, 0.6,\n",
       "                    0.8, 0.7, 0.7, 0.8, 0.6, 0.9, 0.8, 0.7, 0.8, 0.7, 0.8,\n",
       "                    0.9, 0.8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_reg_alpha': masked_array(data=[1, 100, 0.01, 1, 100, 1e-05, 1e-05, 1e-05, 1e-05,\n",
       "                    1e-05, 0.1, 1e-05, 0.01, 1e-05, 0.1, 1e-05, 1, 0.01, 1,\n",
       "                    1e-05, 100, 1, 1, 1e-05, 1, 0.01, 0.01, 0.01, 0.1,\n",
       "                    0.01, 0.1, 0.01, 100, 1, 1, 100, 100, 0.01, 0.1, 0.1,\n",
       "                    100, 100, 100, 0.1, 100, 100, 1e-05, 0.01, 0.01, 100,\n",
       "                    1, 0.01, 100, 1, 0.1, 0.1, 100, 1e-05, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 1, 100, 0.01, 100, 1, 100, 1, 1e-05, 1e-05,\n",
       "                    1, 0.1, 0.1, 100, 100, 100, 1, 0.1, 0.01, 100, 1e-05,\n",
       "                    1, 0.1, 100, 0.01, 0.01, 0.1, 100, 0.01, 1e-05, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.01, 0.01, 1, 0.1, 0.01, 1, 0.01,\n",
       "                    1e-05, 0.01, 0.1, 100, 0.01, 1, 1e-05, 0.1, 100, 100,\n",
       "                    0.01, 100, 0.1, 0.01, 0.01, 100, 1e-05, 1e-05, 1e-05,\n",
       "                    1, 0.01, 1, 0.1, 100, 1e-05, 100, 1, 0.01, 1e-05, 0.1,\n",
       "                    1e-05, 0.01, 0.01, 1, 0.01, 1e-05, 1e-05, 100, 0.1,\n",
       "                    0.1, 0.01, 1, 100, 0.01, 0.01, 0.01, 1, 1e-05, 1e-05,\n",
       "                    0.1, 0.1, 1, 100, 0.01, 1, 0.1, 1, 0.1, 1, 1, 0.1,\n",
       "                    1e-05, 0.01, 100, 0.1, 100, 0.01, 1, 100, 100, 0.1,\n",
       "                    1e-05, 1e-05, 0.1, 1e-05, 1e-05, 0.1, 1e-05, 1e-05,\n",
       "                    0.1, 1, 1, 0.01, 0.01, 1, 0.01, 1, 0.01, 1e-05, 100,\n",
       "                    0.1, 1, 0.1, 0.01, 1, 100, 1e-05],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[3, 3, 5, 3, 1, 3, 1, 1, 5, 3, 5, 3, 1, 3, 1, 3, 5, 1,\n",
       "                    1, 3, 1, 3, 1, 5, 1, 5, 1, 1, 3, 1, 5, 5, 3, 1, 1, 3,\n",
       "                    1, 1, 3, 3, 5, 3, 3, 1, 1, 5, 3, 5, 1, 5, 1, 5, 5, 5,\n",
       "                    3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 3, 3, 1, 5, 1, 5, 5, 3,\n",
       "                    5, 1, 1, 5, 1, 3, 5, 5, 1, 5, 1, 3, 3, 5, 5, 5, 3, 5,\n",
       "                    3, 5, 5, 3, 5, 3, 5, 1, 3, 3, 5, 3, 5, 5, 1, 1, 3, 5,\n",
       "                    1, 3, 3, 1, 5, 3, 1, 1, 5, 5, 1, 1, 3, 1, 3, 3, 3, 3,\n",
       "                    5, 5, 3, 5, 1, 5, 5, 3, 3, 5, 5, 3, 3, 5, 3, 3, 3, 3,\n",
       "                    1, 1, 1, 5, 1, 1, 1, 3, 3, 1, 5, 3, 3, 3, 5, 1, 5, 5,\n",
       "                    1, 3, 5, 5, 3, 1, 5, 1, 1, 5, 3, 5, 3, 5, 1, 1, 5, 1,\n",
       "                    3, 1, 5, 5, 1, 1, 3, 1, 5, 1, 3, 3, 5, 1, 3, 1, 5, 3,\n",
       "                    3, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[10, 6, 10, 5, 4, 6, 6, 4, 6, 6, 5, 6, 5, 6, 6, 6, 5, 5,\n",
       "                    5, 5, 10, 6, 4, 8, 8, 5, 4, 5, 6, 8, 6, 6, 4, 6, 5, 6,\n",
       "                    10, 6, 10, 10, 6, 4, 8, 8, 8, 10, 4, 10, 6, 6, 8, 10,\n",
       "                    5, 4, 10, 5, 6, 8, 8, 4, 8, 8, 8, 4, 4, 8, 10, 6, 4,\n",
       "                    10, 10, 8, 10, 10, 8, 6, 4, 8, 8, 8, 5, 10, 4, 6, 4,\n",
       "                    10, 8, 4, 10, 6, 5, 4, 5, 4, 5, 8, 5, 5, 4, 6, 8, 8,\n",
       "                    10, 10, 6, 10, 4, 8, 6, 10, 5, 5, 8, 6, 4, 5, 10, 4, 6,\n",
       "                    6, 10, 6, 6, 8, 8, 5, 5, 8, 4, 5, 4, 8, 5, 6, 6, 4, 10,\n",
       "                    10, 5, 4, 10, 6, 4, 10, 4, 8, 5, 10, 6, 4, 10, 8, 8, 8,\n",
       "                    6, 10, 4, 8, 4, 5, 4, 6, 10, 10, 6, 10, 10, 8, 4, 10,\n",
       "                    4, 6, 8, 6, 8, 4, 4, 5, 5, 5, 8, 4, 5, 6, 8, 4, 10, 6,\n",
       "                    5, 8, 4, 5, 4, 5, 4, 10, 4, 6, 8, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.4, 0.1, 0.1, 0.2, 0.3, 0.2, 0.2, 0.4, 0.1, 0.2, 0.1,\n",
       "                    0.0, 0.1, 0.1, 0.3, 0.0, 0.0, 0.4, 0.0, 0.4, 0.2, 0.4,\n",
       "                    0.3, 0.1, 0.1, 0.2, 0.1, 0.2, 0.0, 0.0, 0.1, 0.4, 0.4,\n",
       "                    0.3, 0.0, 0.4, 0.2, 0.3, 0.2, 0.2, 0.4, 0.3, 0.2, 0.3,\n",
       "                    0.2, 0.4, 0.1, 0.1, 0.1, 0.3, 0.2, 0.0, 0.2, 0.0, 0.3,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.0, 0.0, 0.3, 0.2, 0.2, 0.3, 0.3,\n",
       "                    0.3, 0.2, 0.0, 0.4, 0.2, 0.1, 0.0, 0.0, 0.1, 0.3, 0.2,\n",
       "                    0.2, 0.0, 0.4, 0.3, 0.2, 0.4, 0.1, 0.2, 0.3, 0.1, 0.0,\n",
       "                    0.1, 0.1, 0.3, 0.1, 0.4, 0.3, 0.2, 0.1, 0.3, 0.2, 0.1,\n",
       "                    0.3, 0.1, 0.2, 0.1, 0.3, 0.2, 0.4, 0.1, 0.1, 0.0, 0.1,\n",
       "                    0.0, 0.2, 0.3, 0.2, 0.2, 0.0, 0.2, 0.4, 0.1, 0.1, 0.1,\n",
       "                    0.2, 0.2, 0.4, 0.4, 0.0, 0.0, 0.1, 0.3, 0.1, 0.3, 0.2,\n",
       "                    0.4, 0.4, 0.1, 0.2, 0.1, 0.0, 0.2, 0.0, 0.0, 0.4, 0.2,\n",
       "                    0.3, 0.3, 0.2, 0.0, 0.0, 0.4, 0.0, 0.1, 0.4, 0.3, 0.0,\n",
       "                    0.0, 0.1, 0.2, 0.0, 0.1, 0.3, 0.2, 0.0, 0.2, 0.2, 0.4,\n",
       "                    0.0, 0.0, 0.0, 0.3, 0.0, 0.2, 0.2, 0.4, 0.3, 0.2, 0.0,\n",
       "                    0.2, 0.4, 0.4, 0.0, 0.0, 0.1, 0.2, 0.1, 0.4, 0.1, 0.3,\n",
       "                    0.0, 0.0, 0.0, 0.1, 0.0, 0.1, 0.2, 0.0, 0.3, 0.0, 0.1,\n",
       "                    0.1, 0.3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_colsample_bytree': masked_array(data=[0.7, 0.9, 0.6, 0.8, 0.6, 0.7, 0.8, 0.6, 0.7, 0.9, 0.7,\n",
       "                    0.6, 0.7, 0.9, 0.6, 0.6, 0.9, 0.7, 0.9, 0.8, 0.7, 0.8,\n",
       "                    0.6, 0.6, 0.7, 0.9, 0.6, 0.7, 0.6, 0.6, 0.8, 0.8, 0.6,\n",
       "                    0.7, 0.9, 0.6, 0.6, 0.9, 0.8, 0.6, 0.7, 0.6, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.7, 0.9, 0.7, 0.6, 0.9, 0.8, 0.6, 0.7, 0.8,\n",
       "                    0.7, 0.9, 0.9, 0.9, 0.7, 0.6, 0.9, 0.8, 0.7, 0.7, 0.7,\n",
       "                    0.9, 0.9, 0.9, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.8, 0.6,\n",
       "                    0.8, 0.8, 0.7, 0.9, 0.8, 0.7, 0.7, 0.6, 0.8, 0.7, 0.6,\n",
       "                    0.6, 0.8, 0.7, 0.8, 0.6, 0.6, 0.7, 0.6, 0.9, 0.7, 0.6,\n",
       "                    0.9, 0.9, 0.8, 0.6, 0.9, 0.9, 0.9, 0.7, 0.6, 0.7, 0.6,\n",
       "                    0.7, 0.7, 0.9, 0.7, 0.6, 0.7, 0.8, 0.6, 0.6, 0.6, 0.9,\n",
       "                    0.7, 0.9, 0.7, 0.7, 0.8, 0.7, 0.7, 0.7, 0.9, 0.7, 0.9,\n",
       "                    0.9, 0.7, 0.8, 0.6, 0.6, 0.8, 0.8, 0.7, 0.7, 0.6, 0.9,\n",
       "                    0.6, 0.7, 0.6, 0.9, 0.9, 0.9, 0.9, 0.7, 0.7, 0.9, 0.7,\n",
       "                    0.7, 0.9, 0.9, 0.6, 0.6, 0.9, 0.8, 0.6, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.9, 0.6, 0.6, 0.8, 0.8, 0.8, 0.6, 0.6, 0.7, 0.8,\n",
       "                    0.8, 0.9, 0.7, 0.6, 0.8, 0.6, 0.7, 0.7, 0.8, 0.9, 0.8,\n",
       "                    0.9, 0.7, 0.9, 0.8, 0.8, 0.6, 0.7, 0.8, 0.9, 0.6, 0.6,\n",
       "                    0.6, 0.6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.6,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.8},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 0.1,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_alpha': 0.01,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.9,\n",
       "   'reg_alpha': 100,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.6},\n",
       "  {'subsample': 0.8,\n",
       "   'reg_alpha': 1e-05,\n",
       "   'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.6}],\n",
       " 'split0_test_score': array([0.93984962, 0.62406015, 0.93984962, 0.93984962, 0.62406015,\n",
       "        0.94736842, 0.92481203, 0.94736842, 0.93233083, 0.93984962,\n",
       "        0.93233083, 0.94736842, 0.93984962, 0.93984962, 0.93984962,\n",
       "        0.94736842, 0.92481203, 0.93984962, 0.92481203, 0.95488722,\n",
       "        0.62406015, 0.93984962, 0.93984962, 0.93984962, 0.93984962,\n",
       "        0.93233083, 0.94736842, 0.93984962, 0.93984962, 0.93984962,\n",
       "        0.93233083, 0.93233083, 0.62406015, 0.93233083, 0.93984962,\n",
       "        0.62406015, 0.62406015, 0.93233083, 0.93233083, 0.94736842,\n",
       "        0.62406015, 0.62406015, 0.62406015, 0.92481203, 0.62406015,\n",
       "        0.62406015, 0.93984962, 0.93984962, 0.93984962, 0.62406015,\n",
       "        0.93233083, 0.93233083, 0.62406015, 0.93984962, 0.93233083,\n",
       "        0.93984962, 0.62406015, 0.93984962, 0.92481203, 0.94736842,\n",
       "        0.94736842, 0.93233083, 0.94736842, 0.93984962, 0.62406015,\n",
       "        0.93984962, 0.62406015, 0.92481203, 0.62406015, 0.92481203,\n",
       "        0.93233083, 0.94736842, 0.93233083, 0.93984962, 0.93984962,\n",
       "        0.62406015, 0.62406015, 0.62406015, 0.93984962, 0.93233083,\n",
       "        0.93984962, 0.62406015, 0.93233083, 0.93984962, 0.93984962,\n",
       "        0.62406015, 0.93233083, 0.93984962, 0.93233083, 0.62406015,\n",
       "        0.93984962, 0.93233083, 0.93984962, 0.93984962, 0.93233083,\n",
       "        0.94736842, 0.93984962, 0.93984962, 0.93984962, 0.94736842,\n",
       "        0.93233083, 0.94736842, 0.93984962, 0.93233083, 0.92481203,\n",
       "        0.92481203, 0.62406015, 0.93984962, 0.93984962, 0.93984962,\n",
       "        0.93984962, 0.62406015, 0.62406015, 0.94736842, 0.62406015,\n",
       "        0.93984962, 0.92481203, 0.93984962, 0.62406015, 0.94736842,\n",
       "        0.93233083, 0.92481203, 0.94736842, 0.93984962, 0.93984962,\n",
       "        0.94736842, 0.62406015, 0.93233083, 0.62406015, 0.93984962,\n",
       "        0.93984962, 0.93233083, 0.92481203, 0.93984962, 0.93984962,\n",
       "        0.93984962, 0.93233083, 0.93984962, 0.93984962, 0.91729323,\n",
       "        0.62406015, 0.94736842, 0.93984962, 0.94736842, 0.93233083,\n",
       "        0.62406015, 0.92481203, 0.93233083, 0.93984962, 0.92481203,\n",
       "        0.93984962, 0.93984962, 0.94736842, 0.92481203, 0.93984962,\n",
       "        0.62406015, 0.93984962, 0.93984962, 0.93984962, 0.93233083,\n",
       "        0.93233083, 0.93984962, 0.92481203, 0.93984962, 0.93984962,\n",
       "        0.93233083, 0.62406015, 0.94736842, 0.62406015, 0.95488722,\n",
       "        0.93233083, 0.62406015, 0.62406015, 0.94736842, 0.93984962,\n",
       "        0.92481203, 0.93233083, 0.92481203, 0.93233083, 0.94736842,\n",
       "        0.93233083, 0.93984962, 0.93984962, 0.93984962, 0.93984962,\n",
       "        0.93984962, 0.93233083, 0.93984962, 0.93233083, 0.92481203,\n",
       "        0.93984962, 0.93233083, 0.62406015, 0.93984962, 0.93984962,\n",
       "        0.92481203, 0.93984962, 0.93984962, 0.62406015, 0.93233083]),\n",
       " 'split1_test_score': array([0.96240602, 0.62406015, 0.97744361, 0.96992481, 0.62406015,\n",
       "        0.96240602, 0.96240602, 0.96992481, 0.97744361, 0.97744361,\n",
       "        0.96240602, 0.98496241, 0.98496241, 0.97744361, 0.96240602,\n",
       "        0.96240602, 0.97744361, 0.97744361, 0.97744361, 0.96992481,\n",
       "        0.62406015, 0.96240602, 0.95488722, 0.97744361, 0.97744361,\n",
       "        0.97744361, 0.97744361, 0.96992481, 0.96992481, 0.97744361,\n",
       "        0.95488722, 0.96240602, 0.62406015, 0.96240602, 0.96240602,\n",
       "        0.62406015, 0.62406015, 0.96992481, 0.96992481, 0.97744361,\n",
       "        0.62406015, 0.62406015, 0.62406015, 0.97744361, 0.62406015,\n",
       "        0.62406015, 0.96992481, 0.96992481, 0.98496241, 0.62406015,\n",
       "        0.96992481, 0.96992481, 0.62406015, 0.96992481, 0.96992481,\n",
       "        0.96240602, 0.62406015, 0.97744361, 0.96240602, 0.96992481,\n",
       "        0.96992481, 0.96992481, 0.98496241, 0.96240602, 0.62406015,\n",
       "        0.97744361, 0.62406015, 0.97744361, 0.62406015, 0.96992481,\n",
       "        0.97744361, 0.96992481, 0.97744361, 0.98496241, 0.97744361,\n",
       "        0.62406015, 0.62406015, 0.62406015, 0.96992481, 0.96240602,\n",
       "        0.96240602, 0.62406015, 0.96240602, 0.98496241, 0.96992481,\n",
       "        0.62406015, 0.97744361, 0.96992481, 0.98496241, 0.62406015,\n",
       "        0.97744361, 0.96992481, 0.96992481, 0.96992481, 0.97744361,\n",
       "        0.96992481, 0.97744361, 0.96992481, 0.96992481, 0.96992481,\n",
       "        0.96992481, 0.97744361, 0.96992481, 0.97744361, 0.96240602,\n",
       "        0.96240602, 0.62406015, 0.97744361, 0.96992481, 0.96992481,\n",
       "        0.96992481, 0.62406015, 0.62406015, 0.96992481, 0.62406015,\n",
       "        0.98496241, 0.96992481, 0.97744361, 0.62406015, 0.98496241,\n",
       "        0.97744361, 0.96992481, 0.96992481, 0.98496241, 0.96992481,\n",
       "        0.96992481, 0.62406015, 0.97744361, 0.62406015, 0.96992481,\n",
       "        0.96240602, 0.96240602, 0.97744361, 0.96992481, 0.96992481,\n",
       "        0.97744361, 0.97744361, 0.96992481, 0.96992481, 0.97744361,\n",
       "        0.62406015, 0.96992481, 0.96240602, 0.97744361, 0.96240602,\n",
       "        0.62406015, 0.96240602, 0.97744361, 0.97744361, 0.97744361,\n",
       "        0.96240602, 0.96992481, 0.96992481, 0.96240602, 0.96992481,\n",
       "        0.62406015, 0.97744361, 0.97744361, 0.95488722, 0.97744361,\n",
       "        0.95488722, 0.97744361, 0.96992481, 0.98496241, 0.96240602,\n",
       "        0.96240602, 0.62406015, 0.98496241, 0.62406015, 0.98496241,\n",
       "        0.97744361, 0.62406015, 0.62406015, 0.97744361, 0.96992481,\n",
       "        0.96992481, 0.96992481, 0.97744361, 0.97744361, 0.98496241,\n",
       "        0.97744361, 0.97744361, 0.96992481, 0.96992481, 0.97744361,\n",
       "        0.97744361, 0.97744361, 0.96240602, 0.97744361, 0.97744361,\n",
       "        0.96992481, 0.97744361, 0.62406015, 0.96240602, 0.97744361,\n",
       "        0.96240602, 0.97744361, 0.96992481, 0.62406015, 0.97744361]),\n",
       " 'split2_test_score': array([0.96212121, 0.62878788, 0.95454545, 0.96212121, 0.62878788,\n",
       "        0.96212121, 0.97727273, 0.96969697, 0.95454545, 0.96212121,\n",
       "        0.96212121, 0.96212121, 0.97727273, 0.96212121, 0.96969697,\n",
       "        0.96212121, 0.96212121, 0.97727273, 0.96212121, 0.96212121,\n",
       "        0.62878788, 0.96212121, 0.96212121, 0.96969697, 0.96212121,\n",
       "        0.96212121, 0.98484848, 0.97727273, 0.97727273, 0.98484848,\n",
       "        0.96212121, 0.96212121, 0.62878788, 0.97727273, 0.96969697,\n",
       "        0.62878788, 0.62878788, 0.96212121, 0.95454545, 0.95454545,\n",
       "        0.62878788, 0.62878788, 0.62878788, 0.97727273, 0.62878788,\n",
       "        0.62878788, 0.96212121, 0.96212121, 0.97727273, 0.62878788,\n",
       "        0.96212121, 0.95454545, 0.62878788, 0.95454545, 0.95454545,\n",
       "        0.97727273, 0.62878788, 0.96212121, 0.96212121, 0.96212121,\n",
       "        0.95454545, 0.96969697, 0.96969697, 0.96212121, 0.62878788,\n",
       "        0.96969697, 0.62878788, 0.96212121, 0.62878788, 0.96212121,\n",
       "        0.95454545, 0.96212121, 0.95454545, 0.98484848, 0.97727273,\n",
       "        0.62878788, 0.62878788, 0.62878788, 0.96212121, 0.96212121,\n",
       "        0.97727273, 0.62878788, 0.97727273, 0.96212121, 0.97727273,\n",
       "        0.62878788, 0.95454545, 0.96969697, 0.96212121, 0.62878788,\n",
       "        0.96212121, 0.96212121, 0.9469697 , 0.96969697, 0.95454545,\n",
       "        0.95454545, 0.96212121, 0.96212121, 0.96212121, 0.96212121,\n",
       "        0.96212121, 0.96212121, 0.95454545, 0.96212121, 0.96212121,\n",
       "        0.96212121, 0.62878788, 0.96969697, 0.96969697, 0.98484848,\n",
       "        0.96212121, 0.62878788, 0.62878788, 0.96212121, 0.62878788,\n",
       "        0.98484848, 0.95454545, 0.96212121, 0.62878788, 0.96969697,\n",
       "        0.96969697, 0.97727273, 0.96212121, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.62878788, 0.95454545, 0.62878788, 0.95454545,\n",
       "        0.97727273, 0.96212121, 0.96212121, 0.96212121, 0.96969697,\n",
       "        0.95454545, 0.96212121, 0.96969697, 0.96212121, 0.95454545,\n",
       "        0.62878788, 0.96212121, 0.96969697, 0.95454545, 0.97727273,\n",
       "        0.62878788, 0.96969697, 0.96212121, 0.98484848, 0.96212121,\n",
       "        0.97727273, 0.96212121, 0.96212121, 0.97727273, 0.95454545,\n",
       "        0.62878788, 0.96212121, 0.97727273, 0.9469697 , 0.96212121,\n",
       "        0.96212121, 0.96969697, 0.96212121, 0.96212121, 0.96212121,\n",
       "        0.96212121, 0.62878788, 0.97727273, 0.62878788, 0.97727273,\n",
       "        0.96969697, 0.62878788, 0.62878788, 0.96212121, 0.96212121,\n",
       "        0.95454545, 0.97727273, 0.97727273, 0.95454545, 0.97727273,\n",
       "        0.96212121, 0.98484848, 0.96212121, 0.95454545, 0.95454545,\n",
       "        0.98484848, 0.96212121, 0.96969697, 0.95454545, 0.96212121,\n",
       "        0.96212121, 0.96212121, 0.62878788, 0.97727273, 0.96212121,\n",
       "        0.96969697, 0.95454545, 0.96212121, 0.62878788, 0.96969697]),\n",
       " 'mean_test_score': array([0.95479228, 0.62563606, 0.95727956, 0.95729855, 0.62563606,\n",
       "        0.95729855, 0.95483026, 0.96233007, 0.9547733 , 0.95980482,\n",
       "        0.95228602, 0.96481735, 0.96736159, 0.95980482, 0.95731754,\n",
       "        0.95729855, 0.95479228, 0.96485532, 0.95479228, 0.96231108,\n",
       "        0.62563606, 0.95479228, 0.95228602, 0.96233007, 0.95980482,\n",
       "        0.95729855, 0.96988684, 0.96234905, 0.96234905, 0.96738057,\n",
       "        0.94977975, 0.95228602, 0.62563606, 0.95733652, 0.95731754,\n",
       "        0.62563606, 0.62563606, 0.95479228, 0.95226703, 0.95978583,\n",
       "        0.62563606, 0.62563606, 0.62563606, 0.95984279, 0.62563606,\n",
       "        0.62563606, 0.95729855, 0.95729855, 0.96736159, 0.62563606,\n",
       "        0.95479228, 0.95226703, 0.62563606, 0.9547733 , 0.95226703,\n",
       "        0.95984279, 0.62563606, 0.95980482, 0.94977975, 0.95980482,\n",
       "        0.95727956, 0.95731754, 0.9673426 , 0.95479228, 0.62563606,\n",
       "        0.96233007, 0.62563606, 0.95479228, 0.62563606, 0.95228602,\n",
       "        0.9547733 , 0.95980482, 0.9547733 , 0.96988684, 0.96485532,\n",
       "        0.62563606, 0.62563606, 0.62563606, 0.95729855, 0.95228602,\n",
       "        0.95984279, 0.62563606, 0.95733652, 0.96231108, 0.96234905,\n",
       "        0.62563606, 0.9547733 , 0.9598238 , 0.95980482, 0.62563606,\n",
       "        0.95980482, 0.95479228, 0.95224804, 0.9598238 , 0.9547733 ,\n",
       "        0.95727956, 0.95980482, 0.95729855, 0.95729855, 0.95980482,\n",
       "        0.95479228, 0.96231108, 0.9547733 , 0.95729855, 0.94977975,\n",
       "        0.94977975, 0.62563606, 0.96233007, 0.9598238 , 0.96487431,\n",
       "        0.95729855, 0.62563606, 0.62563606, 0.95980482, 0.62563606,\n",
       "        0.96988684, 0.94976077, 0.95980482, 0.62563606, 0.9673426 ,\n",
       "        0.9598238 , 0.95733652, 0.95980482, 0.96483633, 0.9598238 ,\n",
       "        0.96233007, 0.62563606, 0.9547733 , 0.62563606, 0.9547733 ,\n",
       "        0.95984279, 0.95228602, 0.95479228, 0.95729855, 0.9598238 ,\n",
       "        0.95727956, 0.95729855, 0.9598238 , 0.95729855, 0.94976077,\n",
       "        0.62563606, 0.95980482, 0.95731754, 0.95978583, 0.95733652,\n",
       "        0.62563606, 0.952305  , 0.95729855, 0.96738057, 0.95479228,\n",
       "        0.95984279, 0.95729855, 0.95980482, 0.95483026, 0.9547733 ,\n",
       "        0.62563606, 0.95980482, 0.96485532, 0.94723551, 0.95729855,\n",
       "        0.94977975, 0.96233007, 0.95228602, 0.96231108, 0.95479228,\n",
       "        0.95228602, 0.62563606, 0.96986785, 0.62563606, 0.97237412,\n",
       "        0.9598238 , 0.62563606, 0.62563606, 0.96231108, 0.95729855,\n",
       "        0.94976077, 0.95984279, 0.95984279, 0.9547733 , 0.96986785,\n",
       "        0.95729855, 0.96738057, 0.95729855, 0.9547733 , 0.95727956,\n",
       "        0.96738057, 0.95729855, 0.95731754, 0.9547733 , 0.95479228,\n",
       "        0.95729855, 0.95729855, 0.62563606, 0.95984279, 0.95980482,\n",
       "        0.952305  , 0.95727956, 0.95729855, 0.62563606, 0.9598238 ]),\n",
       " 'std_test_score': array([0.0105667 , 0.00222867, 0.01546897, 0.01274291, 0.00222867,\n",
       "        0.00702262, 0.02207676, 0.01057989, 0.01841792, 0.01543484,\n",
       "        0.01411093, 0.01546563, 0.01970556, 0.01543484, 0.01270526,\n",
       "        0.00702262, 0.02210288, 0.01768183, 0.02210288, 0.00614054,\n",
       "        0.00222867, 0.0105667 , 0.00927651, 0.01620762, 0.01543484,\n",
       "        0.01873027, 0.01620735, 0.01618984, 0.01618984, 0.01970064,\n",
       "        0.01268678, 0.01411093, 0.00222867, 0.01869436, 0.01270526,\n",
       "        0.00222867, 0.00222867, 0.01619901, 0.01543201, 0.01282512,\n",
       "        0.00222867, 0.00222867, 0.00222867, 0.02477059, 0.00222867,\n",
       "        0.00222867, 0.01274291, 0.01274291, 0.01970556, 0.00222867,\n",
       "        0.01619901, 0.01543201, 0.00222867, 0.0122792 , 0.01543201,\n",
       "        0.01538505, 0.00222867, 0.01543484, 0.01765523, 0.00935314,\n",
       "        0.00940936, 0.01766852, 0.01543771, 0.0105667 , 0.00222867,\n",
       "        0.01620762, 0.00222867, 0.02210288, 0.00222867, 0.01968653,\n",
       "        0.01841792, 0.00935314, 0.01841792, 0.02123957, 0.01768183,\n",
       "        0.00222867, 0.00222867, 0.00222867, 0.01274291, 0.01411093,\n",
       "        0.01538505, 0.00222867, 0.01869436, 0.01841771, 0.01618984,\n",
       "        0.00222867, 0.01841792, 0.01412418, 0.02154909, 0.00222867,\n",
       "        0.01543484, 0.01619901, 0.0128329 , 0.01412418, 0.01841792,\n",
       "        0.00940936, 0.01543484, 0.01274291, 0.01274291, 0.00935314,\n",
       "        0.01619901, 0.01227888, 0.0122792 , 0.01873027, 0.01765523,\n",
       "        0.01765523, 0.00222867, 0.01620762, 0.01412418, 0.01871461,\n",
       "        0.01274291, 0.00222867, 0.00222867, 0.00935314, 0.00222867,\n",
       "        0.02123957, 0.0187254 , 0.01543484, 0.00222867, 0.01543771,\n",
       "        0.01969603, 0.0231931 , 0.00935314, 0.01873517, 0.01412418,\n",
       "        0.01057989, 0.00222867, 0.01841792, 0.00222867, 0.0122792 ,\n",
       "        0.01538505, 0.01411093, 0.02210288, 0.01274291, 0.01412418,\n",
       "        0.01546897, 0.01873027, 0.01412418, 0.01274291, 0.02478826,\n",
       "        0.00222867, 0.00935314, 0.01270526, 0.01282512, 0.01869436,\n",
       "        0.00222867, 0.01966702, 0.01873027, 0.01970064, 0.02210288,\n",
       "        0.01538505, 0.01274291, 0.00935314, 0.02207676, 0.0122792 ,\n",
       "        0.00222867, 0.01543484, 0.01768183, 0.00614195, 0.01873027,\n",
       "        0.01268678, 0.01620762, 0.01968653, 0.01841771, 0.0105667 ,\n",
       "        0.01411093, 0.00222867, 0.01621627, 0.00222867, 0.01275739,\n",
       "        0.01969603, 0.00222867, 0.00222867, 0.01227888, 0.01274291,\n",
       "        0.0187254 , 0.01968382, 0.02477059, 0.01841792, 0.01621627,\n",
       "        0.01873027, 0.01970064, 0.01274291, 0.0122792 , 0.01546897,\n",
       "        0.01970064, 0.01873027, 0.01270526, 0.01841792, 0.02210288,\n",
       "        0.01274291, 0.01873027, 0.00222867, 0.01538505, 0.01543484,\n",
       "        0.01966702, 0.01546897, 0.01274291, 0.00222867, 0.01969603]),\n",
       " 'rank_test_score': array([112, 162, 104,  80, 162,  80, 110,  24, 126,  52, 144,  20,  11,\n",
       "         52,  75,  80, 112,  16, 112,  30, 162, 112, 141,  24,  52,  80,\n",
       "          2,  21,  21,   7, 153, 144, 162,  71,  75, 162, 162, 112, 149,\n",
       "         69, 162, 162, 162,  35, 162, 162,  80,  80,  11, 162, 112, 149,\n",
       "        162, 126, 149,  35, 162,  52, 153,  52, 104,  75,  13, 112, 162,\n",
       "         24, 162, 112, 162, 141, 126,  52, 126,   2,  16, 162, 162, 162,\n",
       "         80, 144,  35, 162,  71,  30,  21, 162, 126,  43,  52, 162,  52,\n",
       "        112, 152,  43, 126, 104,  52,  80,  80,  52, 112,  30, 126,  80,\n",
       "        153, 153, 162,  24,  43,  15,  80, 162, 162,  52, 162,   2, 158,\n",
       "         52, 162,  13,  49,  71,  52,  19,  43,  24, 162, 126, 162, 126,\n",
       "         35, 144, 112,  80,  43, 104,  80,  43,  80, 158, 162,  52,  75,\n",
       "         69,  71, 162, 139,  80,   7, 112,  35,  80,  52, 110, 126, 162,\n",
       "         52,  16, 161,  80, 153,  24, 141,  30, 112, 144, 162,   5, 162,\n",
       "          1,  49, 162, 162,  30,  80, 158,  35,  35, 126,   5,  80,   7,\n",
       "         80, 126, 104,   7,  80,  75, 126, 112,  80,  80, 162,  35,  52,\n",
       "        139, 104,  80, 162,  49], dtype=int32)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_xgb_rcv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "467a7818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035152</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'subsample': 0.7, 'reg_alpha': 1, 'min_child_...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.954792</td>\n",
       "      <td>0.010567</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032504</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'subsample': 0.7, 'reg_alpha': 100, 'min_chil...</td>\n",
       "      <td>0.624060</td>\n",
       "      <td>0.624060</td>\n",
       "      <td>0.628788</td>\n",
       "      <td>0.625636</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032131</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'subsample': 0.7, 'reg_alpha': 0.01, 'min_chi...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048289</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 0.7, 'reg_alpha': 1, 'min_child_...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.957299</td>\n",
       "      <td>0.012743</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.108076</td>\n",
       "      <td>0.022007</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'subsample': 0.6, 'reg_alpha': 100, 'min_chil...</td>\n",
       "      <td>0.624060</td>\n",
       "      <td>0.624060</td>\n",
       "      <td>0.628788</td>\n",
       "      <td>0.625636</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.048316</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'subsample': 0.8, 'reg_alpha': 0.1, 'min_chil...</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.952305</td>\n",
       "      <td>0.019667</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.040317</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'subsample': 0.7, 'reg_alpha': 0.01, 'min_chi...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.051475</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'subsample': 0.8, 'reg_alpha': 1, 'min_child_...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.957299</td>\n",
       "      <td>0.012743</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.032534</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'subsample': 0.9, 'reg_alpha': 100, 'min_chil...</td>\n",
       "      <td>0.624060</td>\n",
       "      <td>0.624060</td>\n",
       "      <td>0.628788</td>\n",
       "      <td>0.625636</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.031518</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'subsample': 0.8, 'reg_alpha': 1e-05, 'min_ch...</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.959824</td>\n",
       "      <td>0.019696</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.035152      0.004702         0.003038        0.000152   \n",
       "1         0.032504      0.001579         0.003025        0.000086   \n",
       "2         0.032131      0.002105         0.003137        0.000128   \n",
       "3         0.048289      0.016044         0.003518        0.000377   \n",
       "4         0.108076      0.022007         0.003796        0.000237   \n",
       "..             ...           ...              ...             ...   \n",
       "195       0.048316      0.002615         0.003617        0.000143   \n",
       "196       0.040317      0.002476         0.003463        0.000192   \n",
       "197       0.051475      0.007410         0.003818        0.000296   \n",
       "198       0.032534      0.000626         0.003147        0.000007   \n",
       "199       0.031518      0.000540         0.003225        0.000011   \n",
       "\n",
       "    param_subsample param_reg_alpha param_min_child_weight param_max_depth  \\\n",
       "0               0.7               1                      3              10   \n",
       "1               0.7             100                      3               6   \n",
       "2               0.7            0.01                      5              10   \n",
       "3               0.7               1                      3               5   \n",
       "4               0.6             100                      1               4   \n",
       "..              ...             ...                    ...             ...   \n",
       "195             0.8             0.1                      1              10   \n",
       "196             0.7            0.01                      5               4   \n",
       "197             0.8               1                      3               6   \n",
       "198             0.9             100                      3               8   \n",
       "199             0.8         0.00001                      5              10   \n",
       "\n",
       "    param_gamma param_colsample_bytree  \\\n",
       "0           0.4                    0.7   \n",
       "1           0.1                    0.9   \n",
       "2           0.1                    0.6   \n",
       "3           0.2                    0.8   \n",
       "4           0.3                    0.6   \n",
       "..          ...                    ...   \n",
       "195         0.3                    0.9   \n",
       "196         0.0                    0.6   \n",
       "197         0.1                    0.6   \n",
       "198         0.1                    0.6   \n",
       "199         0.3                    0.6   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'subsample': 0.7, 'reg_alpha': 1, 'min_child_...           0.939850   \n",
       "1    {'subsample': 0.7, 'reg_alpha': 100, 'min_chil...           0.624060   \n",
       "2    {'subsample': 0.7, 'reg_alpha': 0.01, 'min_chi...           0.939850   \n",
       "3    {'subsample': 0.7, 'reg_alpha': 1, 'min_child_...           0.939850   \n",
       "4    {'subsample': 0.6, 'reg_alpha': 100, 'min_chil...           0.624060   \n",
       "..                                                 ...                ...   \n",
       "195  {'subsample': 0.8, 'reg_alpha': 0.1, 'min_chil...           0.924812   \n",
       "196  {'subsample': 0.7, 'reg_alpha': 0.01, 'min_chi...           0.939850   \n",
       "197  {'subsample': 0.8, 'reg_alpha': 1, 'min_child_...           0.939850   \n",
       "198  {'subsample': 0.9, 'reg_alpha': 100, 'min_chil...           0.624060   \n",
       "199  {'subsample': 0.8, 'reg_alpha': 1e-05, 'min_ch...           0.932331   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.962406           0.962121         0.954792        0.010567   \n",
       "1             0.624060           0.628788         0.625636        0.002229   \n",
       "2             0.977444           0.954545         0.957280        0.015469   \n",
       "3             0.969925           0.962121         0.957299        0.012743   \n",
       "4             0.624060           0.628788         0.625636        0.002229   \n",
       "..                 ...                ...              ...             ...   \n",
       "195           0.962406           0.969697         0.952305        0.019667   \n",
       "196           0.977444           0.954545         0.957280        0.015469   \n",
       "197           0.969925           0.962121         0.957299        0.012743   \n",
       "198           0.624060           0.628788         0.625636        0.002229   \n",
       "199           0.977444           0.969697         0.959824        0.019696   \n",
       "\n",
       "     rank_test_score  \n",
       "0                112  \n",
       "1                162  \n",
       "2                104  \n",
       "3                 80  \n",
       "4                162  \n",
       "..               ...  \n",
       "195              139  \n",
       "196              104  \n",
       "197               80  \n",
       "198              162  \n",
       "199               49  \n",
       "\n",
       "[200 rows x 17 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_result = pd.DataFrame(p_xgb_rcv.cv_results_)\n",
    "tuning_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eadf7b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.6,\n",
       " 'reg_alpha': 0.01,\n",
       " 'min_child_weight': 1,\n",
       " 'max_depth': 10,\n",
       " 'gamma': 0.0,\n",
       " 'colsample_bytree': 0.8}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = p_xgb_rcv.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78a7c91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9723741171109591"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_xgb_rcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a0f13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "thebest_clf = p_xgb_rcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7146345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thebest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c306f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415204678362573"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu_ac = thebest_clf.score(X_test, y_test)\n",
    "tu_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd9756e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score Before Tuning 0.9415204678362573\n",
      "Accuracy Score After Tuning 0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score Before Tuning', xgb_acc)\n",
    "print('Accuracy Score After Tuning', tu_ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21620127",
   "metadata": {},
   "source": [
    "# Hyperperameter Tuning using perameter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bd0b6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3], 'max_depth': [3, 4, 5, 6, 8, 10, 12, 15], 'min_child_weight': [1, 3, 5, 7], 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4], 'colsample_bytree': [0.3, 0.4, 0.5, 0.7]}\n"
     ]
    }
   ],
   "source": [
    "param2 = {\"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] }\n",
    "\n",
    "print(param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85ef139c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=200,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        &#x27;gamma&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 3, 5, 7]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=200,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        &#x27;gamma&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 3, 5, 7]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=200,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        'min_child_weight': [1, 3, 5, 7]})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_xgb_clf = XGBClassifier()\n",
    "p2_xgb_rcv = RandomizedSearchCV(p_xgb_clf, param2, n_iter=200, cv=3)\n",
    "p2_xgb_rcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "445f7d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03773967, 0.03018554, 0.03453398, 0.03129061, 0.03067946,\n",
       "        0.02741273, 0.02770861, 0.03069067, 0.02743093, 0.03580729,\n",
       "        0.04369799, 0.03652374, 0.02704231, 0.02781574, 0.03074805,\n",
       "        0.0272367 , 0.03196144, 0.02994641, 0.02734828, 0.0296677 ,\n",
       "        0.04173923, 0.029133  , 0.02640827, 0.02792621, 0.03142126,\n",
       "        0.03102001, 0.02732674, 0.03814665, 0.04322537, 0.0326457 ,\n",
       "        0.02575429, 0.03181831, 0.03155796, 0.03496663, 0.02936117,\n",
       "        0.03114597, 0.03365231, 0.03370229, 0.03263895, 0.034916  ,\n",
       "        0.02923497, 0.03832825, 0.03429405, 0.03067406, 0.02678386,\n",
       "        0.03287331, 0.03749164, 0.03077133, 0.02627309, 0.04186869,\n",
       "        0.03571447, 0.03004511, 0.03266637, 0.03002898, 0.03049262,\n",
       "        0.03229213, 0.0434409 , 0.03707457, 0.03708299, 0.0355107 ,\n",
       "        0.03233933, 0.03099346, 0.0287923 , 0.03139981, 0.03415624,\n",
       "        0.02878308, 0.02757208, 0.02964727, 0.03584774, 0.04260238,\n",
       "        0.02868438, 0.0283064 , 0.03454924, 0.02910837, 0.03444354,\n",
       "        0.03544656, 0.03128004, 0.02969575, 0.02959228, 0.02856406,\n",
       "        0.03153539, 0.03116735, 0.03722636, 0.04143961, 0.06281503,\n",
       "        0.04469419, 0.03623319, 0.02995006, 0.042075  , 0.03835829,\n",
       "        0.03030173, 0.03158768, 0.03018856, 0.02988458, 0.03201858,\n",
       "        0.02981559, 0.03032621, 0.03466201, 0.03388556, 0.03186695,\n",
       "        0.03424462, 0.03260454, 0.02967175, 0.03603013, 0.03667434,\n",
       "        0.04170998, 0.06824835, 0.05920601, 0.05825869, 0.06410734,\n",
       "        0.06412411, 0.05788469, 0.02978897, 0.03517691, 0.02950168,\n",
       "        0.03352038, 0.03233703, 0.02919706, 0.03721237, 0.03842934,\n",
       "        0.04153403, 0.03539276, 0.03350298, 0.03527999, 0.02995737,\n",
       "        0.03010209, 0.0350279 , 0.03229594, 0.03309576, 0.03426814,\n",
       "        0.02821867, 0.03091431, 0.03089436, 0.02980963, 0.03622063,\n",
       "        0.02837261, 0.03243176, 0.03090755, 0.03583415, 0.03022401,\n",
       "        0.028555  , 0.03404363, 0.03588231, 0.03715158, 0.02920143,\n",
       "        0.03276587, 0.02880335, 0.02857931, 0.034271  , 0.02825244,\n",
       "        0.02999401, 0.034319  , 0.03281768, 0.02964425, 0.03769477,\n",
       "        0.02955778, 0.03930585, 0.02820865, 0.03115225, 0.02845502,\n",
       "        0.03224222, 0.02896571, 0.02964258, 0.02902571, 0.03582366,\n",
       "        0.0286874 , 0.02867095, 0.03021479, 0.03183071, 0.03125421,\n",
       "        0.0286022 , 0.03525837, 0.03563205, 0.03475881, 0.02929759,\n",
       "        0.02967103, 0.02902436, 0.02992026, 0.03280028, 0.03053705,\n",
       "        0.02981631, 0.04131651, 0.03056399, 0.03775334, 0.03755562,\n",
       "        0.02937833, 0.03385957, 0.03408607, 0.03008358, 0.03078604,\n",
       "        0.03924298, 0.04414892, 0.03031667, 0.03053236, 0.02982052,\n",
       "        0.03737036, 0.03524804, 0.03143835, 0.03063711, 0.03199999]),\n",
       " 'std_fit_time': array([7.18371598e-03, 7.55790188e-04, 1.19838338e-03, 1.19315358e-03,\n",
       "        7.57671663e-04, 8.54944432e-04, 8.87508612e-04, 1.98235550e-04,\n",
       "        6.88454783e-04, 1.09876728e-02, 1.58863876e-02, 5.80192297e-03,\n",
       "        5.17108640e-04, 9.58684760e-04, 6.99816117e-04, 7.97385250e-04,\n",
       "        7.84043138e-04, 6.50643220e-04, 1.28202139e-03, 2.38941916e-04,\n",
       "        7.54270049e-04, 5.46171549e-04, 5.55260861e-04, 1.25985965e-03,\n",
       "        5.70556278e-04, 5.97153917e-04, 5.13534261e-04, 5.97390043e-03,\n",
       "        1.45047313e-03, 2.86404534e-03, 6.73701140e-05, 3.47910330e-03,\n",
       "        3.36786541e-03, 3.01619694e-03, 1.23926656e-04, 7.87746298e-04,\n",
       "        1.23871570e-03, 1.36251238e-03, 5.41944270e-04, 9.55634831e-04,\n",
       "        2.08375152e-03, 2.16196212e-04, 1.44026231e-03, 6.12661353e-04,\n",
       "        1.42808461e-04, 2.02896697e-03, 8.54247178e-04, 1.46965230e-03,\n",
       "        2.95551242e-04, 3.02449454e-03, 4.11282749e-03, 9.07641470e-04,\n",
       "        1.69717318e-03, 1.82733321e-03, 5.92175641e-04, 1.73208431e-04,\n",
       "        2.83507384e-03, 5.41607523e-03, 3.76685980e-04, 4.86437543e-03,\n",
       "        5.40904065e-04, 5.77095639e-04, 6.60114710e-04, 4.34017243e-03,\n",
       "        1.58920920e-03, 1.15070698e-03, 1.85772225e-04, 6.68692509e-04,\n",
       "        3.75324491e-03, 9.58899732e-04, 4.20760408e-04, 2.68339049e-04,\n",
       "        1.49788291e-03, 5.47978098e-04, 8.95559222e-04, 8.57456995e-04,\n",
       "        6.21588131e-04, 1.29396216e-04, 1.95541901e-04, 1.30010555e-04,\n",
       "        9.99452409e-04, 2.40382398e-04, 1.49043261e-03, 1.41187989e-02,\n",
       "        1.06076537e-02, 3.61613618e-03, 2.17962399e-04, 1.99345720e-04,\n",
       "        1.12015623e-03, 3.96563868e-04, 1.50125515e-04, 6.33425993e-04,\n",
       "        1.03996426e-03, 1.69280661e-04, 5.54802179e-04, 8.42823072e-05,\n",
       "        2.32652667e-04, 7.93945467e-04, 1.58003747e-03, 1.45383120e-03,\n",
       "        1.18030392e-03, 7.80846783e-04, 4.77672098e-04, 3.09941537e-03,\n",
       "        2.27850438e-03, 1.29235697e-02, 7.22900527e-03, 7.41666845e-04,\n",
       "        8.75996762e-04, 8.99431771e-04, 6.27694979e-04, 2.37950056e-03,\n",
       "        2.78558280e-04, 7.36012360e-04, 6.61965510e-05, 5.13694258e-04,\n",
       "        4.09816379e-04, 3.88546428e-04, 1.67187169e-03, 1.18018666e-03,\n",
       "        1.24180984e-03, 1.27158766e-03, 1.00955442e-03, 1.28788210e-03,\n",
       "        9.33007386e-04, 2.14720990e-04, 1.02108325e-03, 5.90236673e-04,\n",
       "        6.48713846e-04, 8.48933358e-04, 1.59930398e-04, 1.87508057e-03,\n",
       "        1.39141204e-04, 5.60440939e-04, 1.51990392e-03, 2.59503434e-04,\n",
       "        4.25780353e-04, 3.71911807e-04, 8.33472828e-04, 2.49764853e-04,\n",
       "        4.72884218e-05, 2.35341017e-03, 7.86027700e-04, 2.72318249e-03,\n",
       "        1.86949189e-04, 2.88662646e-04, 1.02769378e-04, 9.80130115e-05,\n",
       "        4.92640443e-04, 3.76485828e-04, 9.79475291e-04, 1.22915034e-03,\n",
       "        7.57500547e-04, 2.21525204e-04, 1.07875918e-03, 3.60278497e-04,\n",
       "        5.61546240e-04, 9.93610362e-05, 3.44517789e-04, 2.15437628e-04,\n",
       "        2.43836851e-04, 6.77771731e-04, 9.71684408e-04, 6.42132021e-04,\n",
       "        4.20916791e-04, 3.63357337e-04, 3.74101484e-04, 5.92079824e-04,\n",
       "        1.14874374e-03, 9.45321806e-04, 1.42012285e-04, 3.30119284e-03,\n",
       "        4.22938267e-04, 2.25970652e-03, 5.81646870e-05, 5.61711384e-04,\n",
       "        1.24461501e-04, 8.15867526e-04, 2.55165237e-04, 7.47733205e-04,\n",
       "        8.18432245e-04, 1.69259497e-03, 1.79651454e-04, 6.47569469e-04,\n",
       "        2.80353828e-03, 6.26311686e-05, 3.05946708e-04, 3.22389196e-04,\n",
       "        2.51668877e-04, 1.85195842e-04, 7.35858122e-03, 2.55150375e-03,\n",
       "        2.19082445e-04, 2.93593676e-04, 1.70016837e-04, 3.92474028e-04,\n",
       "        4.54634203e-04, 4.27605743e-04, 2.08214403e-04, 3.19503511e-04]),\n",
       " 'mean_score_time': array([0.00302776, 0.00290775, 0.00297729, 0.00303332, 0.00301226,\n",
       "        0.00299668, 0.00291793, 0.00290664, 0.00285673, 0.00296903,\n",
       "        0.004035  , 0.00308951, 0.00300574, 0.00292238, 0.00292468,\n",
       "        0.0029517 , 0.00291618, 0.00296068, 0.00292905, 0.00295536,\n",
       "        0.00300241, 0.0029823 , 0.00290036, 0.00291427, 0.0028851 ,\n",
       "        0.00284791, 0.00298071, 0.00336734, 0.00316858, 0.00308132,\n",
       "        0.00279498, 0.00292095, 0.00303372, 0.00306519, 0.00307091,\n",
       "        0.00286357, 0.00295599, 0.00289901, 0.0029246 , 0.00295734,\n",
       "        0.0028681 , 0.00292842, 0.00289464, 0.00285896, 0.00280404,\n",
       "        0.00334175, 0.0030396 , 0.0029583 , 0.00278592, 0.00295027,\n",
       "        0.00302394, 0.00303094, 0.00303133, 0.00293358, 0.00294574,\n",
       "        0.00304921, 0.00295107, 0.00321706, 0.00314927, 0.00302569,\n",
       "        0.00288701, 0.00281358, 0.00284759, 0.00289933, 0.00291944,\n",
       "        0.00288645, 0.00280007, 0.00285904, 0.00291141, 0.00293732,\n",
       "        0.00301234, 0.00293763, 0.00299414, 0.00298039, 0.00310238,\n",
       "        0.00308998, 0.00307306, 0.00309102, 0.00302664, 0.00306384,\n",
       "        0.00305192, 0.00306066, 0.00316803, 0.00509834, 0.00334565,\n",
       "        0.00330114, 0.00328843, 0.00318503, 0.00334668, 0.00324639,\n",
       "        0.00317891, 0.00320713, 0.00312169, 0.00322549, 0.00313807,\n",
       "        0.00316501, 0.00314291, 0.00324575, 0.00319878, 0.00318766,\n",
       "        0.00321333, 0.00320474, 0.00317264, 0.00326022, 0.00324527,\n",
       "        0.00356555, 0.00342067, 0.00340048, 0.00341566, 0.00354997,\n",
       "        0.0034279 , 0.00375128, 0.00321436, 0.00319942, 0.003112  ,\n",
       "        0.00324297, 0.0031596 , 0.00317939, 0.00333595, 0.0033133 ,\n",
       "        0.00323002, 0.00318464, 0.00317001, 0.00310405, 0.00311502,\n",
       "        0.00311406, 0.00314713, 0.00307973, 0.00311319, 0.00308633,\n",
       "        0.00301298, 0.00310175, 0.00312376, 0.00305597, 0.00334573,\n",
       "        0.00307163, 0.00306567, 0.00306503, 0.0031085 , 0.00306304,\n",
       "        0.00312201, 0.00319219, 0.00315785, 0.00316644, 0.00317709,\n",
       "        0.00313528, 0.00309292, 0.00314331, 0.00310802, 0.00306137,\n",
       "        0.00307139, 0.0030729 , 0.00309102, 0.00303451, 0.0031174 ,\n",
       "        0.00305136, 0.00311812, 0.00302617, 0.0030187 , 0.00309189,\n",
       "        0.00310127, 0.00314236, 0.00307361, 0.00306575, 0.00309753,\n",
       "        0.00305319, 0.00309944, 0.00303555, 0.003045  , 0.00309507,\n",
       "        0.00306606, 0.0030907 , 0.00313958, 0.00320864, 0.00301178,\n",
       "        0.00305247, 0.00308434, 0.00300805, 0.00311708, 0.00302831,\n",
       "        0.00304166, 0.00327206, 0.00314538, 0.00318623, 0.00321531,\n",
       "        0.00311367, 0.00314641, 0.00317828, 0.0031325 , 0.0032413 ,\n",
       "        0.00326363, 0.00333134, 0.00314387, 0.00311573, 0.00316628,\n",
       "        0.0033164 , 0.00322   , 0.00320832, 0.00316819, 0.00317502]),\n",
       " 'std_score_time': array([5.80379363e-05, 5.75661153e-05, 8.17979210e-05, 3.18960538e-05,\n",
       "        2.04866389e-04, 8.50990691e-06, 8.34947023e-05, 5.51753457e-05,\n",
       "        3.37197266e-05, 1.95395335e-04, 1.54254139e-03, 1.52105614e-04,\n",
       "        1.72742885e-04, 5.29276119e-05, 5.48189938e-06, 2.63639159e-05,\n",
       "        5.51162474e-05, 6.86457838e-05, 9.03203369e-05, 3.31675198e-05,\n",
       "        7.29521894e-05, 1.74174341e-05, 7.54114109e-05, 5.69047874e-05,\n",
       "        1.79569977e-05, 1.67550201e-05, 2.23120305e-04, 9.06526535e-05,\n",
       "        1.98716510e-04, 2.04762930e-04, 1.63879897e-05, 9.56232560e-05,\n",
       "        1.60733068e-04, 1.13429851e-04, 1.67112358e-05, 7.37260600e-05,\n",
       "        5.82058270e-05, 8.77009563e-05, 1.66692651e-04, 6.16857873e-05,\n",
       "        3.62528671e-05, 9.53939189e-06, 4.82395676e-05, 1.98067669e-05,\n",
       "        1.17979060e-05, 6.45139509e-04, 1.37555055e-04, 3.91514959e-05,\n",
       "        1.52898016e-05, 1.95496774e-05, 1.75526853e-04, 9.87057397e-05,\n",
       "        1.79551651e-04, 1.09186744e-04, 5.24800159e-05, 6.69505898e-05,\n",
       "        3.56047281e-05, 2.75450295e-04, 2.44584695e-04, 1.04305941e-04,\n",
       "        2.19923101e-05, 8.57202384e-06, 5.52806723e-05, 2.61416184e-06,\n",
       "        5.10063475e-05, 6.00566678e-05, 1.47130001e-05, 6.38146774e-05,\n",
       "        1.24288032e-05, 2.78395594e-05, 1.57298734e-04, 4.34878509e-05,\n",
       "        4.25492377e-05, 5.00165333e-05, 6.56378468e-05, 2.45785799e-05,\n",
       "        7.20495879e-05, 7.79796026e-05, 1.23630756e-05, 1.69889852e-05,\n",
       "        6.35683529e-06, 4.42587488e-05, 5.23748455e-05, 2.66560494e-03,\n",
       "        5.81305806e-05, 5.36376455e-05, 7.78840513e-05, 1.31122994e-05,\n",
       "        8.35223081e-05, 9.19758877e-06, 5.77774796e-05, 5.29326236e-05,\n",
       "        2.75696379e-05, 3.91318099e-05, 1.37057853e-05, 4.28229680e-05,\n",
       "        1.67112358e-05, 9.99115775e-05, 5.46945362e-05, 2.46629779e-05,\n",
       "        1.74206974e-05, 6.16056672e-05, 1.16941984e-04, 2.95910232e-05,\n",
       "        1.57937188e-05, 2.81300246e-04, 4.28978272e-05, 1.94437461e-05,\n",
       "        4.96190758e-05, 1.50617319e-04, 4.96911960e-05, 3.69495624e-04,\n",
       "        3.67798815e-05, 2.39499608e-05, 8.77806426e-07, 9.15144387e-05,\n",
       "        1.96694926e-05, 8.29898358e-05, 4.75679423e-05, 8.60029276e-05,\n",
       "        8.11675112e-05, 1.98564495e-05, 5.95009219e-05, 3.86533964e-05,\n",
       "        9.57672032e-05, 4.56496700e-05, 4.04370843e-05, 1.11188183e-05,\n",
       "        4.37913486e-05, 2.27495139e-05, 1.61296625e-05, 7.60577274e-05,\n",
       "        1.54708491e-04, 3.36197438e-05, 3.14947303e-04, 2.10604578e-05,\n",
       "        2.11502351e-05, 2.56077783e-05, 4.07916468e-05, 5.51049015e-05,\n",
       "        8.07715637e-05, 1.61327126e-04, 6.52126026e-05, 2.55571669e-05,\n",
       "        4.76838483e-05, 4.50513690e-05, 2.28130024e-06, 8.08017413e-05,\n",
       "        4.43744738e-05, 2.13375378e-05, 5.13784509e-05, 6.22698130e-05,\n",
       "        2.73855218e-05, 9.74377449e-06, 1.65483029e-05, 9.36903787e-06,\n",
       "        2.89331421e-05, 2.05891465e-05, 3.23601930e-06, 2.65672433e-05,\n",
       "        3.68726664e-05, 7.95977723e-05, 5.53536312e-05, 2.45754961e-05,\n",
       "        1.01227336e-05, 2.80835092e-05, 4.04782979e-05, 1.17011473e-05,\n",
       "        3.26028629e-05, 2.82210352e-05, 2.62397672e-05, 6.23038836e-06,\n",
       "        6.48715686e-05, 1.41633078e-04, 8.64539067e-06, 3.35829023e-05,\n",
       "        9.31937804e-05, 1.12391596e-07, 2.18418833e-05, 1.64541450e-05,\n",
       "        3.03247023e-05, 1.00770897e-04, 1.45862470e-05, 2.19836928e-05,\n",
       "        2.10484585e-05, 3.59974334e-05, 9.44290085e-06, 2.55988977e-05,\n",
       "        2.48049551e-05, 5.42872351e-05, 1.11478697e-04, 5.72543353e-05,\n",
       "        1.96694926e-05, 2.73571396e-05, 6.11859477e-05, 1.62486533e-05,\n",
       "        4.05962428e-05, 3.49808799e-05, 2.77784646e-05, 5.08858459e-05]),\n",
       " 'param_min_child_weight': masked_array(data=[1, 3, 1, 3, 1, 5, 3, 5, 3, 5, 5, 1, 7, 3, 1, 7, 1, 3,\n",
       "                    5, 1, 1, 5, 7, 5, 1, 1, 3, 3, 1, 3, 7, 3, 5, 3, 5, 5,\n",
       "                    3, 3, 3, 5, 5, 1, 1, 1, 7, 3, 1, 7, 5, 1, 7, 5, 3, 3,\n",
       "                    1, 7, 1, 5, 7, 5, 3, 1, 3, 5, 1, 5, 5, 1, 3, 1, 7, 5,\n",
       "                    3, 5, 1, 3, 3, 5, 5, 7, 3, 7, 1, 5, 1, 1, 1, 5, 1, 1,\n",
       "                    7, 7, 3, 5, 3, 5, 5, 1, 7, 3, 1, 1, 5, 7, 1, 5, 3, 7,\n",
       "                    7, 7, 7, 7, 7, 1, 5, 1, 3, 7, 3, 1, 1, 1, 3, 1, 7, 7,\n",
       "                    3, 1, 7, 1, 7, 7, 7, 7, 3, 7, 1, 5, 3, 5, 5, 3, 1, 1,\n",
       "                    7, 5, 7, 7, 1, 5, 3, 7, 3, 3, 1, 5, 1, 7, 3, 7, 5, 5,\n",
       "                    3, 7, 5, 5, 7, 3, 3, 5, 7, 1, 3, 5, 5, 3, 7, 3, 1, 3,\n",
       "                    3, 1, 5, 1, 1, 7, 1, 1, 5, 7, 3, 1, 7, 7, 7, 3, 1, 5,\n",
       "                    7, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[10, 5, 10, 15, 12, 8, 15, 5, 6, 12, 5, 3, 15, 10, 4, 8,\n",
       "                    15, 3, 4, 3, 6, 5, 5, 3, 8, 5, 5, 8, 5, 5, 8, 12, 12,\n",
       "                    8, 3, 5, 8, 3, 3, 3, 6, 8, 12, 8, 4, 12, 5, 3, 6, 6,\n",
       "                    15, 8, 10, 12, 12, 4, 3, 12, 3, 10, 12, 4, 12, 8, 5,\n",
       "                    10, 4, 3, 6, 8, 6, 10, 4, 10, 10, 6, 6, 8, 5, 3, 10, 4,\n",
       "                    15, 15, 5, 8, 4, 4, 8, 4, 8, 4, 10, 3, 3, 10, 3, 8, 5,\n",
       "                    3, 6, 10, 6, 8, 6, 5, 4, 10, 8, 15, 15, 3, 5, 5, 8, 12,\n",
       "                    10, 4, 4, 4, 10, 12, 6, 5, 10, 8, 6, 10, 8, 10, 8, 15,\n",
       "                    12, 3, 5, 15, 6, 12, 10, 12, 12, 10, 3, 6, 15, 6, 6, 6,\n",
       "                    5, 3, 12, 3, 6, 8, 12, 15, 4, 10, 3, 15, 10, 10, 4, 15,\n",
       "                    8, 5, 8, 10, 5, 10, 15, 12, 10, 6, 12, 3, 4, 6, 6, 12,\n",
       "                    15, 15, 5, 5, 10, 8, 4, 15, 4, 4, 5, 8, 5, 6, 10, 4,\n",
       "                    10, 10, 10, 12],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.2, 0.1, 0.1, 0.1, 0.3, 0.3, 0.25, 0.05, 0.25, 0.1,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.2, 0.2, 0.15, 0.3, 0.25,\n",
       "                    0.05, 0.1, 0.3, 0.2, 0.3, 0.25, 0.3, 0.15, 0.15, 0.2,\n",
       "                    0.3, 0.2, 0.3, 0.3, 0.3, 0.2, 0.15, 0.2, 0.25, 0.05,\n",
       "                    0.3, 0.05, 0.25, 0.25, 0.3, 0.1, 0.15, 0.1, 0.25, 0.15,\n",
       "                    0.1, 0.3, 0.3, 0.3, 0.3, 0.1, 0.05, 0.3, 0.15, 0.05,\n",
       "                    0.05, 0.2, 0.3, 0.15, 0.25, 0.2, 0.15, 0.25, 0.05,\n",
       "                    0.05, 0.15, 0.25, 0.05, 0.25, 0.25, 0.05, 0.2, 0.15,\n",
       "                    0.25, 0.2, 0.25, 0.1, 0.15, 0.25, 0.1, 0.1, 0.15, 0.25,\n",
       "                    0.05, 0.1, 0.15, 0.1, 0.3, 0.25, 0.15, 0.25, 0.3, 0.2,\n",
       "                    0.05, 0.2, 0.3, 0.3, 0.2, 0.1, 0.3, 0.25, 0.3, 0.25,\n",
       "                    0.3, 0.2, 0.15, 0.25, 0.2, 0.2, 0.25, 0.25, 0.2, 0.3,\n",
       "                    0.05, 0.1, 0.1, 0.3, 0.1, 0.15, 0.3, 0.1, 0.1, 0.25,\n",
       "                    0.05, 0.3, 0.2, 0.2, 0.1, 0.1, 0.05, 0.3, 0.25, 0.1,\n",
       "                    0.05, 0.2, 0.3, 0.2, 0.1, 0.2, 0.15, 0.1, 0.25, 0.3,\n",
       "                    0.15, 0.3, 0.3, 0.05, 0.1, 0.25, 0.2, 0.15, 0.15, 0.3,\n",
       "                    0.2, 0.3, 0.1, 0.3, 0.3, 0.3, 0.05, 0.25, 0.2, 0.2,\n",
       "                    0.2, 0.1, 0.2, 0.3, 0.05, 0.05, 0.3, 0.25, 0.3, 0.25,\n",
       "                    0.3, 0.2, 0.3, 0.1, 0.15, 0.1, 0.15, 0.2, 0.2, 0.25,\n",
       "                    0.2, 0.1, 0.1, 0.05, 0.1, 0.2, 0.3, 0.05, 0.3, 0.15,\n",
       "                    0.2, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.2, 0.3, 0.3, 0.4, 0.3, 0.4, 0.2, 0.4, 0.1, 0.0, 0.1,\n",
       "                    0.1, 0.1, 0.4, 0.3, 0.0, 0.3, 0.2, 0.2, 0.2, 0.1, 0.2,\n",
       "                    0.0, 0.2, 0.1, 0.4, 0.4, 0.4, 0.4, 0.2, 0.3, 0.4, 0.3,\n",
       "                    0.4, 0.2, 0.3, 0.0, 0.4, 0.2, 0.2, 0.1, 0.1, 0.4, 0.2,\n",
       "                    0.0, 0.0, 0.2, 0.4, 0.3, 0.4, 0.1, 0.3, 0.0, 0.0, 0.0,\n",
       "                    0.4, 0.1, 0.2, 0.4, 0.1, 0.4, 0.2, 0.2, 0.2, 0.0, 0.2,\n",
       "                    0.1, 0.0, 0.0, 0.2, 0.3, 0.1, 0.2, 0.0, 0.1, 0.3, 0.0,\n",
       "                    0.3, 0.4, 0.0, 0.1, 0.0, 0.4, 0.4, 0.4, 0.4, 0.0, 0.4,\n",
       "                    0.3, 0.3, 0.4, 0.2, 0.3, 0.1, 0.0, 0.0, 0.4, 0.1, 0.3,\n",
       "                    0.0, 0.3, 0.0, 0.4, 0.1, 0.0, 0.1, 0.3, 0.2, 0.0, 0.1,\n",
       "                    0.1, 0.2, 0.4, 0.2, 0.3, 0.0, 0.1, 0.0, 0.1, 0.2, 0.3,\n",
       "                    0.0, 0.4, 0.0, 0.1, 0.3, 0.2, 0.0, 0.2, 0.3, 0.2, 0.2,\n",
       "                    0.1, 0.2, 0.4, 0.2, 0.2, 0.2, 0.1, 0.2, 0.2, 0.0, 0.2,\n",
       "                    0.4, 0.3, 0.2, 0.4, 0.2, 0.0, 0.3, 0.4, 0.0, 0.3, 0.0,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.1, 0.0, 0.1, 0.1, 0.2, 0.3, 0.3,\n",
       "                    0.4, 0.1, 0.1, 0.3, 0.3, 0.4, 0.1, 0.2, 0.0, 0.0, 0.0,\n",
       "                    0.2, 0.3, 0.2, 0.2, 0.2, 0.3, 0.2, 0.0, 0.1, 0.4, 0.1,\n",
       "                    0.1, 0.0, 0.1, 0.2, 0.1, 0.2, 0.0, 0.4, 0.0, 0.4, 0.0,\n",
       "                    0.4, 0.3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_colsample_bytree': masked_array(data=[0.5, 0.4, 0.5, 0.5, 0.3, 0.5, 0.5, 0.5, 0.4, 0.4, 0.5,\n",
       "                    0.5, 0.7, 0.5, 0.4, 0.5, 0.4, 0.7, 0.3, 0.3, 0.7, 0.5,\n",
       "                    0.4, 0.4, 0.7, 0.3, 0.3, 0.3, 0.5, 0.4, 0.3, 0.5, 0.7,\n",
       "                    0.7, 0.3, 0.5, 0.5, 0.7, 0.4, 0.5, 0.4, 0.5, 0.7, 0.4,\n",
       "                    0.7, 0.4, 0.5, 0.5, 0.3, 0.7, 0.4, 0.3, 0.4, 0.5, 0.4,\n",
       "                    0.3, 0.7, 0.7, 0.5, 0.3, 0.3, 0.5, 0.7, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.3, 0.5, 0.7, 0.7, 0.7, 0.5, 0.7, 0.7, 0.4, 0.7,\n",
       "                    0.5, 0.7, 0.3, 0.7, 0.7, 0.5, 0.7, 0.5, 0.7, 0.4, 0.3,\n",
       "                    0.4, 0.5, 0.5, 0.5, 0.3, 0.4, 0.4, 0.3, 0.7, 0.3, 0.5,\n",
       "                    0.5, 0.3, 0.3, 0.3, 0.7, 0.7, 0.7, 0.5, 0.3, 0.4, 0.7,\n",
       "                    0.7, 0.4, 0.3, 0.5, 0.3, 0.5, 0.7, 0.4, 0.3, 0.5, 0.7,\n",
       "                    0.7, 0.3, 0.5, 0.7, 0.4, 0.7, 0.3, 0.5, 0.5, 0.3, 0.5,\n",
       "                    0.7, 0.5, 0.4, 0.5, 0.3, 0.5, 0.5, 0.7, 0.3, 0.7, 0.4,\n",
       "                    0.4, 0.4, 0.7, 0.3, 0.3, 0.3, 0.3, 0.5, 0.7, 0.4, 0.3,\n",
       "                    0.7, 0.4, 0.7, 0.3, 0.7, 0.5, 0.7, 0.4, 0.3, 0.5, 0.7,\n",
       "                    0.3, 0.3, 0.5, 0.7, 0.4, 0.3, 0.5, 0.5, 0.4, 0.7, 0.5,\n",
       "                    0.7, 0.4, 0.3, 0.4, 0.3, 0.7, 0.3, 0.4, 0.5, 0.5, 0.3,\n",
       "                    0.4, 0.3, 0.4, 0.3, 0.3, 0.3, 0.7, 0.7, 0.4, 0.4, 0.5,\n",
       "                    0.7, 0.4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 15,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.3},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 3,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 1,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.4},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 0.0,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'min_child_weight': 7,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0.4,\n",
       "   'colsample_bytree': 0.7},\n",
       "  {'min_child_weight': 5,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.3,\n",
       "   'colsample_bytree': 0.4}],\n",
       " 'split0_test_score': array([0.93984962, 0.94736842, 0.93984962, 0.93984962, 0.93984962,\n",
       "        0.93233083, 0.95488722, 0.93984962, 0.93984962, 0.93984962,\n",
       "        0.93233083, 0.93233083, 0.92481203, 0.93984962, 0.92481203,\n",
       "        0.92481203, 0.93984962, 0.93984962, 0.93984962, 0.93233083,\n",
       "        0.93233083, 0.93984962, 0.93984962, 0.93233083, 0.93233083,\n",
       "        0.93984962, 0.95488722, 0.93984962, 0.93984962, 0.93984962,\n",
       "        0.92481203, 0.93984962, 0.93233083, 0.93233083, 0.93984962,\n",
       "        0.94736842, 0.93984962, 0.93233083, 0.93984962, 0.94736842,\n",
       "        0.93233083, 0.93984962, 0.93233083, 0.93984962, 0.92481203,\n",
       "        0.95488722, 0.93984962, 0.92481203, 0.93233083, 0.92481203,\n",
       "        0.91729323, 0.93984962, 0.95488722, 0.93984962, 0.92481203,\n",
       "        0.93233083, 0.93984962, 0.93233083, 0.91729323, 0.94736842,\n",
       "        0.92481203, 0.93984962, 0.92481203, 0.93233083, 0.93984962,\n",
       "        0.94736842, 0.93984962, 0.93984962, 0.93984962, 0.94736842,\n",
       "        0.92481203, 0.94736842, 0.94736842, 0.93984962, 0.93233083,\n",
       "        0.94736842, 0.93984962, 0.93233083, 0.94736842, 0.91729323,\n",
       "        0.93984962, 0.93233083, 0.93984962, 0.94736842, 0.93984962,\n",
       "        0.93984962, 0.93984962, 0.92481203, 0.94736842, 0.93984962,\n",
       "        0.91729323, 0.92481203, 0.95488722, 0.93984962, 0.93984962,\n",
       "        0.93233083, 0.93233083, 0.93984962, 0.93233083, 0.94736842,\n",
       "        0.93984962, 0.94736842, 0.92481203, 0.93233083, 0.93984962,\n",
       "        0.94736842, 0.93984962, 0.95488722, 0.93984962, 0.93233083,\n",
       "        0.92481203, 0.93984962, 0.91729323, 0.93984962, 0.93233083,\n",
       "        0.93984962, 0.93233083, 0.93984962, 0.93233083, 0.93984962,\n",
       "        0.93233083, 0.93984962, 0.94736842, 0.93984962, 0.92481203,\n",
       "        0.91729323, 0.93984962, 0.93984962, 0.92481203, 0.93984962,\n",
       "        0.91729323, 0.92481203, 0.93233083, 0.92481203, 0.94736842,\n",
       "        0.93233083, 0.93984962, 0.93984962, 0.93233083, 0.93233083,\n",
       "        0.93984962, 0.93984962, 0.93984962, 0.93984962, 0.92481203,\n",
       "        0.93984962, 0.95488722, 0.92481203, 0.93984962, 0.93984962,\n",
       "        0.93984962, 0.92481203, 0.94736842, 0.95488722, 0.93233083,\n",
       "        0.93233083, 0.92481203, 0.92481203, 0.93233083, 0.93233083,\n",
       "        0.93984962, 0.93233083, 0.95488722, 0.93233083, 0.94736842,\n",
       "        0.92481203, 0.91729323, 0.93984962, 0.93233083, 0.93984962,\n",
       "        0.91729323, 0.93233083, 0.94736842, 0.93233083, 0.93233083,\n",
       "        0.93984962, 0.92481203, 0.93984962, 0.93233083, 0.93984962,\n",
       "        0.95488722, 0.93233083, 0.92481203, 0.94736842, 0.93984962,\n",
       "        0.92481203, 0.93984962, 0.93984962, 0.95488722, 0.91729323,\n",
       "        0.94736842, 0.95488722, 0.93233083, 0.93233083, 0.92481203,\n",
       "        0.93233083, 0.93984962, 0.93984962, 0.92481203, 0.93984962]),\n",
       " 'split1_test_score': array([0.96240602, 0.96992481, 0.98496241, 0.96992481, 0.96240602,\n",
       "        0.95488722, 0.96992481, 0.96992481, 0.96240602, 0.96240602,\n",
       "        0.96240602, 0.96992481, 0.96240602, 0.97744361, 0.96240602,\n",
       "        0.96992481, 0.96240602, 0.96240602, 0.96992481, 0.96992481,\n",
       "        0.96240602, 0.96240602, 0.95488722, 0.95488722, 0.96992481,\n",
       "        0.96992481, 0.97744361, 0.96992481, 0.95488722, 0.96992481,\n",
       "        0.96992481, 0.95488722, 0.96240602, 0.97744361, 0.96992481,\n",
       "        0.96240602, 0.96992481, 0.96992481, 0.96992481, 0.96992481,\n",
       "        0.97744361, 0.96992481, 0.96992481, 0.96240602, 0.96240602,\n",
       "        0.96992481, 0.96240602, 0.95488722, 0.95488722, 0.96992481,\n",
       "        0.95488722, 0.96240602, 0.96240602, 0.96992481, 0.96992481,\n",
       "        0.96240602, 0.96240602, 0.96240602, 0.96240602, 0.96240602,\n",
       "        0.97744361, 0.96240602, 0.97744361, 0.96240602, 0.96240602,\n",
       "        0.96240602, 0.96240602, 0.97744361, 0.98496241, 0.96240602,\n",
       "        0.97744361, 0.95488722, 0.97744361, 0.95488722, 0.96992481,\n",
       "        0.97744361, 0.96992481, 0.96240602, 0.95488722, 0.96240602,\n",
       "        0.96992481, 0.96240602, 0.95488722, 0.95488722, 0.96992481,\n",
       "        0.96240602, 0.96992481, 0.96992481, 0.96992481, 0.97744361,\n",
       "        0.96240602, 0.95488722, 0.96992481, 0.96240602, 0.96240602,\n",
       "        0.96240602, 0.96240602, 0.97744361, 0.95488722, 0.97744361,\n",
       "        0.96240602, 0.96992481, 0.96240602, 0.96240602, 0.96992481,\n",
       "        0.95488722, 0.96992481, 0.94736842, 0.95488722, 0.96992481,\n",
       "        0.95488722, 0.96240602, 0.94736842, 0.96240602, 0.95488722,\n",
       "        0.96240602, 0.96992481, 0.95488722, 0.97744361, 0.97744361,\n",
       "        0.96992481, 0.96992481, 0.97744361, 0.96240602, 0.96240602,\n",
       "        0.95488722, 0.96992481, 0.97744361, 0.96240602, 0.96992481,\n",
       "        0.96240602, 0.96992481, 0.96240602, 0.95488722, 0.97744361,\n",
       "        0.96240602, 0.96240602, 0.96240602, 0.98496241, 0.96992481,\n",
       "        0.96992481, 0.96992481, 0.96992481, 0.96992481, 0.96992481,\n",
       "        0.96992481, 0.94736842, 0.96992481, 0.96992481, 0.96240602,\n",
       "        0.97744361, 0.96992481, 0.96992481, 0.96240602, 0.96992481,\n",
       "        0.96240602, 0.96992481, 0.96992481, 0.96992481, 0.96240602,\n",
       "        0.96240602, 0.97744361, 0.96992481, 0.96240602, 0.96992481,\n",
       "        0.96992481, 0.96240602, 0.96992481, 0.96992481, 0.96992481,\n",
       "        0.94736842, 0.96240602, 0.97744361, 0.96992481, 0.96240602,\n",
       "        0.96240602, 0.96240602, 0.96992481, 0.96992481, 0.96992481,\n",
       "        0.96992481, 0.96992481, 0.96992481, 0.97744361, 0.96240602,\n",
       "        0.96992481, 0.96240602, 0.96992481, 0.96240602, 0.95488722,\n",
       "        0.96992481, 0.96240602, 0.96240602, 0.96992481, 0.95488722,\n",
       "        0.97744361, 0.96240602, 0.96240602, 0.96992481, 0.96992481]),\n",
       " 'split2_test_score': array([0.96212121, 0.96969697, 0.96969697, 0.96212121, 0.96969697,\n",
       "        0.96969697, 0.96212121, 0.95454545, 0.96969697, 0.96212121,\n",
       "        0.96212121, 0.97727273, 0.9469697 , 0.96969697, 0.96212121,\n",
       "        0.95454545, 0.96969697, 0.96212121, 0.95454545, 0.97727273,\n",
       "        0.96212121, 0.96212121, 0.9469697 , 0.96212121, 0.96212121,\n",
       "        0.96969697, 0.96212121, 0.96969697, 0.96969697, 0.96212121,\n",
       "        0.95454545, 0.96212121, 0.96969697, 0.96969697, 0.95454545,\n",
       "        0.96212121, 0.96212121, 0.96212121, 0.96969697, 0.95454545,\n",
       "        0.95454545, 0.96212121, 0.96212121, 0.96212121, 0.9469697 ,\n",
       "        0.96969697, 0.96969697, 0.95454545, 0.96212121, 0.96969697,\n",
       "        0.95454545, 0.95454545, 0.96969697, 0.96212121, 0.96969697,\n",
       "        0.95454545, 0.96212121, 0.96969697, 0.95454545, 0.96969697,\n",
       "        0.96969697, 0.96212121, 0.96969697, 0.95454545, 0.96969697,\n",
       "        0.96212121, 0.95454545, 0.97727273, 0.96212121, 0.96212121,\n",
       "        0.95454545, 0.95454545, 0.96212121, 0.95454545, 0.97727273,\n",
       "        0.96212121, 0.96212121, 0.95454545, 0.95454545, 0.96212121,\n",
       "        0.96212121, 0.95454545, 0.96969697, 0.95454545, 0.96969697,\n",
       "        0.96969697, 0.97727273, 0.96212121, 0.96212121, 0.96969697,\n",
       "        0.95454545, 0.95454545, 0.96212121, 0.95454545, 0.96969697,\n",
       "        0.96212121, 0.96969697, 0.97727273, 0.95454545, 0.96212121,\n",
       "        0.96969697, 0.96969697, 0.96212121, 0.95454545, 0.96969697,\n",
       "        0.95454545, 0.96969697, 0.9469697 , 0.9469697 , 0.95454545,\n",
       "        0.95454545, 0.9469697 , 0.95454545, 0.96212121, 0.96212121,\n",
       "        0.96969697, 0.96212121, 0.9469697 , 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.97727273, 0.9469697 ,\n",
       "        0.95454545, 0.96212121, 0.96969697, 0.95454545, 0.96969697,\n",
       "        0.96212121, 0.95454545, 0.95454545, 0.95454545, 0.96212121,\n",
       "        0.9469697 , 0.97727273, 0.96212121, 0.96212121, 0.96212121,\n",
       "        0.95454545, 0.96212121, 0.96969697, 0.96969697, 0.96212121,\n",
       "        0.95454545, 0.9469697 , 0.95454545, 0.97727273, 0.95454545,\n",
       "        0.96969697, 0.95454545, 0.96969697, 0.95454545, 0.96212121,\n",
       "        0.95454545, 0.96969697, 0.95454545, 0.96212121, 0.93939394,\n",
       "        0.95454545, 0.95454545, 0.96212121, 0.9469697 , 0.95454545,\n",
       "        0.96212121, 0.96212121, 0.96212121, 0.96212121, 0.96212121,\n",
       "        0.95454545, 0.96969697, 0.96212121, 0.95454545, 0.96969697,\n",
       "        0.96212121, 0.9469697 , 0.96212121, 0.96969697, 0.96212121,\n",
       "        0.96212121, 0.96969697, 0.96969697, 0.96969697, 0.97727273,\n",
       "        0.95454545, 0.97727273, 0.96212121, 0.96212121, 0.95454545,\n",
       "        0.97727273, 0.96212121, 0.95454545, 0.95454545, 0.9469697 ,\n",
       "        0.96212121, 0.96212121, 0.96212121, 0.95454545, 0.96212121]),\n",
       " 'mean_test_score': array([0.95479228, 0.96233007, 0.96483633, 0.95729855, 0.95731754,\n",
       "        0.952305  , 0.96231108, 0.9547733 , 0.95731754, 0.95479228,\n",
       "        0.95228602, 0.95984279, 0.94472925, 0.96233007, 0.94977975,\n",
       "        0.94976077, 0.95731754, 0.95479228, 0.9547733 , 0.95984279,\n",
       "        0.95228602, 0.95479228, 0.94723551, 0.94977975, 0.95479228,\n",
       "        0.9598238 , 0.96481735, 0.9598238 , 0.95481127, 0.95729855,\n",
       "        0.94976077, 0.95228602, 0.95481127, 0.9598238 , 0.9547733 ,\n",
       "        0.95729855, 0.95729855, 0.95479228, 0.9598238 , 0.95727956,\n",
       "        0.9547733 , 0.95729855, 0.95479228, 0.95479228, 0.94472925,\n",
       "        0.96483633, 0.95731754, 0.94474823, 0.94977975, 0.95481127,\n",
       "        0.94224197, 0.95226703, 0.96233007, 0.95729855, 0.95481127,\n",
       "        0.94976077, 0.95479228, 0.95481127, 0.94474823, 0.9598238 ,\n",
       "        0.95731754, 0.95479228, 0.95731754, 0.94976077, 0.95731754,\n",
       "        0.95729855, 0.95226703, 0.96485532, 0.96231108, 0.95729855,\n",
       "        0.95226703, 0.95226703, 0.96231108, 0.94976077, 0.95984279,\n",
       "        0.96231108, 0.95729855, 0.94976077, 0.95226703, 0.94727349,\n",
       "        0.95729855, 0.94976077, 0.95481127, 0.95226703, 0.9598238 ,\n",
       "        0.95731754, 0.96234905, 0.95228602, 0.95980482, 0.96233007,\n",
       "        0.94474823, 0.94474823, 0.96231108, 0.95226703, 0.95731754,\n",
       "        0.95228602, 0.95481127, 0.96485532, 0.9472545 , 0.96231108,\n",
       "        0.95731754, 0.96233007, 0.94977975, 0.94976077, 0.9598238 ,\n",
       "        0.95226703, 0.9598238 , 0.94974178, 0.94723551, 0.95226703,\n",
       "        0.94474823, 0.94974178, 0.9397357 , 0.95479228, 0.94977975,\n",
       "        0.95731754, 0.95479228, 0.94723551, 0.9598238 , 0.96233007,\n",
       "        0.95731754, 0.9598238 , 0.96483633, 0.95984279, 0.94472925,\n",
       "        0.94224197, 0.95729855, 0.96233007, 0.9472545 , 0.9598238 ,\n",
       "        0.94727349, 0.94976077, 0.94976077, 0.94474823, 0.96231108,\n",
       "        0.94723551, 0.95984279, 0.95479228, 0.95980482, 0.95479228,\n",
       "        0.9547733 , 0.95729855, 0.9598238 , 0.9598238 , 0.95228602,\n",
       "        0.9547733 , 0.94974178, 0.94976077, 0.96234905, 0.95226703,\n",
       "        0.96233007, 0.94976077, 0.96233007, 0.95727956, 0.95479228,\n",
       "        0.94976077, 0.95481127, 0.94976077, 0.95479228, 0.94471026,\n",
       "        0.95226703, 0.9547733 , 0.96231108, 0.94723551, 0.95727956,\n",
       "        0.95228602, 0.94727349, 0.95729855, 0.95479228, 0.95729855,\n",
       "        0.9397357 , 0.95481127, 0.96231108, 0.95226703, 0.95481127,\n",
       "        0.95479228, 0.94472925, 0.95729855, 0.95731754, 0.95729855,\n",
       "        0.96231108, 0.95731754, 0.95481127, 0.96483633, 0.95984279,\n",
       "        0.94976077, 0.95984279, 0.95729855, 0.95980482, 0.94224197,\n",
       "        0.96485532, 0.95980482, 0.94976077, 0.95226703, 0.94222298,\n",
       "        0.95729855, 0.95479228, 0.95479228, 0.94976077, 0.95729855]),\n",
       " 'std_test_score': array([0.0105667 , 0.01057989, 0.01873517, 0.01274291, 0.01270526,\n",
       "        0.01536355, 0.00614054, 0.0122792 , 0.01270526, 0.0105667 ,\n",
       "        0.01411093, 0.01968382, 0.01542923, 0.01620762, 0.01765523,\n",
       "        0.0187254 , 0.01270526, 0.0105667 , 0.0122792 , 0.01968382,\n",
       "        0.01411093, 0.0105667 , 0.00614195, 0.01268678, 0.01619901,\n",
       "        0.01412418, 0.00940388, 0.01412418, 0.01218525, 0.01274291,\n",
       "        0.0187254 , 0.00927651, 0.01617235, 0.01969603, 0.0122792 ,\n",
       "        0.00702262, 0.01274291, 0.01619901, 0.01412418, 0.00940936,\n",
       "        0.01841792, 0.01274291, 0.01619901, 0.0105667 , 0.01542923,\n",
       "        0.0070357 , 0.01270526, 0.01409772, 0.01268678, 0.02121287,\n",
       "        0.01764197, 0.00934848, 0.00604629, 0.01274291, 0.02121287,\n",
       "        0.01273575, 0.0105667 , 0.01617235, 0.01967706, 0.00929666,\n",
       "        0.02320142, 0.0105667 , 0.02320142, 0.01273575, 0.01270526,\n",
       "        0.00702262, 0.00934848, 0.01768183, 0.01841771, 0.00702262,\n",
       "        0.02154707, 0.00346665, 0.01227888, 0.00700962, 0.01968382,\n",
       "        0.01227888, 0.01274291, 0.01273575, 0.00346665, 0.02119956,\n",
       "        0.01274291, 0.01273575, 0.01218525, 0.00346665, 0.01412418,\n",
       "        0.01270526, 0.01618984, 0.01968653, 0.00935314, 0.01620762,\n",
       "        0.01967706, 0.01409772, 0.00614054, 0.00934848, 0.01270526,\n",
       "        0.01411093, 0.01617235, 0.01768183, 0.01055355, 0.01227888,\n",
       "        0.01270526, 0.01057989, 0.01765523, 0.01273575, 0.01412418,\n",
       "        0.00346665, 0.01412418, 0.00364201, 0.00614195, 0.01543201,\n",
       "        0.01409772, 0.00941492, 0.01613745, 0.0105667 , 0.01268678,\n",
       "        0.01270526, 0.01619901, 0.00614195, 0.01969603, 0.01620762,\n",
       "        0.01766852, 0.01412418, 0.01275013, 0.01538505, 0.01542923,\n",
       "        0.01764197, 0.01274291, 0.01620762, 0.01619044, 0.01412418,\n",
       "        0.02119956, 0.0187254 , 0.01273575, 0.01409772, 0.01227888,\n",
       "        0.01227958, 0.01538505, 0.0105667 , 0.02154909, 0.01619901,\n",
       "        0.0122792 , 0.01274291, 0.01412418, 0.01412418, 0.01968653,\n",
       "        0.0122792 , 0.00364201, 0.0187254 , 0.01618984, 0.00934848,\n",
       "        0.01620762, 0.0187254 , 0.01057989, 0.00362763, 0.01619901,\n",
       "        0.01273575, 0.02121287, 0.0187254 , 0.01619901, 0.01284073,\n",
       "        0.00934848, 0.01841792, 0.00614054, 0.01227958, 0.00940936,\n",
       "        0.01968653, 0.02119956, 0.01274291, 0.01619901, 0.01274291,\n",
       "        0.01613745, 0.01617235, 0.01227888, 0.01543201, 0.01617235,\n",
       "        0.0105667 , 0.01542923, 0.01274291, 0.01766852, 0.01274291,\n",
       "        0.00614054, 0.01766852, 0.02121287, 0.01275013, 0.01538505,\n",
       "        0.0187254 , 0.01538505, 0.01274291, 0.00347921, 0.01764197,\n",
       "        0.01272378, 0.00347921, 0.01273575, 0.01543201, 0.01272865,\n",
       "        0.01873027, 0.0105667 , 0.0105667 , 0.0187254 , 0.01274291]),\n",
       " 'rank_test_score': array([101,  11,   4,  68,  54, 128,  20, 121,  54, 101, 133,  30, 190,\n",
       "         11, 149, 154,  54, 101, 121,  30, 133, 101, 179, 149, 101,  37,\n",
       "          8,  37,  90,  68, 154, 129,  96,  47, 121,  68,  68, 101,  37,\n",
       "         87, 121,  68, 101, 101, 190,   4,  54, 184, 149,  90, 195, 136,\n",
       "         11,  68,  90, 154, 101,  96, 184,  47,  54, 101,  54, 154,  54,\n",
       "         68, 136,   1,  20,  68, 136, 136,  20, 154,  30,  20,  68, 154,\n",
       "        136, 174,  68, 154,  90, 136,  37,  54,   9, 129,  50,  11, 184,\n",
       "        184,  20, 136,  54, 133,  96,   1, 177,  20,  54,  11, 149, 154,\n",
       "         37, 136,  37, 171, 179, 136, 184, 171, 199, 101, 149,  54, 101,\n",
       "        179,  47,  11,  54,  37,   4,  30, 190, 195,  68,  11, 177,  37,\n",
       "        174, 154, 154, 184,  20, 179,  30, 101,  50, 101, 121,  68,  37,\n",
       "         37, 129, 121, 171, 154,   9, 136,  11, 154,  11,  87, 101, 154,\n",
       "         90, 154, 101, 194, 136, 121,  20, 179,  87, 129, 174,  68, 101,\n",
       "         68, 199,  96,  20, 136,  96, 101, 190,  68,  54,  68,  20,  54,\n",
       "         90,   4,  30, 154,  30,  68,  50, 195,   1,  50, 154, 136, 198,\n",
       "         68, 101, 101, 154,  68], dtype=int32)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2_xgb_rcv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8900d60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037740</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'min_child_weight': 1, 'max_depth': 10, 'lear...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.954792</td>\n",
       "      <td>0.010567</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'min_child_weight': 3, 'max_depth': 5, 'learn...</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.962330</td>\n",
       "      <td>0.010580</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034534</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'min_child_weight': 1, 'max_depth': 10, 'lear...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.984962</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.964836</td>\n",
       "      <td>0.018735</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031291</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'min_child_weight': 3, 'max_depth': 15, 'lear...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.957299</td>\n",
       "      <td>0.012743</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030679</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'min_child_weight': 1, 'max_depth': 12, 'lear...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.957318</td>\n",
       "      <td>0.012705</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.037370</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'min_child_weight': 3, 'max_depth': 4, 'learn...</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.957299</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.035248</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'min_child_weight': 1, 'max_depth': 10, 'lear...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.954792</td>\n",
       "      <td>0.010567</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.031438</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'min_child_weight': 5, 'max_depth': 10, 'lear...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.954792</td>\n",
       "      <td>0.010567</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.030637</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'min_child_weight': 7, 'max_depth': 10, 'lear...</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.949761</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'min_child_weight': 5, 'max_depth': 12, 'lear...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.957299</td>\n",
       "      <td>0.012743</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.037740      0.007184         0.003028        0.000058   \n",
       "1         0.030186      0.000756         0.002908        0.000058   \n",
       "2         0.034534      0.001198         0.002977        0.000082   \n",
       "3         0.031291      0.001193         0.003033        0.000032   \n",
       "4         0.030679      0.000758         0.003012        0.000205   \n",
       "..             ...           ...              ...             ...   \n",
       "195       0.037370      0.000392         0.003316        0.000016   \n",
       "196       0.035248      0.000455         0.003220        0.000041   \n",
       "197       0.031438      0.000428         0.003208        0.000035   \n",
       "198       0.030637      0.000208         0.003168        0.000028   \n",
       "199       0.032000      0.000320         0.003175        0.000051   \n",
       "\n",
       "    param_min_child_weight param_max_depth param_learning_rate param_gamma  \\\n",
       "0                        1              10                 0.2         0.2   \n",
       "1                        3               5                 0.1         0.3   \n",
       "2                        1              10                 0.1         0.3   \n",
       "3                        3              15                 0.1         0.4   \n",
       "4                        1              12                 0.3         0.3   \n",
       "..                     ...             ...                 ...         ...   \n",
       "195                      3               4                0.05         0.0   \n",
       "196                      1              10                 0.3         0.4   \n",
       "197                      5              10                0.15         0.0   \n",
       "198                      7              10                 0.2         0.4   \n",
       "199                      5              12                 0.1         0.3   \n",
       "\n",
       "    param_colsample_bytree                                             params  \\\n",
       "0                      0.5  {'min_child_weight': 1, 'max_depth': 10, 'lear...   \n",
       "1                      0.4  {'min_child_weight': 3, 'max_depth': 5, 'learn...   \n",
       "2                      0.5  {'min_child_weight': 1, 'max_depth': 10, 'lear...   \n",
       "3                      0.5  {'min_child_weight': 3, 'max_depth': 15, 'lear...   \n",
       "4                      0.3  {'min_child_weight': 1, 'max_depth': 12, 'lear...   \n",
       "..                     ...                                                ...   \n",
       "195                    0.4  {'min_child_weight': 3, 'max_depth': 4, 'learn...   \n",
       "196                    0.4  {'min_child_weight': 1, 'max_depth': 10, 'lear...   \n",
       "197                    0.5  {'min_child_weight': 5, 'max_depth': 10, 'lear...   \n",
       "198                    0.7  {'min_child_weight': 7, 'max_depth': 10, 'lear...   \n",
       "199                    0.4  {'min_child_weight': 5, 'max_depth': 12, 'lear...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0             0.939850           0.962406           0.962121         0.954792   \n",
       "1             0.947368           0.969925           0.969697         0.962330   \n",
       "2             0.939850           0.984962           0.969697         0.964836   \n",
       "3             0.939850           0.969925           0.962121         0.957299   \n",
       "4             0.939850           0.962406           0.969697         0.957318   \n",
       "..                 ...                ...                ...              ...   \n",
       "195           0.932331           0.977444           0.962121         0.957299   \n",
       "196           0.939850           0.962406           0.962121         0.954792   \n",
       "197           0.939850           0.962406           0.962121         0.954792   \n",
       "198           0.924812           0.969925           0.954545         0.949761   \n",
       "199           0.939850           0.969925           0.962121         0.957299   \n",
       "\n",
       "     std_test_score  rank_test_score  \n",
       "0          0.010567              101  \n",
       "1          0.010580               11  \n",
       "2          0.018735                4  \n",
       "3          0.012743               68  \n",
       "4          0.012705               54  \n",
       "..              ...              ...  \n",
       "195        0.018730               68  \n",
       "196        0.010567              101  \n",
       "197        0.010567              101  \n",
       "198        0.018725              154  \n",
       "199        0.012743               68  \n",
       "\n",
       "[200 rows x 16 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_result = pd.DataFrame(p2_xgb_rcv.cv_results_)\n",
    "tuning_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b571837c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_child_weight': 1,\n",
       " 'max_depth': 3,\n",
       " 'learning_rate': 0.25,\n",
       " 'gamma': 0.0,\n",
       " 'colsample_bytree': 0.3}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_params = p2_xgb_rcv.best_params_\n",
    "b_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8d662e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9648553201184781"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2_xgb_rcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac8ffa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = p2_xgb_rcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50768bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.25, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=3, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.25, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=3, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.25, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=3, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11306fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tu_acc = best_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3860603f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu_y_pred = best_clf.predict(X_test)\n",
    "tu_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b30e0333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[106,   5],\n",
       "       [  2,  58]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu_cm = confusion_matrix(tu_y_pred, y_test)\n",
    "tu_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4a77dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(tu_cm, annot=True,cmap='Blues', fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f502688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score Before Tuning 0.9415204678362573\n",
      "Accuracy Score After Tuning with Param1 0.9415204678362573\n",
      "Accuracy Score After Tuning with Param2 0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score Before Tuning', xgb_acc)\n",
    "print('Accuracy Score After Tuning with Param1', tu_ac)\n",
    "print('Accuracy Score After Tuning with Param2', tu_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9795b",
   "metadata": {},
   "source": [
    "# Hyperperameter Tuning using perameter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00c25e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 53,  92, 163,  83, 125, 321,  41,  30, 243, 121,  92, 204, 257,\n",
       "        20, 261, 259, 281, 298, 440, 211,  53, 334, 126,  66,  72, 265,\n",
       "       211, 227,  79,  37, 145, 441, 130, 142, 334, 364, 144, 420, 166,\n",
       "       431,  40, 129, 390, 206, 445,  34, 161, 368, 217, 427, 369, 399,\n",
       "        78, 218, 176,  50, 175, 199, 435,  49, 398,  79, 422,  95, 150,\n",
       "        18,  63, 272, 247, 121, 347, 228, 369, 397,  19, 320, 410, 263,\n",
       "       228, 162,  19, 285,  91, 406, 363,  83,  48, 405, 160, 162, 350,\n",
       "       392, 125, 322, 231, 421, 313, 378, 424, 273,  85, 305, 259, 257,\n",
       "       290, 101, 413, 445, 319, 439,  21, 287, 147,  71, 358,  95,  45,\n",
       "       274, 408, 392,  35, 227, 290, 374, 448, 265, 226, 339,  39, 341,\n",
       "       354, 283, 398, 112, 102, 176, 437,  16, 385, 187, 426, 360, 205,\n",
       "       157, 349, 434, 110,  57, 380,  18])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create random number list using Numpy\n",
    "trees = np.random.randint(15,450,150)\n",
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04484f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55471126, 0.50232666, 0.35058727, 0.89377454, 0.42473628,\n",
       "       0.04654459, 0.18554081, 0.43597323, 0.28527811, 0.77818119])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = np.random.random(10)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7dd7a8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19542585, 0.50092253, 0.62855085, 0.81070328, 0.97449964,\n",
       "       0.95019845])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colsamp = np.random.random(6)\n",
    "colsamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ffa9196e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5], 'max_depth': array([ 53,  92, 163,  83, 125, 321,  41,  30, 243, 121,  92, 204, 257,\n",
      "        20, 261, 259, 281, 298, 440, 211,  53, 334, 126,  66,  72, 265,\n",
      "       211, 227,  79,  37, 145, 441, 130, 142, 334, 364, 144, 420, 166,\n",
      "       431,  40, 129, 390, 206, 445,  34, 161, 368, 217, 427, 369, 399,\n",
      "        78, 218, 176,  50, 175, 199, 435,  49, 398,  79, 422,  95, 150,\n",
      "        18,  63, 272, 247, 121, 347, 228, 369, 397,  19, 320, 410, 263,\n",
      "       228, 162,  19, 285,  91, 406, 363,  83,  48, 405, 160, 162, 350,\n",
      "       392, 125, 322, 231, 421, 313, 378, 424, 273,  85, 305, 259, 257,\n",
      "       290, 101, 413, 445, 319, 439,  21, 287, 147,  71, 358,  95,  45,\n",
      "       274, 408, 392,  35, 227, 290, 374, 448, 265, 226, 339,  39, 341,\n",
      "       354, 283, 398, 112, 102, 176, 437,  16, 385, 187, 426, 360, 205,\n",
      "       157, 349, 434, 110,  57, 380,  18]), 'min_child_weight': [1, 3, 6], 'max_delta_step': [1, 2, 3, 4, 5, 6, 7, 8], 'gamma': [1, 2, 3, 4, 5], 'subsample': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5], 'colsample_bytree': array([0.19542585, 0.50092253, 0.62855085, 0.81070328, 0.97449964,\n",
      "       0.95019845]), 'reg_alpha': array([0.55471126, 0.50232666, 0.35058727, 0.89377454, 0.42473628,\n",
      "       0.04654459, 0.18554081, 0.43597323, 0.28527811, 0.77818119])}\n"
     ]
    }
   ],
   "source": [
    "param3 = {\n",
    "    #'boster' : ['gbtree', 'gblinear'],\n",
    "    'learning_rate' : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50],\n",
    "    'max_depth':trees,\n",
    "    'min_child_weight' : [1,3,6],\n",
    "    'max_delta_step' : [1,2,3,4,5,6,7,8],\n",
    "    'gamma':[1,2,3,4,5],\n",
    "    'subsample':[0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50],\n",
    "    'colsample_bytree':colsamp,\n",
    "    'reg_alpha': alphas\n",
    "}\n",
    "\n",
    "print(param3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e0989bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "       290, 101, 413, 445, 319, 439,  21, 287, 147,  71, 358,  95,  45,\n",
       "       274, 408, 392,  35, 227, 290, 374, 448, 265, 226, 339,  39, 341,\n",
       "       354, 283, 398, 112, 102, 176, 437,  16, 385, 187, 426, 360, 205,\n",
       "       157, 349, 434, 110,  57, 380,  18]),\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 3, 6],\n",
       "                                        &#x27;reg_alpha&#x27;: array([0.55471126, 0.50232666, 0.35058727, 0.89377454, 0.42473628,\n",
       "       0.04654459, 0.18554081, 0.43597323, 0.28527811, 0.77818119]),\n",
       "                                        &#x27;subsample&#x27;: [0.05, 0.1, 0.15, 0.2,\n",
       "                                                      0.25, 0.3, 0.35, 0.4,\n",
       "                                                      0.45, 0.5]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "       290, 101, 413, 445, 319, 439,  21, 287, 147,  71, 358,  95,  45,\n",
       "       274, 408, 392,  35, 227, 290, 374, 448, 265, 226, 339,  39, 341,\n",
       "       354, 283, 398, 112, 102, 176, 437,  16, 385, 187, 426, 360, 205,\n",
       "       157, 349, 434, 110,  57, 380,  18]),\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 3, 6],\n",
       "                                        &#x27;reg_alpha&#x27;: array([0.55471126, 0.50232666, 0.35058727, 0.89377454, 0.42473628,\n",
       "       0.04654459, 0.18554081, 0.43597323, 0.28527811, 0.77818119]),\n",
       "                                        &#x27;subsample&#x27;: [0.05, 0.1, 0.15, 0.2,\n",
       "                                                      0.25, 0.3, 0.35, 0.4,\n",
       "                                                      0.45, 0.5]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "       290, 101, 413, 445, 319, 439,  21, 287, 147,  71, 358,  95,  45,\n",
       "       274, 408, 392,  35, 227, 290, 374, 448, 265, 226, 339,  39, 341,\n",
       "       354, 283, 398, 112, 102, 176, 437,  16, 385, 187, 426, 360, 205,\n",
       "       157, 349, 434, 110,  57, 380,  18]),\n",
       "                                        'min_child_weight': [1, 3, 6],\n",
       "                                        'reg_alpha': array([0.55471126, 0.50232666, 0.35058727, 0.89377454, 0.42473628,\n",
       "       0.04654459, 0.18554081, 0.43597323, 0.28527811, 0.77818119]),\n",
       "                                        'subsample': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                      0.25, 0.3, 0.35, 0.4,\n",
       "                                                      0.45, 0.5]})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3_xgb_clf = XGBClassifier()\n",
    "p3_xgb_rcv = RandomizedSearchCV(p3_xgb_clf, param3, n_iter=200, cv=3)\n",
    "p3_xgb_rcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63a95a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.04908299, 0.03080503, 0.02500669, 0.02514323, 0.02653527,\n",
       "        0.02758567, 0.02630623, 0.02731236, 0.0244147 , 0.02712377,\n",
       "        0.06704164, 0.03893932, 0.03293077, 0.03493261, 0.03163632,\n",
       "        0.03255614, 0.03120939, 0.03022305, 0.03412708, 0.03051591,\n",
       "        0.02620697, 0.03112785, 0.03699557, 0.03613822, 0.02824569,\n",
       "        0.03379202, 0.02671758, 0.03113699, 0.06208444, 0.04410474,\n",
       "        0.02979517, 0.03263434, 0.03058751, 0.03260056, 0.03171929,\n",
       "        0.03666886, 0.02997971, 0.02692238, 0.02572171, 0.03422308,\n",
       "        0.02989332, 0.02810192, 0.03347898, 0.02687923, 0.02949961,\n",
       "        0.02694615, 0.03051464, 0.03245926, 0.02603833, 0.02843372,\n",
       "        0.02508839, 0.02882234, 0.02588073, 0.02754545, 0.02502418,\n",
       "        0.02588232, 0.02586476, 0.02627659, 0.02573808, 0.02680977,\n",
       "        0.0272944 , 0.02715937, 0.02910391, 0.02578203, 0.02767428,\n",
       "        0.02709198, 0.02501464, 0.03187617, 0.02798343, 0.02630734,\n",
       "        0.0273393 , 0.02585705, 0.03086535, 0.02655991, 0.04022137,\n",
       "        0.05720186, 0.05393211, 0.07204247, 0.05155261, 0.06982605,\n",
       "        0.04132032, 0.03260295, 0.03005568, 0.0265007 , 0.02637307,\n",
       "        0.03082331, 0.02872626, 0.02716923, 0.02828574, 0.02968876,\n",
       "        0.02959665, 0.03039042, 0.03419272, 0.02992765, 0.06565563,\n",
       "        0.05975715, 0.04559429, 0.03591641, 0.03493222, 0.03554177,\n",
       "        0.0379138 , 0.03789123, 0.03062876, 0.03487921, 0.03859138,\n",
       "        0.03314328, 0.03053204, 0.02963638, 0.02772959, 0.04513963,\n",
       "        0.04595097, 0.03986573, 0.04493435, 0.03269601, 0.03297869,\n",
       "        0.02855961, 0.02846964, 0.03020533, 0.04687095, 0.06235139,\n",
       "        0.03572838, 0.03352833, 0.03179367, 0.03043739, 0.02922599,\n",
       "        0.02994617, 0.03463562, 0.08634535, 0.08634528, 0.08379022,\n",
       "        0.05918256, 0.0581371 , 0.03698874, 0.11827596, 0.10834813,\n",
       "        0.09458931, 0.10529733, 0.08336306, 0.08645837, 0.08439128,\n",
       "        0.07727695, 0.14033031, 0.09969672, 0.09608301, 0.15122533,\n",
       "        0.12315003, 0.05334449, 0.05248745, 0.06458632, 0.04185867,\n",
       "        0.03825029, 0.03224214, 0.02991199, 0.03558222, 0.05069224,\n",
       "        0.03002874, 0.03051098, 0.04104328, 0.03822803, 0.03360931,\n",
       "        0.03143636, 0.03418628, 0.03122703, 0.02913221, 0.03563468,\n",
       "        0.03276467, 0.04966299, 0.03892152, 0.05226572, 0.03074201,\n",
       "        0.03148993, 0.03093974, 0.02919038, 0.02855142, 0.03606757,\n",
       "        0.10366265, 0.03666774, 0.03109129, 0.20686428, 0.13195626,\n",
       "        0.09495584, 0.09932407, 0.0548687 , 0.05436897, 0.04880826,\n",
       "        0.05427273, 0.05790869, 0.08082891, 0.03628826, 0.04738919,\n",
       "        0.04424898, 0.03649306, 0.0501581 , 0.06079626, 0.06083544,\n",
       "        0.09177589, 0.0556461 , 0.08584317, 0.07112932, 0.05905024]),\n",
       " 'std_fit_time': array([1.72964718e-02, 1.21106150e-03, 1.63008386e-04, 2.96870758e-04,\n",
       "        2.96665979e-04, 3.23660068e-04, 3.00164499e-04, 4.21377543e-04,\n",
       "        2.26628478e-04, 6.55289271e-05, 2.70558887e-02, 7.85999842e-03,\n",
       "        9.37320791e-04, 4.86408962e-05, 1.21985720e-03, 9.36779119e-04,\n",
       "        1.18221375e-03, 1.45638244e-03, 7.44310432e-04, 2.82716187e-03,\n",
       "        1.08970246e-04, 2.35782220e-04, 4.62891286e-03, 2.15803104e-03,\n",
       "        8.58755149e-04, 4.03455571e-04, 5.06647889e-04, 1.81379851e-03,\n",
       "        2.18329289e-02, 7.52869791e-03, 1.03086880e-03, 1.56735030e-03,\n",
       "        3.38208461e-04, 1.63575152e-03, 1.65176169e-03, 6.36928569e-04,\n",
       "        4.48879450e-03, 4.92238906e-04, 4.75839419e-04, 4.17463647e-04,\n",
       "        3.02108777e-03, 1.57041293e-03, 6.21006245e-04, 3.59174686e-04,\n",
       "        4.68082015e-04, 2.59590527e-05, 1.91025969e-03, 5.59346129e-03,\n",
       "        2.69948891e-04, 8.74750485e-04, 1.01263705e-04, 5.28807046e-04,\n",
       "        1.50584482e-04, 2.49226001e-04, 1.49802904e-04, 1.24592712e-04,\n",
       "        1.31648849e-04, 7.90854516e-04, 3.03476311e-04, 5.96416147e-05,\n",
       "        2.87294289e-04, 1.14648077e-04, 2.31253104e-04, 1.28028828e-04,\n",
       "        2.60343069e-04, 3.34697625e-04, 1.95916348e-04, 1.55643370e-04,\n",
       "        1.91457789e-04, 1.01589915e-03, 2.14962201e-04, 9.23617560e-05,\n",
       "        8.95481761e-05, 3.11529636e-04, 1.09843296e-02, 1.87062984e-03,\n",
       "        3.58692774e-04, 6.52289036e-04, 1.74741055e-03, 1.38703499e-03,\n",
       "        1.31079460e-02, 1.68098265e-03, 4.77595296e-04, 9.56595497e-04,\n",
       "        1.18662907e-04, 2.45041595e-04, 9.95739820e-04, 1.31998798e-04,\n",
       "        3.89957523e-04, 4.07868080e-04, 3.08084185e-04, 6.09372464e-04,\n",
       "        3.77899857e-04, 5.93265733e-04, 2.60056380e-02, 8.72865111e-04,\n",
       "        5.05824013e-03, 3.59888746e-03, 1.01237880e-04, 1.15128638e-03,\n",
       "        1.32218064e-03, 2.53728259e-03, 7.70817316e-04, 1.95429660e-04,\n",
       "        1.20485281e-03, 7.73367618e-04, 1.59387962e-03, 7.98774759e-04,\n",
       "        1.09752911e-04, 5.70315097e-03, 6.09736048e-03, 1.20732584e-03,\n",
       "        9.20437445e-04, 3.69165950e-04, 9.90972254e-04, 5.46935627e-04,\n",
       "        1.45092588e-04, 1.22334262e-03, 8.71097512e-03, 4.55211467e-03,\n",
       "        2.13656661e-03, 1.79704265e-03, 1.99237588e-03, 1.38083173e-04,\n",
       "        4.19182324e-04, 7.86831217e-04, 2.10766118e-03, 8.00558736e-02,\n",
       "        3.69993839e-02, 2.98360667e-02, 3.45242082e-02, 2.84763035e-02,\n",
       "        1.17687705e-02, 5.90615319e-02, 2.98963102e-03, 3.22442810e-02,\n",
       "        2.65210016e-02, 1.46315413e-02, 2.26454743e-02, 2.45959577e-03,\n",
       "        7.95412414e-03, 5.16258789e-03, 2.25472775e-02, 6.18285462e-03,\n",
       "        9.41298210e-02, 3.75806206e-02, 1.13271760e-02, 4.76474363e-03,\n",
       "        3.35311480e-02, 8.46843591e-03, 1.70788136e-03, 9.50051825e-04,\n",
       "        6.37503372e-04, 1.10155762e-03, 2.87323438e-02, 1.05371002e-04,\n",
       "        3.73923918e-04, 7.90572019e-03, 2.15492452e-03, 6.03603814e-04,\n",
       "        2.07207130e-03, 3.33948746e-03, 2.97915906e-04, 2.16009718e-04,\n",
       "        8.29320954e-04, 1.25675733e-03, 3.05201151e-03, 5.33341452e-03,\n",
       "        1.57534143e-03, 2.57429924e-03, 2.27486623e-03, 1.74562247e-03,\n",
       "        6.86390273e-04, 1.42498051e-04, 1.46471530e-03, 4.40320837e-02,\n",
       "        6.29263740e-03, 5.44254328e-04, 7.81368897e-02, 3.16089307e-02,\n",
       "        1.58719469e-02, 5.42740318e-02, 6.92621669e-03, 1.95341792e-03,\n",
       "        2.68559667e-03, 1.05781003e-02, 5.91191124e-03, 3.60150645e-02,\n",
       "        8.35840794e-04, 5.01122158e-03, 1.06728954e-03, 3.81776425e-03,\n",
       "        1.60988772e-02, 5.78888013e-03, 4.42294700e-03, 7.04223118e-03,\n",
       "        4.70215479e-03, 9.62889885e-03, 1.54932277e-02, 4.14209248e-03]),\n",
       " 'mean_score_time': array([0.00297276, 0.00315213, 0.00283853, 0.00292857, 0.00288169,\n",
       "        0.00297697, 0.00287477, 0.00285133, 0.00283058, 0.00284266,\n",
       "        0.0034647 , 0.0032297 , 0.00321992, 0.00322596, 0.0032541 ,\n",
       "        0.00313814, 0.00306368, 0.00319338, 0.00300725, 0.00310842,\n",
       "        0.00293271, 0.00288916, 0.00324829, 0.00352971, 0.00299899,\n",
       "        0.00283774, 0.0030218 , 0.00315452, 0.00401195, 0.00330154,\n",
       "        0.00304898, 0.00300725, 0.00302235, 0.00301329, 0.00318933,\n",
       "        0.0031418 , 0.0029343 , 0.00284298, 0.00286524, 0.0028619 ,\n",
       "        0.00305311, 0.00296315, 0.00292738, 0.00278838, 0.0028375 ,\n",
       "        0.0028104 , 0.00288391, 0.00286969, 0.00282868, 0.0028673 ,\n",
       "        0.00279959, 0.0028367 , 0.00287358, 0.00286571, 0.00275691,\n",
       "        0.00281437, 0.00282677, 0.00282772, 0.0028193 , 0.00281151,\n",
       "        0.00284052, 0.00283345, 0.0028073 , 0.00283885, 0.00281231,\n",
       "        0.00284767, 0.00285244, 0.00292293, 0.00289925, 0.00283027,\n",
       "        0.00286937, 0.00279093, 0.00285673, 0.00284974, 0.00299327,\n",
       "        0.00305605, 0.00325688, 0.00307043, 0.00306066, 0.00310214,\n",
       "        0.00288145, 0.00301107, 0.00300638, 0.00292802, 0.00290163,\n",
       "        0.00292166, 0.00300805, 0.00298405, 0.00296696, 0.00301735,\n",
       "        0.00304206, 0.00303833, 0.00316548, 0.00322946, 0.00338236,\n",
       "        0.00378013, 0.00347606, 0.00339031, 0.00360815, 0.00354067,\n",
       "        0.00348234, 0.00342774, 0.00323002, 0.0031871 , 0.00317709,\n",
       "        0.0031871 , 0.00336432, 0.00314824, 0.00308092, 0.00358923,\n",
       "        0.00356332, 0.00340589, 0.00346096, 0.00321674, 0.00327531,\n",
       "        0.00317208, 0.00314045, 0.00321349, 0.00359901, 0.00349847,\n",
       "        0.0033443 , 0.00323534, 0.00323272, 0.00315166, 0.00316103,\n",
       "        0.00330861, 0.00340843, 0.00521342, 0.00393208, 0.00375048,\n",
       "        0.00422335, 0.00433524, 0.00816814, 0.00355299, 0.00368317,\n",
       "        0.00366569, 0.00434566, 0.00381422, 0.00379229, 0.00371607,\n",
       "        0.00366799, 0.00381517, 0.00589808, 0.00374103, 0.00515962,\n",
       "        0.00440534, 0.00411638, 0.00392262, 0.00563463, 0.00327635,\n",
       "        0.00350634, 0.00330027, 0.00324607, 0.00328167, 0.00330893,\n",
       "        0.00331155, 0.00329312, 0.00365376, 0.00334827, 0.00319839,\n",
       "        0.00317852, 0.00317438, 0.00316691, 0.00321603, 0.003148  ,\n",
       "        0.00319457, 0.00326331, 0.00366457, 0.00323431, 0.0031662 ,\n",
       "        0.0031387 , 0.00312289, 0.00313091, 0.00316318, 0.00313346,\n",
       "        0.0044384 , 0.00326999, 0.00335344, 0.00598009, 0.004299  ,\n",
       "        0.00414252, 0.00443069, 0.00441265, 0.00528828, 0.00351477,\n",
       "        0.00366775, 0.00350404, 0.0040404 , 0.00355713, 0.00365496,\n",
       "        0.0034887 , 0.00403412, 0.00363215, 0.00383838, 0.00389536,\n",
       "        0.00420976, 0.00388773, 0.00366545, 0.00386206, 0.00410159]),\n",
       " 'std_score_time': array([4.32085394e-05, 1.80598677e-04, 4.31607143e-05, 5.86258741e-05,\n",
       "        5.53008912e-05, 9.30645850e-05, 4.53080342e-05, 3.71781818e-05,\n",
       "        6.57200668e-05, 1.55295743e-05, 1.61502148e-04, 2.18602434e-04,\n",
       "        1.92198141e-04, 1.06645767e-04, 1.37409287e-04, 1.69122578e-04,\n",
       "        1.77545606e-04, 2.73375848e-04, 9.84327754e-05, 2.64535438e-04,\n",
       "        2.61002713e-05, 4.65166807e-05, 2.01816535e-04, 1.50966139e-04,\n",
       "        6.56817103e-05, 9.68330405e-06, 3.55280128e-05, 2.83373094e-04,\n",
       "        4.20997496e-04, 1.86406367e-04, 5.50818588e-05, 1.08739842e-04,\n",
       "        1.44076163e-04, 1.14412161e-04, 1.92161332e-04, 1.96555775e-04,\n",
       "        4.10755535e-05, 5.10257846e-05, 5.92092539e-05, 2.21873081e-05,\n",
       "        1.26301753e-04, 2.28925983e-05, 5.76773698e-05, 4.25964149e-05,\n",
       "        2.53287871e-05, 1.35910208e-05, 4.68090421e-05, 5.57431725e-05,\n",
       "        3.82542757e-05, 9.98762971e-05, 9.74960657e-06, 4.75392537e-05,\n",
       "        4.15379329e-05, 3.20501343e-05, 1.36007763e-05, 2.19244289e-05,\n",
       "        1.36827248e-05, 7.86278625e-05, 3.50683393e-05, 2.09892622e-05,\n",
       "        4.97448048e-05, 1.56054426e-05, 4.64491501e-06, 6.08638630e-05,\n",
       "        5.61957980e-07, 6.18789996e-05, 4.35321249e-05, 6.95750278e-05,\n",
       "        8.36703915e-05, 5.70416970e-05, 2.97428173e-05, 2.52010431e-05,\n",
       "        1.91696050e-05, 4.38933432e-05, 1.00467589e-04, 2.68069861e-05,\n",
       "        2.87089389e-04, 2.25557361e-05, 3.93144132e-05, 1.04799423e-04,\n",
       "        3.76803616e-05, 1.97349178e-04, 3.90426146e-05, 3.47835194e-05,\n",
       "        1.92419533e-05, 3.19850370e-05, 8.33947915e-05, 6.29464182e-05,\n",
       "        3.53762257e-05, 4.39692529e-05, 1.72028913e-05, 2.58111895e-05,\n",
       "        1.18929694e-04, 1.06099274e-04, 1.92931788e-04, 3.37524089e-04,\n",
       "        8.90857082e-05, 1.15774746e-04, 1.04038200e-04, 1.19149723e-04,\n",
       "        2.18834836e-05, 1.77596184e-04, 6.26033297e-05, 1.14744059e-05,\n",
       "        3.42063966e-05, 6.77671930e-05, 2.28634923e-04, 5.05688498e-05,\n",
       "        1.14859592e-05, 3.50869012e-04, 1.55866236e-04, 2.15590021e-04,\n",
       "        6.30286419e-05, 1.66972459e-05, 8.70114222e-05, 3.12454701e-05,\n",
       "        6.11117870e-05, 1.65483029e-05, 1.44929780e-04, 1.28190486e-04,\n",
       "        3.46339404e-05, 3.82961891e-05, 7.18501462e-05, 2.23385189e-05,\n",
       "        3.98258158e-05, 2.61663301e-04, 1.94496961e-04, 2.18614280e-03,\n",
       "        3.24135551e-04, 1.38851800e-04, 1.55300698e-03, 1.71492626e-03,\n",
       "        5.81203621e-03, 2.58362319e-04, 1.93011518e-04, 1.49491301e-04,\n",
       "        2.28894750e-04, 1.64367896e-04, 1.76521977e-04, 1.17099908e-04,\n",
       "        6.95466991e-05, 8.95751854e-05, 1.43004100e-03, 1.85732307e-04,\n",
       "        1.15607578e-03, 3.62989414e-04, 3.64229743e-04, 5.09450996e-04,\n",
       "        2.67644288e-03, 1.61139920e-05, 3.46864556e-04, 5.86795005e-05,\n",
       "        9.45346954e-05, 7.30511656e-05, 6.01776974e-05, 7.62130222e-05,\n",
       "        9.22365310e-05, 3.27942654e-04, 3.93952986e-05, 2.66396535e-05,\n",
       "        3.36670522e-05, 5.14002048e-05, 7.08238298e-05, 5.46975385e-05,\n",
       "        4.05177549e-05, 6.86880023e-05, 8.83520909e-05, 1.97756423e-04,\n",
       "        9.27597060e-05, 5.90546987e-05, 7.09759825e-06, 3.21091991e-05,\n",
       "        3.54290329e-05, 2.70695807e-05, 1.55202173e-05, 1.06256519e-03,\n",
       "        7.04741911e-05, 1.25217706e-04, 2.42468188e-03, 3.53456881e-04,\n",
       "        2.46793289e-04, 6.42725854e-04, 7.43444973e-04, 1.23833460e-03,\n",
       "        5.37456330e-05, 1.73592340e-04, 3.58442861e-05, 1.58111889e-04,\n",
       "        1.42481163e-04, 2.18950916e-04, 6.26940633e-05, 4.53230744e-04,\n",
       "        2.59300663e-04, 1.80698984e-04, 2.41192129e-04, 2.18838213e-04,\n",
       "        2.83122863e-04, 2.88141454e-05, 1.39900091e-04, 5.51565201e-04]),\n",
       " 'param_subsample': masked_array(data=[0.5, 0.25, 0.15, 0.2, 0.5, 0.35, 0.2, 0.3, 0.05, 0.2,\n",
       "                    0.2, 0.45, 0.15, 0.45, 0.25, 0.45, 0.25, 0.2, 0.25,\n",
       "                    0.05, 0.4, 0.3, 0.35, 0.15, 0.45, 0.5, 0.05, 0.3, 0.35,\n",
       "                    0.35, 0.05, 0.4, 0.2, 0.15, 0.1, 0.1, 0.1, 0.4, 0.05,\n",
       "                    0.5, 0.45, 0.05, 0.5, 0.45, 0.45, 0.3, 0.45, 0.05, 0.2,\n",
       "                    0.15, 0.05, 0.4, 0.35, 0.45, 0.05, 0.1, 0.2, 0.2, 0.05,\n",
       "                    0.5, 0.35, 0.05, 0.45, 0.1, 0.4, 0.45, 0.1, 0.4, 0.4,\n",
       "                    0.25, 0.4, 0.05, 0.25, 0.2, 0.15, 0.25, 0.5, 0.3, 0.3,\n",
       "                    0.2, 0.4, 0.5, 0.45, 0.2, 0.2, 0.35, 0.45, 0.15, 0.45,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.3, 0.2, 0.25, 0.45, 0.15, 0.05,\n",
       "                    0.05, 0.2, 0.5, 0.45, 0.4, 0.4, 0.5, 0.1, 0.1, 0.05,\n",
       "                    0.4, 0.2, 0.45, 0.5, 0.5, 0.15, 0.05, 0.1, 0.1, 0.1,\n",
       "                    0.4, 0.4, 0.2, 0.45, 0.5, 0.15, 0.5, 0.45, 0.2, 0.4,\n",
       "                    0.05, 0.25, 0.2, 0.35, 0.4, 0.4, 0.3, 0.25, 0.25, 0.15,\n",
       "                    0.45, 0.15, 0.4, 0.4, 0.25, 0.1, 0.2, 0.3, 0.25, 0.1,\n",
       "                    0.35, 0.3, 0.2, 0.5, 0.5, 0.05, 0.4, 0.5, 0.25, 0.25,\n",
       "                    0.2, 0.1, 0.45, 0.15, 0.05, 0.4, 0.35, 0.1, 0.1, 0.45,\n",
       "                    0.05, 0.25, 0.2, 0.05, 0.4, 0.4, 0.5, 0.15, 0.15, 0.05,\n",
       "                    0.45, 0.25, 0.25, 0.05, 0.05, 0.15, 0.35, 0.4, 0.5,\n",
       "                    0.1, 0.45, 0.4, 0.05, 0.15, 0.1, 0.5, 0.5, 0.2, 0.45,\n",
       "                    0.25, 0.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_reg_alpha': masked_array(data=[0.1855408089572732, 0.5547112581619261,\n",
       "                    0.5547112581619261, 0.28527811086466404,\n",
       "                    0.5023266634599854, 0.35058727336955586,\n",
       "                    0.7781811945608316, 0.1855408089572732,\n",
       "                    0.35058727336955586, 0.42473628271390806,\n",
       "                    0.04654458835282671, 0.43597323264505594,\n",
       "                    0.04654458835282671, 0.04654458835282671,\n",
       "                    0.1855408089572732, 0.28527811086466404,\n",
       "                    0.7781811945608316, 0.8937745443062259,\n",
       "                    0.1855408089572732, 0.28527811086466404,\n",
       "                    0.43597323264505594, 0.7781811945608316,\n",
       "                    0.04654458835282671, 0.5023266634599854,\n",
       "                    0.5547112581619261, 0.35058727336955586,\n",
       "                    0.7781811945608316, 0.04654458835282671,\n",
       "                    0.7781811945608316, 0.5547112581619261,\n",
       "                    0.42473628271390806, 0.28527811086466404,\n",
       "                    0.1855408089572732, 0.04654458835282671,\n",
       "                    0.35058727336955586, 0.1855408089572732,\n",
       "                    0.28527811086466404, 0.5023266634599854,\n",
       "                    0.42473628271390806, 0.42473628271390806,\n",
       "                    0.8937745443062259, 0.1855408089572732,\n",
       "                    0.04654458835282671, 0.28527811086466404,\n",
       "                    0.04654458835282671, 0.5023266634599854,\n",
       "                    0.5547112581619261, 0.04654458835282671,\n",
       "                    0.42473628271390806, 0.8937745443062259,\n",
       "                    0.28527811086466404, 0.28527811086466404,\n",
       "                    0.8937745443062259, 0.42473628271390806,\n",
       "                    0.28527811086466404, 0.43597323264505594,\n",
       "                    0.28527811086466404, 0.04654458835282671,\n",
       "                    0.42473628271390806, 0.42473628271390806,\n",
       "                    0.5023266634599854, 0.43597323264505594,\n",
       "                    0.28527811086466404, 0.8937745443062259,\n",
       "                    0.42473628271390806, 0.5023266634599854,\n",
       "                    0.5023266634599854, 0.5023266634599854,\n",
       "                    0.5023266634599854, 0.28527811086466404,\n",
       "                    0.43597323264505594, 0.5547112581619261,\n",
       "                    0.1855408089572732, 0.5023266634599854,\n",
       "                    0.5547112581619261, 0.8937745443062259,\n",
       "                    0.5547112581619261, 0.04654458835282671,\n",
       "                    0.5547112581619261, 0.35058727336955586,\n",
       "                    0.5023266634599854, 0.35058727336955586,\n",
       "                    0.5547112581619261, 0.35058727336955586,\n",
       "                    0.7781811945608316, 0.28527811086466404,\n",
       "                    0.43597323264505594, 0.04654458835282671,\n",
       "                    0.28527811086466404, 0.43597323264505594,\n",
       "                    0.35058727336955586, 0.8937745443062259,\n",
       "                    0.42473628271390806, 0.35058727336955586,\n",
       "                    0.42473628271390806, 0.8937745443062259,\n",
       "                    0.42473628271390806, 0.5023266634599854,\n",
       "                    0.35058727336955586, 0.28527811086466404,\n",
       "                    0.7781811945608316, 0.5023266634599854,\n",
       "                    0.04654458835282671, 0.43597323264505594,\n",
       "                    0.8937745443062259, 0.5023266634599854,\n",
       "                    0.5023266634599854, 0.28527811086466404,\n",
       "                    0.7781811945608316, 0.7781811945608316,\n",
       "                    0.1855408089572732, 0.5547112581619261,\n",
       "                    0.42473628271390806, 0.43597323264505594,\n",
       "                    0.28527811086466404, 0.5023266634599854,\n",
       "                    0.35058727336955586, 0.7781811945608316,\n",
       "                    0.43597323264505594, 0.35058727336955586,\n",
       "                    0.42473628271390806, 0.7781811945608316,\n",
       "                    0.04654458835282671, 0.04654458835282671,\n",
       "                    0.04654458835282671, 0.1855408089572732,\n",
       "                    0.7781811945608316, 0.43597323264505594,\n",
       "                    0.8937745443062259, 0.35058727336955586,\n",
       "                    0.04654458835282671, 0.5023266634599854,\n",
       "                    0.5023266634599854, 0.8937745443062259,\n",
       "                    0.04654458835282671, 0.1855408089572732,\n",
       "                    0.43597323264505594, 0.5547112581619261,\n",
       "                    0.04654458835282671, 0.35058727336955586,\n",
       "                    0.5547112581619261, 0.5547112581619261,\n",
       "                    0.42473628271390806, 0.42473628271390806,\n",
       "                    0.5023266634599854, 0.5023266634599854,\n",
       "                    0.8937745443062259, 0.43597323264505594,\n",
       "                    0.5023266634599854, 0.7781811945608316,\n",
       "                    0.42473628271390806, 0.35058727336955586,\n",
       "                    0.43597323264505594, 0.28527811086466404,\n",
       "                    0.04654458835282671, 0.42473628271390806,\n",
       "                    0.1855408089572732, 0.28527811086466404,\n",
       "                    0.43597323264505594, 0.43597323264505594,\n",
       "                    0.43597323264505594, 0.1855408089572732,\n",
       "                    0.5023266634599854, 0.5547112581619261,\n",
       "                    0.43597323264505594, 0.43597323264505594,\n",
       "                    0.04654458835282671, 0.35058727336955586,\n",
       "                    0.42473628271390806, 0.5023266634599854,\n",
       "                    0.35058727336955586, 0.5547112581619261,\n",
       "                    0.04654458835282671, 0.28527811086466404,\n",
       "                    0.04654458835282671, 0.04654458835282671,\n",
       "                    0.5547112581619261, 0.1855408089572732,\n",
       "                    0.04654458835282671, 0.28527811086466404,\n",
       "                    0.7781811945608316, 0.04654458835282671,\n",
       "                    0.8937745443062259, 0.28527811086466404,\n",
       "                    0.5547112581619261, 0.5547112581619261,\n",
       "                    0.42473628271390806, 0.5547112581619261,\n",
       "                    0.5547112581619261, 0.42473628271390806,\n",
       "                    0.04654458835282671, 0.7781811945608316,\n",
       "                    0.43597323264505594, 0.7781811945608316,\n",
       "                    0.1855408089572732, 0.04654458835282671,\n",
       "                    0.42473628271390806, 0.43597323264505594,\n",
       "                    0.42473628271390806, 0.04654458835282671],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[1, 1, 3, 3, 3, 1, 3, 1, 3, 1, 1, 6, 6, 3, 6, 6, 3, 6,\n",
       "                    6, 1, 3, 1, 1, 6, 6, 1, 1, 3, 3, 1, 3, 3, 1, 6, 3, 1,\n",
       "                    3, 3, 6, 1, 3, 1, 1, 3, 1, 3, 1, 1, 6, 1, 3, 1, 6, 3,\n",
       "                    6, 1, 6, 3, 3, 6, 3, 1, 1, 6, 3, 3, 3, 1, 1, 6, 3, 1,\n",
       "                    1, 6, 3, 3, 6, 1, 3, 1, 3, 1, 3, 3, 6, 1, 1, 3, 6, 6,\n",
       "                    6, 3, 1, 6, 1, 1, 6, 3, 3, 6, 3, 6, 6, 1, 1, 3, 6, 3,\n",
       "                    6, 1, 3, 6, 1, 6, 6, 3, 3, 3, 3, 1, 6, 1, 6, 6, 6, 3,\n",
       "                    1, 6, 1, 3, 1, 3, 6, 6, 1, 6, 1, 6, 6, 3, 3, 1, 3, 1,\n",
       "                    6, 3, 3, 6, 1, 3, 3, 6, 6, 1, 3, 6, 6, 6, 1, 1, 3, 3,\n",
       "                    1, 6, 1, 3, 1, 6, 1, 3, 6, 6, 1, 6, 3, 1, 3, 3, 3, 6,\n",
       "                    6, 3, 3, 1, 3, 6, 6, 1, 3, 3, 1, 6, 6, 3, 6, 1, 6, 3,\n",
       "                    3, 6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[392, 19, 176, 160, 102, 231, 145, 78, 112, 439, 121,\n",
       "                    34, 273, 341, 41, 298, 354, 265, 147, 101, 206, 274,\n",
       "                    259, 19, 79, 110, 231, 150, 162, 83, 211, 369, 66, 48,\n",
       "                    227, 424, 426, 369, 405, 399, 441, 160, 426, 92, 126,\n",
       "                    257, 40, 427, 30, 63, 79, 92, 358, 259, 272, 20, 95,\n",
       "                    421, 161, 410, 439, 50, 413, 227, 385, 211, 142, 397,\n",
       "                    129, 45, 313, 45, 125, 434, 435, 218, 206, 435, 440,\n",
       "                    125, 410, 48, 380, 161, 263, 265, 422, 397, 101, 273,\n",
       "                    129, 283, 273, 435, 50, 406, 397, 283, 71, 397, 227,\n",
       "                    320, 283, 290, 162, 66, 399, 290, 274, 160, 426, 445,\n",
       "                    142, 95, 247, 19, 95, 18, 79, 45, 247, 350, 85, 445,\n",
       "                    392, 265, 227, 290, 130, 166, 257, 445, 176, 18, 72,\n",
       "                    41, 163, 434, 320, 439, 95, 95, 102, 413, 313, 18, 427,\n",
       "                    211, 378, 217, 204, 53, 285, 347, 364, 369, 199, 448,\n",
       "                    334, 434, 161, 437, 163, 399, 313, 265, 53, 261, 265,\n",
       "                    231, 145, 334, 257, 405, 441, 435, 265, 162, 227, 227,\n",
       "                    162, 39, 354, 176, 66, 406, 166, 399, 102, 205, 349,\n",
       "                    405, 369, 21, 322, 290, 176, 440, 41, 228],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_delta_step': masked_array(data=[2, 7, 8, 2, 7, 5, 3, 8, 5, 8, 5, 5, 4, 4, 5, 6, 1, 7,\n",
       "                    3, 1, 5, 1, 5, 7, 6, 3, 4, 4, 4, 7, 6, 4, 6, 8, 6, 2,\n",
       "                    7, 7, 7, 2, 1, 4, 2, 8, 8, 2, 4, 7, 6, 1, 5, 6, 7, 3,\n",
       "                    8, 4, 5, 3, 1, 2, 2, 4, 4, 6, 7, 8, 6, 1, 4, 8, 7, 2,\n",
       "                    1, 1, 8, 8, 3, 2, 6, 7, 8, 2, 5, 6, 1, 3, 7, 1, 2, 3,\n",
       "                    4, 7, 7, 1, 6, 4, 3, 7, 6, 8, 7, 3, 7, 1, 4, 3, 2, 6,\n",
       "                    3, 1, 7, 5, 7, 7, 6, 7, 2, 7, 8, 8, 4, 2, 1, 3, 3, 2,\n",
       "                    7, 5, 2, 2, 1, 3, 5, 5, 8, 8, 6, 7, 4, 5, 2, 7, 3, 2,\n",
       "                    6, 8, 8, 6, 7, 5, 8, 1, 7, 3, 6, 4, 5, 5, 4, 5, 3, 8,\n",
       "                    4, 4, 5, 5, 6, 3, 8, 4, 7, 8, 7, 3, 7, 1, 5, 4, 1, 6,\n",
       "                    1, 2, 6, 7, 2, 2, 3, 5, 8, 2, 7, 5, 6, 8, 5, 3, 5, 8,\n",
       "                    6, 3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.4, 0.25, 0.2, 0.4, 0.15, 0.45, 0.4, 0.25, 0.45, 0.5,\n",
       "                    0.3, 0.15, 0.2, 0.5, 0.5, 0.25, 0.2, 0.2, 0.05, 0.35,\n",
       "                    0.5, 0.3, 0.45, 0.1, 0.25, 0.3, 0.4, 0.05, 0.2, 0.4,\n",
       "                    0.45, 0.15, 0.35, 0.15, 0.2, 0.2, 0.05, 0.2, 0.25,\n",
       "                    0.35, 0.35, 0.35, 0.1, 0.45, 0.45, 0.1, 0.4, 0.15,\n",
       "                    0.25, 0.25, 0.5, 0.2, 0.45, 0.25, 0.15, 0.45, 0.2,\n",
       "                    0.35, 0.2, 0.3, 0.15, 0.1, 0.4, 0.15, 0.3, 0.1, 0.5,\n",
       "                    0.4, 0.3, 0.2, 0.3, 0.1, 0.1, 0.05, 0.1, 0.1, 0.15,\n",
       "                    0.2, 0.3, 0.3, 0.05, 0.3, 0.1, 0.45, 0.45, 0.25, 0.4,\n",
       "                    0.5, 0.3, 0.25, 0.15, 0.45, 0.45, 0.05, 0.05, 0.15,\n",
       "                    0.25, 0.25, 0.5, 0.45, 0.3, 0.15, 0.15, 0.15, 0.1, 0.5,\n",
       "                    0.35, 0.05, 0.2, 0.05, 0.1, 0.05, 0.3, 0.25, 0.1, 0.35,\n",
       "                    0.45, 0.25, 0.1, 0.1, 0.05, 0.2, 0.3, 0.15, 0.15, 0.5,\n",
       "                    0.45, 0.5, 0.4, 0.5, 0.1, 0.1, 0.5, 0.2, 0.2, 0.5, 0.4,\n",
       "                    0.35, 0.3, 0.1, 0.1, 0.15, 0.25, 0.25, 0.05, 0.05, 0.1,\n",
       "                    0.1, 0.4, 0.05, 0.05, 0.25, 0.5, 0.4, 0.05, 0.45, 0.5,\n",
       "                    0.45, 0.5, 0.2, 0.35, 0.3, 0.15, 0.05, 0.45, 0.1, 0.45,\n",
       "                    0.15, 0.05, 0.45, 0.3, 0.5, 0.25, 0.45, 0.05, 0.15,\n",
       "                    0.15, 0.3, 0.45, 0.1, 0.2, 0.5, 0.2, 0.45, 0.1, 0.15,\n",
       "                    0.05, 0.5, 0.1, 0.1, 0.4, 0.1, 0.4, 0.25, 0.4, 0.05,\n",
       "                    0.3, 0.05, 0.05, 0.3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[4, 5, 1, 4, 1, 2, 2, 2, 3, 2, 5, 4, 2, 3, 1, 1, 3, 4,\n",
       "                    5, 1, 2, 5, 5, 5, 1, 3, 3, 2, 4, 2, 3, 5, 1, 3, 2, 4,\n",
       "                    5, 5, 1, 3, 2, 2, 2, 3, 3, 3, 4, 3, 2, 5, 3, 1, 2, 4,\n",
       "                    4, 1, 1, 5, 1, 1, 3, 5, 2, 4, 4, 3, 3, 3, 2, 2, 5, 5,\n",
       "                    4, 4, 1, 5, 1, 3, 3, 5, 5, 2, 2, 3, 3, 3, 1, 3, 1, 1,\n",
       "                    3, 5, 3, 1, 1, 1, 1, 4, 4, 5, 1, 5, 1, 2, 3, 5, 4, 4,\n",
       "                    5, 2, 3, 2, 3, 4, 4, 4, 5, 2, 3, 4, 5, 4, 2, 3, 2, 1,\n",
       "                    3, 3, 1, 2, 4, 3, 4, 2, 3, 4, 1, 5, 4, 2, 5, 2, 3, 3,\n",
       "                    4, 3, 2, 3, 1, 3, 1, 2, 1, 4, 4, 5, 4, 1, 4, 5, 1, 5,\n",
       "                    3, 3, 4, 2, 4, 5, 5, 1, 3, 3, 3, 3, 5, 3, 5, 2, 1, 4,\n",
       "                    5, 4, 2, 3, 2, 1, 5, 2, 2, 3, 5, 5, 5, 4, 5, 3, 5, 5,\n",
       "                    1, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_colsample_bytree': masked_array(data=[0.8107032835376461, 0.5009225345925948,\n",
       "                    0.1954258452471287, 0.1954258452471287,\n",
       "                    0.1954258452471287, 0.1954258452471287,\n",
       "                    0.9744996392090239, 0.1954258452471287,\n",
       "                    0.1954258452471287, 0.9744996392090239,\n",
       "                    0.9744996392090239, 0.6285508520018352,\n",
       "                    0.9744996392090239, 0.9501984500126606,\n",
       "                    0.1954258452471287, 0.6285508520018352,\n",
       "                    0.9501984500126606, 0.5009225345925948,\n",
       "                    0.8107032835376461, 0.9501984500126606,\n",
       "                    0.5009225345925948, 0.9501984500126606,\n",
       "                    0.6285508520018352, 0.9501984500126606,\n",
       "                    0.5009225345925948, 0.9744996392090239,\n",
       "                    0.8107032835376461, 0.9744996392090239,\n",
       "                    0.8107032835376461, 0.1954258452471287,\n",
       "                    0.6285508520018352, 0.9744996392090239,\n",
       "                    0.5009225345925948, 0.9501984500126606,\n",
       "                    0.5009225345925948, 0.8107032835376461,\n",
       "                    0.5009225345925948, 0.1954258452471287,\n",
       "                    0.9744996392090239, 0.9501984500126606,\n",
       "                    0.8107032835376461, 0.1954258452471287,\n",
       "                    0.1954258452471287, 0.6285508520018352,\n",
       "                    0.5009225345925948, 0.5009225345925948,\n",
       "                    0.1954258452471287, 0.9744996392090239,\n",
       "                    0.9744996392090239, 0.6285508520018352,\n",
       "                    0.6285508520018352, 0.5009225345925948,\n",
       "                    0.5009225345925948, 0.5009225345925948,\n",
       "                    0.6285508520018352, 0.6285508520018352,\n",
       "                    0.8107032835376461, 0.5009225345925948,\n",
       "                    0.9744996392090239, 0.8107032835376461,\n",
       "                    0.8107032835376461, 0.9501984500126606,\n",
       "                    0.5009225345925948, 0.9744996392090239,\n",
       "                    0.9501984500126606, 0.1954258452471287,\n",
       "                    0.1954258452471287, 0.9744996392090239,\n",
       "                    0.1954258452471287, 0.5009225345925948,\n",
       "                    0.8107032835376461, 0.1954258452471287,\n",
       "                    0.9501984500126606, 0.9501984500126606,\n",
       "                    0.5009225345925948, 0.5009225345925948,\n",
       "                    0.5009225345925948, 0.1954258452471287,\n",
       "                    0.1954258452471287, 0.8107032835376461,\n",
       "                    0.9744996392090239, 0.8107032835376461,\n",
       "                    0.8107032835376461, 0.1954258452471287,\n",
       "                    0.6285508520018352, 0.5009225345925948,\n",
       "                    0.1954258452471287, 0.9501984500126606,\n",
       "                    0.8107032835376461, 0.9501984500126606,\n",
       "                    0.8107032835376461, 0.8107032835376461,\n",
       "                    0.6285508520018352, 0.6285508520018352,\n",
       "                    0.9501984500126606, 0.5009225345925948,\n",
       "                    0.8107032835376461, 0.1954258452471287,\n",
       "                    0.1954258452471287, 0.1954258452471287,\n",
       "                    0.8107032835376461, 0.1954258452471287,\n",
       "                    0.8107032835376461, 0.8107032835376461,\n",
       "                    0.9501984500126606, 0.9501984500126606,\n",
       "                    0.6285508520018352, 0.9744996392090239,\n",
       "                    0.5009225345925948, 0.9744996392090239,\n",
       "                    0.8107032835376461, 0.9501984500126606,\n",
       "                    0.8107032835376461, 0.9744996392090239,\n",
       "                    0.9501984500126606, 0.1954258452471287,\n",
       "                    0.8107032835376461, 0.1954258452471287,\n",
       "                    0.8107032835376461, 0.9501984500126606,\n",
       "                    0.8107032835376461, 0.5009225345925948,\n",
       "                    0.9744996392090239, 0.8107032835376461,\n",
       "                    0.6285508520018352, 0.8107032835376461,\n",
       "                    0.1954258452471287, 0.1954258452471287,\n",
       "                    0.1954258452471287, 0.5009225345925948,\n",
       "                    0.6285508520018352, 0.9501984500126606,\n",
       "                    0.6285508520018352, 0.8107032835376461,\n",
       "                    0.6285508520018352, 0.6285508520018352,\n",
       "                    0.6285508520018352, 0.9501984500126606,\n",
       "                    0.8107032835376461, 0.1954258452471287,\n",
       "                    0.9501984500126606, 0.1954258452471287,\n",
       "                    0.8107032835376461, 0.8107032835376461,\n",
       "                    0.1954258452471287, 0.1954258452471287,\n",
       "                    0.6285508520018352, 0.9501984500126606,\n",
       "                    0.8107032835376461, 0.1954258452471287,\n",
       "                    0.8107032835376461, 0.8107032835376461,\n",
       "                    0.1954258452471287, 0.1954258452471287,\n",
       "                    0.8107032835376461, 0.6285508520018352,\n",
       "                    0.6285508520018352, 0.6285508520018352,\n",
       "                    0.9744996392090239, 0.6285508520018352,\n",
       "                    0.9744996392090239, 0.9501984500126606,\n",
       "                    0.5009225345925948, 0.9501984500126606,\n",
       "                    0.9501984500126606, 0.9501984500126606,\n",
       "                    0.5009225345925948, 0.5009225345925948,\n",
       "                    0.8107032835376461, 0.5009225345925948,\n",
       "                    0.9501984500126606, 0.9744996392090239,\n",
       "                    0.5009225345925948, 0.5009225345925948,\n",
       "                    0.9744996392090239, 0.8107032835376461,\n",
       "                    0.9744996392090239, 0.5009225345925948,\n",
       "                    0.6285508520018352, 0.1954258452471287,\n",
       "                    0.1954258452471287, 0.6285508520018352,\n",
       "                    0.5009225345925948, 0.8107032835376461,\n",
       "                    0.9501984500126606, 0.9501984500126606,\n",
       "                    0.8107032835376461, 0.5009225345925948,\n",
       "                    0.8107032835376461, 0.9501984500126606,\n",
       "                    0.8107032835376461, 0.6285508520018352,\n",
       "                    0.6285508520018352, 0.6285508520018352,\n",
       "                    0.8107032835376461, 0.9744996392090239,\n",
       "                    0.1954258452471287, 0.9501984500126606,\n",
       "                    0.1954258452471287, 0.9744996392090239],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'subsample': 0.5,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 392,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 19,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 176,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 160,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 102,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.35,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 231,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 145,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.3,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 78,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 112,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 439,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 121,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 34,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 273,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 341,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 41,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 298,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 354,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 265,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 147,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 101,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.35,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 206,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.3,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 274,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.35,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 259,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 19,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 79,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 110,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 231,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.3,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 150,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.35,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 162,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.35,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 83,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 211,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 369,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 66,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.35,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 48,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 227,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 424,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 426,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 369,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 405,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 399,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.35,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 441,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.35,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 160,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.35,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 426,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 92,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 126,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.3,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 257,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 40,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 427,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 30,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 63,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 79,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 92,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.35,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 358,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 259,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 272,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 20,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 95,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 421,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.35,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 161,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 410,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.35,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 439,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 50,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 413,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 227,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 385,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 211,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 142,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 397,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 129,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 45,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 313,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 45,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 125,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 434,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 435,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 218,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 206,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.3,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 435,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.3,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 440,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 125,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 410,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 48,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 380,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 161,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 263,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.35,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 265,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 422,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 397,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 101,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 273,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 129,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 283,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 273,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.3,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 435,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 50,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 406,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 397,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 283,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 71,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 397,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 227,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 320,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 283,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 290,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 162,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 66,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 399,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.35,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 290,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 274,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 160,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 426,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 445,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 142,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 95,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 247,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 19,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.35,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 95,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 18,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 79,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 45,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 247,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 350,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 85,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 445,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 392,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 265,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 227,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 290,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 130,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 166,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 257,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 445,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.35,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 176,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 18,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 72,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.3,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 41,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 163,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 434,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.35,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 320,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 439,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 95,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 95,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 102,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 413,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 313,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 18,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.3,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 427,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 211,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 378,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.35,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 217,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.3,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 204,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 53,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 285,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 347,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 364,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 369,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 199,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 448,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 334,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 434,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 161,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.35,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 437,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 163,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 399,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 313,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.35,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 265,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 53,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 261,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 265,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.5023266634599854,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 231,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.35058727336955586,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 145,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 334,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 257,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 405,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 441,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 435,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 265,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 162,\n",
       "   'max_delta_step': 4,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 227,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 227,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 162,\n",
       "   'max_delta_step': 1,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 39,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.8937745443062259,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 354,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.28527811086466404,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 176,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.45,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 66,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.35,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 406,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.15,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 166,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 399,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.5,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.5009225345925948},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.5547112581619261,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 102,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 2,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 205,\n",
       "   'max_delta_step': 2,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.4,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 349,\n",
       "   'max_delta_step': 7,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.05,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 405,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.15,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 369,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.1,\n",
       "   'reg_alpha': 0.7781811945608316,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 21,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.25,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.6285508520018352},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.1855408089572732,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 322,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.4,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.8107032835376461},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 1,\n",
       "   'max_depth': 290,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 3,\n",
       "   'colsample_bytree': 0.9744996392090239},\n",
       "  {'subsample': 0.2,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 176,\n",
       "   'max_delta_step': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.45,\n",
       "   'reg_alpha': 0.43597323264505594,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 440,\n",
       "   'max_delta_step': 8,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 5,\n",
       "   'colsample_bytree': 0.9501984500126606},\n",
       "  {'subsample': 0.25,\n",
       "   'reg_alpha': 0.42473628271390806,\n",
       "   'min_child_weight': 3,\n",
       "   'max_depth': 41,\n",
       "   'max_delta_step': 6,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 1,\n",
       "   'colsample_bytree': 0.1954258452471287},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_alpha': 0.04654458835282671,\n",
       "   'min_child_weight': 6,\n",
       "   'max_depth': 228,\n",
       "   'max_delta_step': 3,\n",
       "   'learning_rate': 0.3,\n",
       "   'gamma': 4,\n",
       "   'colsample_bytree': 0.9744996392090239}],\n",
       " 'split0_test_score': array([0.93984962, 0.93984962, 0.92481203, 0.93984962, 0.93984962,\n",
       "        0.93233083, 0.93233083, 0.93984962, 0.62406015, 0.94736842,\n",
       "        0.93984962, 0.91729323, 0.62406015, 0.92481203, 0.90977444,\n",
       "        0.92481203, 0.92481203, 0.90225564, 0.91729323, 0.92481203,\n",
       "        0.93233083, 0.93984962, 0.94736842, 0.62406015, 0.92481203,\n",
       "        0.94736842, 0.91729323, 0.93233083, 0.93233083, 0.93233083,\n",
       "        0.62406015, 0.93233083, 0.93984962, 0.62406015, 0.90225564,\n",
       "        0.91729323, 0.91729323, 0.93233083, 0.62406015, 0.95488722,\n",
       "        0.95488722, 0.89473684, 0.93984962, 0.92481203, 0.95488722,\n",
       "        0.93984962, 0.91729323, 0.90977444, 0.91729323, 0.92481203,\n",
       "        0.62406015, 0.95488722, 0.90977444, 0.94736842, 0.62406015,\n",
       "        0.94736842, 0.90977444, 0.92481203, 0.62406015, 0.93233083,\n",
       "        0.93233083, 0.90977444, 0.94736842, 0.62406015, 0.95488722,\n",
       "        0.92481203, 0.90977444, 0.93233083, 0.93233083, 0.93233083,\n",
       "        0.94736842, 0.89473684, 0.93984962, 0.89473684, 0.91729323,\n",
       "        0.93984962, 0.93984962, 0.93984962, 0.93984962, 0.91729323,\n",
       "        0.93984962, 0.94736842, 0.93984962, 0.95488722, 0.90977444,\n",
       "        0.93233083, 0.94736842, 0.92481203, 0.91729323, 0.93233083,\n",
       "        0.93984962, 0.93984962, 0.95488722, 0.92481203, 0.93984962,\n",
       "        0.93984962, 0.91729323, 0.93233083, 0.62406015, 0.62406015,\n",
       "        0.92481203, 0.92481203, 0.93233083, 0.95488722, 0.95488722,\n",
       "        0.93233083, 0.62406015, 0.92481203, 0.62406015, 0.94736842,\n",
       "        0.93233083, 0.92481203, 0.93984962, 0.91729323, 0.62406015,\n",
       "        0.62406015, 0.80451128, 0.92481203, 0.88721805, 0.94736842,\n",
       "        0.93984962, 0.94736842, 0.90225564, 0.93984962, 0.62406015,\n",
       "        0.93233083, 0.91729323, 0.83458647, 0.93984962, 0.62406015,\n",
       "        0.93984962, 0.92481203, 0.93984962, 0.92481203, 0.94736842,\n",
       "        0.92481203, 0.95488722, 0.90977444, 0.84962406, 0.93233083,\n",
       "        0.90977444, 0.93984962, 0.93984962, 0.93233083, 0.62406015,\n",
       "        0.92481203, 0.94736842, 0.91729323, 0.93984962, 0.91729323,\n",
       "        0.93233083, 0.91729323, 0.94736842, 0.93233083, 0.62406015,\n",
       "        0.93233083, 0.92481203, 0.93233083, 0.96240602, 0.93984962,\n",
       "        0.86466165, 0.93984962, 0.93984962, 0.62406015, 0.93984962,\n",
       "        0.94736842, 0.92481203, 0.62406015, 0.92481203, 0.62406015,\n",
       "        0.90977444, 0.84210526, 0.91729323, 0.92481203, 0.93233083,\n",
       "        0.94736842, 0.92481203, 0.92481203, 0.62406015, 0.90977444,\n",
       "        0.90977444, 0.93233083, 0.62406015, 0.89473684, 0.93233083,\n",
       "        0.91729323, 0.93984962, 0.95488722, 0.90225564, 0.95488722,\n",
       "        0.94736842, 0.62406015, 0.84962406, 0.90977444, 0.93984962,\n",
       "        0.93984962, 0.90225564, 0.92481203, 0.93233083, 0.93233083]),\n",
       " 'split1_test_score': array([0.97744361, 0.96240602, 0.94736842, 0.96992481, 0.96240602,\n",
       "        0.98496241, 0.96992481, 0.97744361, 0.62406015, 0.96240602,\n",
       "        0.96240602, 0.96240602, 0.62406015, 0.95488722, 0.93984962,\n",
       "        0.96992481, 0.95488722, 0.96240602, 0.94736842, 0.92481203,\n",
       "        0.97744361, 0.96240602, 0.9924812 , 0.62406015, 0.94736842,\n",
       "        0.97744361, 0.94736842, 0.96240602, 0.96992481, 0.96992481,\n",
       "        0.62406015, 0.97744361, 0.97744361, 0.62406015, 0.94736842,\n",
       "        0.96240602, 0.94736842, 0.94736842, 0.62406015, 0.97744361,\n",
       "        0.96992481, 0.94736842, 0.97744361, 0.96992481, 0.96992481,\n",
       "        0.96992481, 0.95488722, 0.93984962, 0.93984962, 0.94736842,\n",
       "        0.62406015, 0.97744361, 0.96240602, 0.96240602, 0.62406015,\n",
       "        0.96240602, 0.93984962, 0.96240602, 0.62406015, 0.96240602,\n",
       "        0.96992481, 0.91729323, 0.96992481, 0.62406015, 0.96992481,\n",
       "        0.96240602, 0.90977444, 0.96992481, 0.9924812 , 0.93984962,\n",
       "        0.96992481, 0.90977444, 0.97744361, 0.93233083, 0.93984962,\n",
       "        0.93233083, 0.96240602, 0.98496241, 0.96992481, 0.96240602,\n",
       "        0.96992481, 0.97744361, 0.96992481, 0.96992481, 0.93233083,\n",
       "        0.98496241, 0.97744361, 0.94736842, 0.95488722, 0.96992481,\n",
       "        0.95488722, 0.96992481, 0.97744361, 0.93233083, 0.96992481,\n",
       "        0.98496241, 0.95488722, 0.94736842, 0.62406015, 0.62406015,\n",
       "        0.96240602, 0.95488722, 0.96240602, 0.97744361, 0.96240602,\n",
       "        0.95488722, 0.62406015, 0.96240602, 0.62406015, 0.96240602,\n",
       "        0.95488722, 0.95488722, 0.97744361, 0.95488722, 0.62406015,\n",
       "        0.62406015, 0.95488722, 0.93984962, 0.93233083, 0.97744361,\n",
       "        0.96992481, 0.95488722, 0.93984962, 0.95488722, 0.62406015,\n",
       "        0.96992481, 0.95488722, 0.93233083, 0.96992481, 0.62406015,\n",
       "        0.97744361, 0.95488722, 0.96240602, 0.96240602, 0.98496241,\n",
       "        0.96992481, 0.97744361, 0.93233083, 0.62406015, 0.96240602,\n",
       "        0.94736842, 0.97744361, 0.96992481, 0.97744361, 0.62406015,\n",
       "        0.95488722, 0.97744361, 0.94736842, 0.95488722, 0.96992481,\n",
       "        0.96240602, 0.94736842, 0.93984962, 0.96240602, 0.62406015,\n",
       "        0.97744361, 0.97744361, 0.98496241, 0.98496241, 0.95488722,\n",
       "        0.93984962, 0.96240602, 0.96240602, 0.62406015, 0.97744361,\n",
       "        0.97744361, 0.98496241, 0.62406015, 0.96992481, 0.62406015,\n",
       "        0.93233083, 0.92481203, 0.95488722, 0.97744361, 0.96240602,\n",
       "        0.97744361, 0.93984962, 0.96240602, 0.62406015, 0.93233083,\n",
       "        0.93984962, 0.96240602, 0.62406015, 0.96992481, 0.94736842,\n",
       "        0.94736842, 0.96992481, 0.97744361, 0.93233083, 0.96992481,\n",
       "        0.97744361, 0.62406015, 0.93233083, 0.97744361, 0.96992481,\n",
       "        0.97744361, 0.96240602, 0.96992481, 0.96240602, 0.95488722]),\n",
       " 'split2_test_score': array([0.93939394, 0.93939394, 0.9469697 , 0.96212121, 0.97727273,\n",
       "        0.98484848, 0.9469697 , 0.96212121, 0.62878788, 0.96969697,\n",
       "        0.9469697 , 0.9469697 , 0.62878788, 0.96969697, 0.90151515,\n",
       "        0.93939394, 0.93181818, 0.96212121, 0.95454545, 0.95454545,\n",
       "        0.95454545, 0.96969697, 0.93939394, 0.62878788, 0.9469697 ,\n",
       "        0.96969697, 0.93181818, 0.95454545, 0.95454545, 0.97727273,\n",
       "        0.62878788, 0.95454545, 0.98484848, 0.62878788, 0.93939394,\n",
       "        0.95454545, 0.93181818, 0.95454545, 0.62878788, 0.95454545,\n",
       "        0.95454545, 0.93181818, 0.96969697, 0.96969697, 0.95454545,\n",
       "        0.96212121, 0.96212121, 0.93181818, 0.9469697 , 0.93939394,\n",
       "        0.62878788, 0.98484848, 0.9469697 , 0.96212121, 0.62878788,\n",
       "        0.98484848, 0.9469697 , 0.9469697 , 0.62878788, 0.9469697 ,\n",
       "        0.96969697, 0.89393939, 0.96212121, 0.62878788, 0.96212121,\n",
       "        0.96969697, 0.92424242, 0.96969697, 0.97727273, 0.93939394,\n",
       "        0.95454545, 0.87878788, 0.93181818, 0.95454545, 0.95454545,\n",
       "        0.9469697 , 0.9469697 , 0.96969697, 0.95454545, 0.93939394,\n",
       "        0.9469697 , 0.96969697, 0.96212121, 0.9469697 , 0.96212121,\n",
       "        0.96969697, 0.96212121, 0.95454545, 0.93939394, 0.9469697 ,\n",
       "        0.96212121, 0.95454545, 0.96212121, 0.93939394, 0.93181818,\n",
       "        0.98484848, 0.93939394, 0.95454545, 0.62878788, 0.62878788,\n",
       "        0.93939394, 0.9469697 , 0.93939394, 0.98484848, 0.96212121,\n",
       "        0.95454545, 0.62878788, 0.95454545, 0.62878788, 0.9469697 ,\n",
       "        0.9469697 , 0.9469697 , 0.96212121, 0.95454545, 0.62878788,\n",
       "        0.62878788, 0.93181818, 0.9469697 , 0.95454545, 0.95454545,\n",
       "        0.93939394, 0.96969697, 0.9469697 , 0.95454545, 0.62878788,\n",
       "        0.96212121, 0.96212121, 0.96212121, 0.97727273, 0.62878788,\n",
       "        0.96212121, 0.95454545, 0.93939394, 0.93939394, 0.96212121,\n",
       "        0.9469697 , 0.96969697, 0.93181818, 0.9469697 , 0.96969697,\n",
       "        0.93939394, 0.98484848, 0.9469697 , 0.96212121, 0.62878788,\n",
       "        0.95454545, 0.96969697, 0.9469697 , 0.98484848, 0.96969697,\n",
       "        0.95454545, 0.9469697 , 0.93939394, 0.96212121, 0.62878788,\n",
       "        0.93181818, 0.9469697 , 0.93939394, 0.93939394, 0.96212121,\n",
       "        0.95454545, 0.96969697, 0.96212121, 0.62878788, 0.96212121,\n",
       "        0.96969697, 0.93939394, 0.62878788, 0.9469697 , 0.62878788,\n",
       "        0.93181818, 0.93181818, 0.90909091, 0.95454545, 0.95454545,\n",
       "        0.96212121, 0.93939394, 0.97727273, 0.62878788, 0.9469697 ,\n",
       "        0.93939394, 0.93939394, 0.62878788, 0.93181818, 0.93939394,\n",
       "        0.9469697 , 0.93939394, 0.96969697, 0.95454545, 0.96969697,\n",
       "        0.9469697 , 0.62878788, 0.9469697 , 0.93181818, 0.95454545,\n",
       "        0.95454545, 0.93939394, 0.9469697 , 0.96212121, 0.9469697 ]),\n",
       " 'mean_test_score': array([0.95222906, 0.94721653, 0.93971672, 0.95729855, 0.95984279,\n",
       "        0.96738057, 0.94974178, 0.95980482, 0.62563606, 0.9598238 ,\n",
       "        0.94974178, 0.94222298, 0.62563606, 0.94979874, 0.9170464 ,\n",
       "        0.94471026, 0.93717248, 0.94226096, 0.9397357 , 0.93472317,\n",
       "        0.9547733 , 0.95731754, 0.95974785, 0.62563606, 0.93971672,\n",
       "        0.96483633, 0.93215995, 0.94976077, 0.95226703, 0.95984279,\n",
       "        0.62563606, 0.9547733 , 0.96738057, 0.62563606, 0.92967267,\n",
       "        0.94474823, 0.93215995, 0.94474823, 0.62563606, 0.96229209,\n",
       "        0.95978583, 0.92464115, 0.96233007, 0.95481127, 0.95978583,\n",
       "        0.95729855, 0.94476722, 0.92714741, 0.93470418, 0.93719146,\n",
       "        0.62563606, 0.9723931 , 0.93971672, 0.95729855, 0.62563606,\n",
       "        0.96487431, 0.93219792, 0.94472925, 0.62563606, 0.94723551,\n",
       "        0.95731754, 0.90700235, 0.95980482, 0.62563606, 0.96231108,\n",
       "        0.952305  , 0.9145971 , 0.95731754, 0.96736159, 0.93719146,\n",
       "        0.95727956, 0.89443305, 0.9497038 , 0.92720437, 0.93722944,\n",
       "        0.93971672, 0.94974178, 0.96483633, 0.9547733 , 0.93969773,\n",
       "        0.95224804, 0.96483633, 0.95729855, 0.95726058, 0.93474216,\n",
       "        0.96233007, 0.96231108, 0.94224197, 0.93719146, 0.94974178,\n",
       "        0.95228602, 0.9547733 , 0.96481735, 0.93217893, 0.94719754,\n",
       "        0.96988684, 0.93719146, 0.94474823, 0.62563606, 0.62563606,\n",
       "        0.94220399, 0.94222298, 0.94471026, 0.9723931 , 0.95980482,\n",
       "        0.9472545 , 0.62563606, 0.9472545 , 0.62563606, 0.95224804,\n",
       "        0.94472925, 0.94222298, 0.95980482, 0.94224197, 0.62563606,\n",
       "        0.62563606, 0.89707223, 0.93721045, 0.92469811, 0.95978583,\n",
       "        0.94972279, 0.95731754, 0.92969165, 0.94976077, 0.62563606,\n",
       "        0.95479228, 0.94476722, 0.9096795 , 0.96234905, 0.62563606,\n",
       "        0.95980482, 0.94474823, 0.94721653, 0.94220399, 0.96481735,\n",
       "        0.94723551, 0.9673426 , 0.92464115, 0.80688464, 0.95481127,\n",
       "        0.93217893, 0.96738057, 0.95224804, 0.95729855, 0.62563606,\n",
       "        0.94474823, 0.96483633, 0.93721045, 0.95986178, 0.952305  ,\n",
       "        0.94976077, 0.93721045, 0.94220399, 0.95228602, 0.62563606,\n",
       "        0.94719754, 0.94974178, 0.95222906, 0.96225412, 0.95228602,\n",
       "        0.91968558, 0.95731754, 0.95479228, 0.62563606, 0.95980482,\n",
       "        0.96483633, 0.94972279, 0.62563606, 0.94723551, 0.62563606,\n",
       "        0.92464115, 0.89957849, 0.92709045, 0.95226703, 0.94976077,\n",
       "        0.96231108, 0.9346852 , 0.95483026, 0.62563606, 0.92969165,\n",
       "        0.92967267, 0.94471026, 0.62563606, 0.93215995, 0.93969773,\n",
       "        0.93721045, 0.94972279, 0.9673426 , 0.92971064, 0.96483633,\n",
       "        0.95726058, 0.62563606, 0.90964153, 0.93967874, 0.9547733 ,\n",
       "        0.95727956, 0.9346852 , 0.94723551, 0.95228602, 0.94472925]),\n",
       " 'std_test_score': array([0.01783035, 0.0107422 , 0.01054046, 0.01274291, 0.01538505,\n",
       "        0.02478396, 0.01547235, 0.01543484, 0.00222867, 0.00929666,\n",
       "        0.00941492, 0.01872056, 0.00222867, 0.01867412, 0.01647309,\n",
       "        0.01879695, 0.01284862, 0.02828827, 0.01613745, 0.01401647,\n",
       "        0.01841792, 0.01270526, 0.02337381, 0.00222867, 0.01054046,\n",
       "        0.01275013, 0.01228052, 0.01273575, 0.01543201, 0.01968382,\n",
       "        0.00222867, 0.01841792, 0.01970064, 0.00222867, 0.01965822,\n",
       "        0.01967706, 0.01228052, 0.0092564 , 0.00222867, 0.01071465,\n",
       "        0.0071707 , 0.02207794, 0.01620762, 0.02121287, 0.0071707 ,\n",
       "        0.01274291, 0.01965024, 0.01271459, 0.0126499 , 0.00933937,\n",
       "        0.00222867, 0.01274232, 0.02209035, 0.00702262, 0.00222867,\n",
       "        0.01540039, 0.01612004, 0.01542923, 0.00222867, 0.01227958,\n",
       "        0.01766852, 0.00973358, 0.00935314, 0.00222867, 0.00614054,\n",
       "        0.01966702, 0.00682028, 0.01766852, 0.02553677, 0.00344202,\n",
       "        0.00940936, 0.01265203, 0.01988716, 0.02468438, 0.0153206 ,\n",
       "        0.00597703, 0.00941492, 0.01873517, 0.0122792 , 0.01841847,\n",
       "        0.0128329 , 0.01275013, 0.01274291, 0.00952047, 0.02143839,\n",
       "        0.02210919, 0.01227888, 0.01266832, 0.01542649, 0.01547235,\n",
       "        0.00927651, 0.0122792 , 0.00940388, 0.00595401, 0.01640168,\n",
       "        0.02123957, 0.01542649, 0.0092564 , 0.00222867, 0.00222867,\n",
       "        0.01547577, 0.01272865, 0.01284073, 0.01274232, 0.00347921,\n",
       "        0.01055355, 0.00222867, 0.01619044, 0.00222867, 0.00718461,\n",
       "        0.00934389, 0.01272865, 0.01543484, 0.01764197, 0.00222867,\n",
       "        0.00222867, 0.06612459, 0.00923632, 0.02801117, 0.01282512,\n",
       "        0.0142862 , 0.00927617, 0.01961674, 0.00700962, 0.00222867,\n",
       "        0.01619901, 0.01965024, 0.05447378, 0.01618984, 0.00222867,\n",
       "        0.01543484, 0.01409772, 0.0107422 , 0.01547577, 0.01546563,\n",
       "        0.01841818, 0.00935788, 0.01051444, 0.13524703, 0.01617235,\n",
       "        0.01617342, 0.01970064, 0.0128329 , 0.01873027, 0.00222867,\n",
       "        0.01409772, 0.01275013, 0.01408454, 0.01870444, 0.02475724,\n",
       "        0.01273575, 0.01408454, 0.00365654, 0.01411093, 0.00222867,\n",
       "        0.02138822, 0.02157598, 0.02332489, 0.01860356, 0.00927651,\n",
       "        0.03936763, 0.01270526, 0.0105667 , 0.00222867, 0.01543484,\n",
       "        0.01275013, 0.0256194 , 0.00222867, 0.01841818, 0.00222867,\n",
       "        0.01051444, 0.04074024, 0.01993848, 0.02154707, 0.01273575,\n",
       "        0.01227888, 0.00698386, 0.02207676, 0.00222867, 0.01529915,\n",
       "        0.0140714 , 0.01284073, 0.00222867, 0.03069631, 0.00614283,\n",
       "        0.01408454, 0.0142862 , 0.00935788, 0.02142748, 0.0070357 ,\n",
       "        0.01427249, 0.00222867, 0.04285749, 0.02817943, 0.0122792 ,\n",
       "        0.01546897, 0.02478099, 0.01841818, 0.01411093, 0.00934389]),\n",
       " 'rank_test_score': array([ 76,  98, 125,  46,  28,   4,  83,  31, 175,  30,  83, 118, 175,\n",
       "         78, 166, 112, 141, 115, 124, 143,  60,  41,  40, 175, 125,  11,\n",
       "        150,  79,  71,  28, 175,  60,   4, 175, 156, 104, 150, 104, 175,\n",
       "         25,  37, 162,  20,  56,  37,  46, 102, 159, 144, 137, 175,   1,\n",
       "        125,  46, 175,  10, 147, 109, 175,  94,  41, 170,  31, 175,  22,\n",
       "         65, 167,  41,   7, 137,  51, 173,  91, 158, 132, 125,  83,  11,\n",
       "         60, 129,  73,  11,  46,  53, 142,  20,  22, 116, 137,  83,  67,\n",
       "         60,  17, 148, 100,   3, 137, 104, 175, 175, 121, 118, 113,   1,\n",
       "         31,  92, 175,  92, 175,  75, 109, 118,  31, 116, 175, 175, 172,\n",
       "        133, 161,  37,  88,  41, 154,  79, 175,  58, 102, 168,  19, 175,\n",
       "         31, 104,  98, 121,  17,  94,   8, 162, 174,  57, 148,   4,  73,\n",
       "         46, 175, 104,  11, 133,  27,  65,  79, 133, 121,  69, 175, 101,\n",
       "         83,  76,  26,  67, 165,  41,  58, 175,  31,  11,  88, 175,  94,\n",
       "        175, 162, 171, 160,  71,  79,  22, 145,  55, 175, 154, 156, 113,\n",
       "        175, 150, 129, 133,  88,   8, 153,  11,  53, 175, 169, 131,  60,\n",
       "         51, 145,  94,  69, 109], dtype=int32)}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3_xgb_rcv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d10ceded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_delta_step</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049083</td>\n",
       "      <td>0.017296</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.185541</td>\n",
       "      <td>1</td>\n",
       "      <td>392</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.810703</td>\n",
       "      <td>{'subsample': 0.5, 'reg_alpha': 0.185540808957...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.952229</td>\n",
       "      <td>0.017830</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030805</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.554711</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500923</td>\n",
       "      <td>{'subsample': 0.25, 'reg_alpha': 0.55471125816...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.947217</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025007</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.554711</td>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195426</td>\n",
       "      <td>{'subsample': 0.15, 'reg_alpha': 0.55471125816...</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.946970</td>\n",
       "      <td>0.939717</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025143</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.285278</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.195426</td>\n",
       "      <td>{'subsample': 0.2, 'reg_alpha': 0.285278110864...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.957299</td>\n",
       "      <td>0.012743</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026535</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.502327</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195426</td>\n",
       "      <td>{'subsample': 0.5, 'reg_alpha': 0.502326663459...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.959843</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.091776</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.046545</td>\n",
       "      <td>1</td>\n",
       "      <td>290</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>{'subsample': 0.5, 'reg_alpha': 0.046544588352...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.055646</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.424736</td>\n",
       "      <td>6</td>\n",
       "      <td>176</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.195426</td>\n",
       "      <td>{'subsample': 0.2, 'reg_alpha': 0.424736282713...</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.934685</td>\n",
       "      <td>0.024781</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.085843</td>\n",
       "      <td>0.009629</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.435973</td>\n",
       "      <td>3</td>\n",
       "      <td>440</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.950198</td>\n",
       "      <td>{'subsample': 0.45, 'reg_alpha': 0.43597323264...</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.946970</td>\n",
       "      <td>0.947236</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.071129</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.424736</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195426</td>\n",
       "      <td>{'subsample': 0.25, 'reg_alpha': 0.42473628271...</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.952286</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.059050</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.046545</td>\n",
       "      <td>6</td>\n",
       "      <td>228</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>{'subsample': 0.5, 'reg_alpha': 0.046544588352...</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.954887</td>\n",
       "      <td>0.946970</td>\n",
       "      <td>0.944729</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.049083      0.017296         0.002973        0.000043   \n",
       "1         0.030805      0.001211         0.003152        0.000181   \n",
       "2         0.025007      0.000163         0.002839        0.000043   \n",
       "3         0.025143      0.000297         0.002929        0.000059   \n",
       "4         0.026535      0.000297         0.002882        0.000055   \n",
       "..             ...           ...              ...             ...   \n",
       "195       0.091776      0.007042         0.004210        0.000219   \n",
       "196       0.055646      0.004702         0.003888        0.000283   \n",
       "197       0.085843      0.009629         0.003665        0.000029   \n",
       "198       0.071129      0.015493         0.003862        0.000140   \n",
       "199       0.059050      0.004142         0.004102        0.000552   \n",
       "\n",
       "    param_subsample param_reg_alpha param_min_child_weight param_max_depth  \\\n",
       "0               0.5        0.185541                      1             392   \n",
       "1              0.25        0.554711                      1              19   \n",
       "2              0.15        0.554711                      3             176   \n",
       "3               0.2        0.285278                      3             160   \n",
       "4               0.5        0.502327                      3             102   \n",
       "..              ...             ...                    ...             ...   \n",
       "195             0.5        0.046545                      1             290   \n",
       "196             0.2        0.424736                      6             176   \n",
       "197            0.45        0.435973                      3             440   \n",
       "198            0.25        0.424736                      3              41   \n",
       "199             0.5        0.046545                      6             228   \n",
       "\n",
       "    param_max_delta_step param_learning_rate param_gamma  \\\n",
       "0                      2                 0.4           4   \n",
       "1                      7                0.25           5   \n",
       "2                      8                 0.2           1   \n",
       "3                      2                 0.4           4   \n",
       "4                      7                0.15           1   \n",
       "..                   ...                 ...         ...   \n",
       "195                    3                0.05           3   \n",
       "196                    5                 0.3           5   \n",
       "197                    8                0.05           5   \n",
       "198                    6                0.05           1   \n",
       "199                    3                 0.3           4   \n",
       "\n",
       "    param_colsample_bytree                                             params  \\\n",
       "0                 0.810703  {'subsample': 0.5, 'reg_alpha': 0.185540808957...   \n",
       "1                 0.500923  {'subsample': 0.25, 'reg_alpha': 0.55471125816...   \n",
       "2                 0.195426  {'subsample': 0.15, 'reg_alpha': 0.55471125816...   \n",
       "3                 0.195426  {'subsample': 0.2, 'reg_alpha': 0.285278110864...   \n",
       "4                 0.195426  {'subsample': 0.5, 'reg_alpha': 0.502326663459...   \n",
       "..                     ...                                                ...   \n",
       "195                 0.9745  {'subsample': 0.5, 'reg_alpha': 0.046544588352...   \n",
       "196               0.195426  {'subsample': 0.2, 'reg_alpha': 0.424736282713...   \n",
       "197               0.950198  {'subsample': 0.45, 'reg_alpha': 0.43597323264...   \n",
       "198               0.195426  {'subsample': 0.25, 'reg_alpha': 0.42473628271...   \n",
       "199                 0.9745  {'subsample': 0.5, 'reg_alpha': 0.046544588352...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0             0.939850           0.977444           0.939394         0.952229   \n",
       "1             0.939850           0.962406           0.939394         0.947217   \n",
       "2             0.924812           0.947368           0.946970         0.939717   \n",
       "3             0.939850           0.969925           0.962121         0.957299   \n",
       "4             0.939850           0.962406           0.977273         0.959843   \n",
       "..                 ...                ...                ...              ...   \n",
       "195           0.939850           0.977444           0.954545         0.957280   \n",
       "196           0.902256           0.962406           0.939394         0.934685   \n",
       "197           0.924812           0.969925           0.946970         0.947236   \n",
       "198           0.932331           0.962406           0.962121         0.952286   \n",
       "199           0.932331           0.954887           0.946970         0.944729   \n",
       "\n",
       "     std_test_score  rank_test_score  \n",
       "0          0.017830               76  \n",
       "1          0.010742               98  \n",
       "2          0.010540              125  \n",
       "3          0.012743               46  \n",
       "4          0.015385               28  \n",
       "..              ...              ...  \n",
       "195        0.015469               51  \n",
       "196        0.024781              145  \n",
       "197        0.018418               94  \n",
       "198        0.014111               69  \n",
       "199        0.009344              109  \n",
       "\n",
       "[200 rows x 19 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3_tuning_result = pd.DataFrame(p3_xgb_rcv.cv_results_)\n",
    "p3_tuning_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8dc905e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590643274853801"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3_tu_acc = best_clf.score(X_test, y_test)\n",
    "p3_tu_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "add51f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3_tu_y_pred = best_clf.predict(X_test)\n",
    "p3_tu_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5a449f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[106,   5],\n",
       "       [  2,  58]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3_tu_cm = confusion_matrix(p3_tu_y_pred, y_test)\n",
    "p3_tu_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9bf1a430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(p3_tu_cm, annot=True,cmap='Blues', fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "53b5abc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score Before Tuning 0.9415204678362573\n",
      "Accuracy Score After Tuning with Parameter_1 0.9415204678362573\n",
      "Accuracy Score After Tuning with Parameter_2 0.9590643274853801\n",
      "Accuracy Score After Tuning with Parameter_3 0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score Before Tuning', xgb_acc)\n",
    "print('Accuracy Score After Tuning with Parameter_1', tu_ac)\n",
    "print('Accuracy Score After Tuning with Parameter_2', tu_acc)\n",
    "print('Accuracy Score After Tuning with Parameter_3', p3_tu_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225acfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4cd269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
